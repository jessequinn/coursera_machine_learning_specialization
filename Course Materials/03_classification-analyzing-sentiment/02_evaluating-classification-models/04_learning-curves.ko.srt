1
00:00:00,253 --> 00:00:03,883
[음악]

2
00:00:03,883 --> 00:00:08,593
회귀 모듈에서는 모델의 오차와 정확도 간의

3
00:00:08,593 --> 00:00:11,140
관련성을 알아봤습니다

4
00:00:12,150 --> 00:00:14,680
이번엔 학습이 필요한 데이터 양을

5
00:00:14,680 --> 00:00:17,530
기준으로 한 관련성을 알아보죠

6
00:00:17,530 --> 00:00:20,750
어느 정도의 데이터를 배워야 하는지 탐구합니다

7
00:00:20,750 --> 00:00:24,380
기계학습에서는 어렵고도 복잡한 질문이죠

8
00:00:24,380 --> 00:00:28,146
물론 데이터의 질만 괜찮다면

9
00:00:28,146 --> 00:00:31,220
데이터는 많을수록 좋습니다

10
00:00:31,220 --> 00:00:35,674
질나쁜 데이터는 아무리 많아도

11
00:00:35,674 --> 00:00:40,830
질좋고 깔끔한 소수의 데이터 샘플보다 못합니다

12
00:00:42,700 --> 00:00:47,560
필요 데이터 양을 분석하는 이론적인 기법이 있습니다

13
00:00:47,560 --> 00:00:52,360
전반적인 경향은 알려주지만

14
00:00:52,360 --> 00:00:55,800
실무에서 사용할 정도로 정밀하지 않습니다

15
00:00:55,800 --> 00:01:00,330
실무에서는 오차의 크기와 종류를

16
00:01:00,330 --> 00:01:05,390
알아내기 위한 경험적 기법들이 있습니다

17
00:01:05,390 --> 00:01:09,400
이어지는 강의에서 이런 기법들을 자세히 다루지만

18
00:01:09,400 --> 00:01:12,000
여기서도 분류에서 어떤 역할을 하는지

19
00:01:12,000 --> 00:01:18,130
안내와 통찰을 제공하고자 합니다

20
00:01:18,130 --> 00:01:22,297
데이터와 품질 관련성의

21
00:01:22,297 --> 00:01:25,040
중요한 표현법의 하나는 학습곡선이라 합니다

22
00:01:25,040 --> 00:01:29,237
학습곡선은 훈련 데이터 양과

23
00:01:29,237 --> 00:01:32,380
오차의 관련성을 나타냅니다

24
00:01:32,380 --> 00:01:36,300
테스트 오차를 알아보죠

25
00:01:36,300 --> 00:01:40,211
훈련 데이터가 아주 적다면

26
00:01:40,211 --> 00:01:43,630
테스트 오차는 클 것입니다

27
00:01:43,630 --> 00:01:46,294
훈련 데이터가 많다면

28
00:01:46,294 --> 00:01:48,510
테스트 오차는 작겠죠

29
00:01:48,510 --> 00:01:53,319
데이터를 추가하면 할수록

30
00:01:53,319 --> 00:01:58,550
곡선이 좋아질 겁니다

31
00:02:04,380 --> 00:02:07,560
점을 통과하지 않았네요 지우겠습니다

32
00:02:09,180 --> 00:02:09,860
됐죠

33
00:02:09,860 --> 00:02:14,145
데이터를 추가할수록 품질이 나아지는

34
00:02:14,145 --> 00:02:15,050
학습곡선의 예입니다

35
00:02:15,050 --> 00:02:17,420
한계가 있나고요?

36
00:02:17,420 --> 00:02:22,720
데이터를 추가하면 품질이 무한히 좋아지나요?

37
00:02:22,720 --> 00:02:29,675
데이터를 추가할수록 오차가 줄어들 겁니다

38
00:02:29,675 --> 00:02:33,295
하지만 여전히 간극이 있습니다

39
00:02:33,295 --> 00:02:36,490
이 간극이 0가 될지 보면 답은

40
00:02:36,490 --> 00:02:37,295
일반적으로 아닙니다

41
00:02:37,295 --> 00:02:39,175
이 간극은 편향이라 불립니다

42
00:02:40,475 --> 00:02:45,215
이 편향, 간극이 뭔지 설명하죠

43
00:02:45,215 --> 00:02:47,949
직관적으로

44
00:02:47,949 --> 00:02:53,052
데이터가 무한하더라도

45
00:02:53,052 --> 00:02:58,350
테스트 오차가 0이 되지는 않습니다

46
00:02:59,880 --> 00:03:01,280
왜인지 잠시 생각해보죠

47
00:03:02,340 --> 00:03:06,640
복잡한 모델일수록 편향이 적은 경향이 있습니다

48
00:03:06,640 --> 00:03:10,890
우리가 만들 감성 분석 분류기에서

49
00:03:10,890 --> 00:03:12,920
굉장하다, 좋다, 훌륭하다, 최악이다, 끔찍하다

50
00:03:12,920 --> 00:03:18,032
같이 단어 하나만 사용하면 성능이
그럭저럭 나옵니다

51
00:03:18,032 --> 00:03:20,840
꽤 괜찮을지도 모르지만 대체로 그럭저럭이죠

52
00:03:20,840 --> 00:03:24,929
하지만 무한한 데이터, 전세계의 모든 데이터가

53
00:03:24,929 --> 00:03:28,970
있더라도 초밥은 좋지 않았다는 문장을
제대로 판별하지 못할 것입니다

54
00:03:30,070 --> 00:03:32,010
단어짝을 보지 않기 때문이죠

55
00:03:32,010 --> 00:03:34,940
좋다라는 단어 하나만 봅니다

56
00:03:37,050 --> 00:03:42,880
예를 들어 단어 조합을 고려하는 복잡한 모델은

57
00:03:42,880 --> 00:03:44,820
바이그램 모델이라고 하는데

58
00:03:44,820 --> 00:03:47,850
좋지 않다 같은 연속적인 단어짝을 고려합니다

59
00:03:49,090 --> 00:03:53,760
이런 모델에는 더 많은 파라미터가 필요한데
가짓수가 많기 때문이죠

60
00:03:53,760 --> 00:03:58,803
성능도 나은데 좋다에 대한 파라미터는 1.5,

61
00:03:58,803 --> 00:04:01,053
좋지 않다는 -2.1를 써서요

62
00:04:01,053 --> 00:04:04,803
그러면 방금의 문장, 초밥은 좋지 않았다는
제대로 판별하게 됩니다

63
00:04:04,803 --> 00:04:06,330
편향이 줄어듭니다

64
00:04:07,430 --> 00:04:11,270
단어만으론 표현하지 못했던 문장을 표현해서

65
00:04:11,270 --> 00:04:13,820
더 정확해지는 것이죠

66
00:04:13,820 --> 00:04:17,158
하지만 더 많은 데이터가 필요한데 파라미터가
더 많기 때문입니다

67
00:04:17,158 --> 00:04:20,150
좋다라는 파라미터뿐만 아니라 좋지 않다는 파라미터와

68
00:04:20,150 --> 00:04:22,230
모든 단어 조합이 있습니다

69
00:04:22,230 --> 00:04:27,160
모델에 파라미터가 많을수록 일반적으로
학습 데이터가 더 필요합니다

70
00:04:27,160 --> 00:04:28,390
다시 예제로 돌아가보죠

71
00:04:29,390 --> 00:04:35,280
훈련 데이터의 양이 테스트 오차에 미치는
영향에 대해 알아봤습니다

72
00:04:35,280 --> 00:04:39,470
단어 하나만 가지고 만드는 모델을 설명하죠

73
00:04:39,470 --> 00:04:45,840
이게 단어짝 기반의 분류기와 연관이 있냐고요?

74
00:04:45,840 --> 00:04:49,863
바이그램 기반 분류기는 데이터가 적을 때

75
00:04:49,863 --> 00:04:54,050
성능이 좋지 않은데 더 많은 파라미터를
적합화해야 하기 때문이죠

76
00:04:55,050 --> 00:04:59,700
하지만 데이터가 많으면 성능이 좋아지는데

77
00:04:59,700 --> 00:05:04,490
초밥은 좋지 않았다 같은 문장을
잡아낼 수 있기 때문이죠

78
00:05:04,490 --> 00:05:08,675
그러므로 예상되는 반응은 다음과 같습니다

79
00:05:12,220 --> 00:05:16,898
어느 점에서 바이그램 모델이 유니그램 모델을

80
00:05:16,898 --> 00:05:19,170
성능으로 넘어서게 됩니다

81
00:05:20,370 --> 00:05:24,850
하지만 바이그램 모델에도 편향이 있습니다

82
00:05:24,850 --> 00:05:28,870
적기는 하지만 아직 있죠

83
00:05:32,509 --> 00:05:36,479
[음악]