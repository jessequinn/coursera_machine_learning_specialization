1
00:00:00,253 --> 00:00:03,883
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:03,883 --> 00:00:08,593
在回归模型里 我们讨论过 误差/正确率

3
00:00:08,593 --> 00:00:11,140
和模型复杂度之间的关系

4
00:00:12,150 --> 00:00:14,680
现在我们来看看

5
00:00:14,680 --> 00:00:17,530
你的模型需要学习多少数据
和模型复杂度之间的关系

6
00:00:17,530 --> 00:00:20,750
我们会探讨为了学好一个模型
到底需要多少数据

7
00:00:20,750 --> 00:00:24,380
这在机器学习中 是一个很困难和复杂的问题

8
00:00:24,380 --> 00:00:28,146
当然了 在数据质量不错的前提下

9
00:00:28,146 --> 00:00:31,220
数据总是越多越好

10
00:00:31,220 --> 00:00:35,674
坏数据  大量的坏数据

11
00:00:35,674 --> 00:00:40,830
肯定比拥有少量很好很清晰 高质量的数据 
要糟糕得多

12
00:00:42,700 --> 00:00:47,560
自然我们可以用一些理论技巧来分析
我们到底需要多少数据

13
00:00:47,560 --> 00:00:52,360
这些技巧能帮助我们理解数据的总体趋势

14
00:00:52,360 --> 00:00:55,800
但这些技巧对实际应用来说太松散了

15
00:00:55,800 --> 00:01:00,330
实际应用中 我们有些很实用的技术

16
00:01:00,330 --> 00:01:05,390
可以帮助我们理解 我们的误差率有多大
以及我们在犯哪种错误

17
00:01:05,390 --> 00:01:09,400
在这系列后面的课程中 我们会更深入探讨这些技术

18
00:01:09,400 --> 00:01:12,000
但这里我想给大家一点指导

19
00:01:12,000 --> 00:01:18,130
一点这些技术在分类领域里的应用指导

20
00:01:18,130 --> 00:01:22,297
在数据和模型质量的关系里
有个很重要的指标

21
00:01:22,297 --> 00:01:25,040
是我们所谓的 学习曲线

22
00:01:25,040 --> 00:01:29,237
学习曲线把我们有多少数据

23
00:01:29,237 --> 00:01:32,380
和我们的误差率 联系在一起

24
00:01:32,380 --> 00:01:36,300
我们这里说的是测试误差率

25
00:01:36,300 --> 00:01:40,211
如果你的训练数据非常少

26
00:01:40,211 --> 00:01:43,630
那么自然测试误差会比较高

27
00:01:43,630 --> 00:01:46,294
如果你的训练数据比较多

28
00:01:46,294 --> 00:01:48,510
你的测试误差会比较低

29
00:01:48,510 --> 00:01:53,319
所以 随着你拥有越来越多的数据

30
00:01:53,319 --> 00:01:58,550
你的学习曲线会越来越好 
(就是测试误差率会越来越低)

31
00:02:04,380 --> 00:02:07,560
糟糕 我还没讲到那块呢 那我就删掉这个好了 

32
00:02:09,180 --> 00:02:09,860
我们再接着讲

33
00:02:09,860 --> 00:02:14,145
图中曲线就是一个学习曲线的例子

34
00:02:14,145 --> 00:02:15,050
横轴代表的数据量越来越高的话
纵轴代表的误差率就越来越低

35
00:02:15,050 --> 00:02:17,420
那么现在你可能问了  这个曲线趋势有没有个极限呢

36
00:02:17,420 --> 00:02:22,720
如果你一直加入更多的数据
误差率会不会永远地降低下去

37
00:02:22,720 --> 00:02:29,675
我们知道 当我们加入更多数据的时候
测试误差会降低

38
00:02:29,675 --> 00:02:33,295
但是我们看到 误差率的值和零之间有个空隙

39
00:02:33,295 --> 00:02:36,490
那么问题来了 这个空隙能变成零吗

40
00:02:36,490 --> 00:02:37,295
一般来说 答案是不能

41
00:02:37,295 --> 00:02:39,175
这个空隙被称作 偏差

42
00:02:40,475 --> 00:02:45,215
我们接下来谈谈这个偏差 或说这个空隙 到底是什么

43
00:02:45,215 --> 00:02:47,949
直觉来说

44
00:02:47,949 --> 00:02:53,052
偏差代表着 就算你有无限多的数据

45
00:02:53,052 --> 00:02:58,350
测试误差也不会变成零

46
00:02:59,880 --> 00:03:01,280
为什么呢

47
00:03:02,340 --> 00:03:06,640
更复杂的模型一般会有更小的偏差

48
00:03:06,640 --> 00:03:10,890
所以说如果你看看我们前面建造的情绪分析分类器

49
00:03:10,890 --> 00:03:12,920
如果你只用一些简单的词
好比说 棒 好 很好 可怕 糟糕

50
00:03:12,920 --> 00:03:18,032
分类器也能凑合工作

51
00:03:18,032 --> 00:03:20,840
有可能还工作的挺好的  
也有可能就是凑合能用

52
00:03:20,840 --> 00:03:24,929
但是就算你有无穷多的数据
你有全世界的数据

53
00:03:24,929 --> 00:03:28,970
下面这个句子你也分不好类:
这寿司  不(not) 好(good)

54
00:03:30,070 --> 00:03:32,010
原因是你没有考虑 单词对

55
00:03:32,010 --> 00:03:34,940
你仅仅考虑了每个单词本身 比如 好(good)  不(not)

56
00:03:37,050 --> 00:03:42,880
所以有些更复杂的模型 会考虑单词组合

57
00:03:42,880 --> 00:03:44,820
举个例子 有所谓 双连词 模型

58
00:03:44,820 --> 00:03:47,850
这个模型会考虑单词对 比如  不好(not good)

59
00:03:49,090 --> 00:03:53,760
这类模型需要更多参数
因为有可更多可能

60
00:03:53,760 --> 00:03:58,803
它们的分类结果可以更好 
比如它们给一个单词 "好"(good) 的参数是 1.5

61
00:03:58,803 --> 00:04:01,053
但给单词对 "不好"(not good) 的参数是 -2.1

62
00:04:01,053 --> 00:04:04,803
因此这类模型可以正确把 "这寿司不好" 分类

63
00:04:04,803 --> 00:04:06,330
所以它们的偏差会更小

64
00:04:07,430 --> 00:04:11,270
它们可以代表那些不能通过单个单词代表的句子

65
00:04:11,270 --> 00:04:13,820
因此它们有可能分类更准确

66
00:04:13,820 --> 00:04:17,158
但这些模型需要更多数据来学习 
因为它们参数更多

67
00:04:17,158 --> 00:04:20,150
不仅仅是只有一个对单词 "好" 的参数
它们还有表示 单词对 "不好" 的参数

68
00:04:20,150 --> 00:04:22,230
以及针对其它各种单词组合的参数

69
00:04:22,230 --> 00:04:27,160
一般来说 你的模型参数越多
你学习这个模型所需要的数据也就越多

70
00:04:27,160 --> 00:04:28,390
我们回头再看我们的例子

71
00:04:29,390 --> 00:04:35,280
我们讨论了数据量和误差率之间的关系

72
00:04:35,280 --> 00:04:39,470
比如说我用单个单词来构建一个分类器模型

73
00:04:39,470 --> 00:04:45,840
它和一个在用单词对的基础上构建的分类器
比较起来怎么样呢

74
00:04:45,840 --> 00:04:49,863
如果你只有比较少的数据
一个用双连词构建的分类器

75
00:04:49,863 --> 00:04:54,050
表现不会怎么样的 
因为它需要拟合更多参数

76
00:04:55,050 --> 00:04:59,700
但一旦你有了更多的数据
这个模型成绩就会更好 

77
00:04:59,700 --> 00:05:04,490
因为它可以正确分类  类似
"这寿司不好" 这样的句子

78
00:05:04,490 --> 00:05:08,675
所以说学习曲线看起来会像这样:

79
00:05:12,220 --> 00:05:16,898
在某个点 这两种模型的误差率会交叉

80
00:05:16,898 --> 00:05:19,170
就是随着数据变多 双连词模型开始比
独个单词模型 结果更好

81
00:05:20,370 --> 00:05:24,850
但请注意双连词模型依然还是有些偏差

82
00:05:24,850 --> 00:05:28,870
这偏差比独个单词模型变小了  但依然存在

83
00:05:32,509 --> 00:05:36,479
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community