[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community 在回归模型里 我们讨论过 误差/正确率 和模型复杂度之间的关系 现在我们来看看 你的模型需要学习多少数据
和模型复杂度之间的关系 我们会探讨为了学好一个模型
到底需要多少数据 这在机器学习中 是一个很困难和复杂的问题 当然了 在数据质量不错的前提下 数据总是越多越好 坏数据  大量的坏数据 肯定比拥有少量很好很清晰 高质量的数据 
要糟糕得多 自然我们可以用一些理论技巧来分析
我们到底需要多少数据 这些技巧能帮助我们理解数据的总体趋势 但这些技巧对实际应用来说太松散了 实际应用中 我们有些很实用的技术 可以帮助我们理解 我们的误差率有多大
以及我们在犯哪种错误 在这系列后面的课程中 我们会更深入探讨这些技术 但这里我想给大家一点指导 一点这些技术在分类领域里的应用指导 在数据和模型质量的关系里
有个很重要的指标 是我们所谓的 学习曲线 学习曲线把我们有多少数据 和我们的误差率 联系在一起 我们这里说的是测试误差率 如果你的训练数据非常少 那么自然测试误差会比较高 如果你的训练数据比较多 你的测试误差会比较低 所以 随着你拥有越来越多的数据 你的学习曲线会越来越好 
(就是测试误差率会越来越低) 糟糕 我还没讲到那块呢 那我就删掉这个好了 我们再接着讲 图中曲线就是一个学习曲线的例子 横轴代表的数据量越来越高的话
纵轴代表的误差率就越来越低 那么现在你可能问了  这个曲线趋势有没有个极限呢 如果你一直加入更多的数据
误差率会不会永远地降低下去 我们知道 当我们加入更多数据的时候
测试误差会降低 但是我们看到 误差率的值和零之间有个空隙 那么问题来了 这个空隙能变成零吗 一般来说 答案是不能 这个空隙被称作 偏差 我们接下来谈谈这个偏差 或说这个空隙 到底是什么 直觉来说 偏差代表着 就算你有无限多的数据 测试误差也不会变成零 为什么呢 更复杂的模型一般会有更小的偏差 所以说如果你看看我们前面建造的情绪分析分类器 如果你只用一些简单的词
好比说 棒 好 很好 可怕 糟糕 分类器也能凑合工作 有可能还工作的挺好的  
也有可能就是凑合能用 但是就算你有无穷多的数据
你有全世界的数据 下面这个句子你也分不好类:
这寿司  不(not) 好(good) 原因是你没有考虑 单词对 你仅仅考虑了每个单词本身 比如 好(good)  不(not) 所以有些更复杂的模型 会考虑单词组合 举个例子 有所谓 双连词 模型 这个模型会考虑单词对 比如  不好(not good) 这类模型需要更多参数
因为有可更多可能 它们的分类结果可以更好 
比如它们给一个单词 "好"(good) 的参数是 1.5 但给单词对 "不好"(not good) 的参数是 -2.1 因此这类模型可以正确把 "这寿司不好" 分类 所以它们的偏差会更小 它们可以代表那些不能通过单个单词代表的句子 因此它们有可能分类更准确 但这些模型需要更多数据来学习 
因为它们参数更多 不仅仅是只有一个对单词 "好" 的参数
它们还有表示 单词对 "不好" 的参数 以及针对其它各种单词组合的参数 一般来说 你的模型参数越多
你学习这个模型所需要的数据也就越多 我们回头再看我们的例子 我们讨论了数据量和误差率之间的关系 比如说我用单个单词来构建一个分类器模型 它和一个在用单词对的基础上构建的分类器
比较起来怎么样呢 如果你只有比较少的数据
一个用双连词构建的分类器 表现不会怎么样的 
因为它需要拟合更多参数 但一旦你有了更多的数据
这个模型成绩就会更好 因为它可以正确分类  类似
"这寿司不好" 这样的句子 所以说学习曲线看起来会像这样: 在某个点 这两种模型的误差率会交叉 就是随着数据变多 双连词模型开始比
独个单词模型 结果更好 但请注意双连词模型依然还是有些偏差 这偏差比独个单词模型变小了  但依然存在 [背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community