1
00:00:00,000 --> 00:00:04,106
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:04,106 --> 00:00:09,158
对于每一个我们可能考虑到的模型的次数

3
00:00:09,158 --> 00:00:12,441
举例来说 一个线性模型 或者

4
00:00:12,441 --> 00:00:17,367
我们同样讨论过使用一个二次模型

5
00:00:17,367 --> 00:00:23,700
一直到我们所讨论的 非常疯狂的
13次多项式

6
00:00:25,140 --> 00:00:30,322
当然 我们甚至也可以考虑更加高次的模型

7
00:00:30,322 --> 00:00:32,790
好的 那么测试损失会发生什么呢？

8
00:00:32,790 --> 00:00:34,200
抱歉 我想说的不是测试损失

9
00:00:34,200 --> 00:00:35,559
让我们从训练损失开始

10
00:00:35,559 --> 00:00:37,090
这考虑起来要容易许多

11
00:00:37,090 --> 00:00:37,920
所以训练损失

12
00:00:39,510 --> 00:00:45,520
当我们增加模型的次数时 这样的模型能够

13
00:00:45,520 --> 00:00:50,470
更好地拟合我们在训练集中的观测值

14
00:00:50,470 --> 00:00:53,260
所以我们将会看到的是 
我们的训练损失

15
00:00:54,390 --> 00:00:59,320
会随着模型次数的上升而下降

16
00:00:59,320 --> 00:01:01,000
记住我们所画出的这条曲线

17
00:01:01,000 --> 00:01:04,335
我们可以看到残差平方和的变化
关于线性拟合

18
00:01:04,335 --> 00:01:09,450
二次拟合 一直到13次多项式的拟合
这基本上符合了

19
00:01:09,450 --> 00:01:10,860
我们每一个的观测值

20
00:01:10,860 --> 00:01:14,770
所以我们可以看到
残差平方和在不断地下降

21
00:01:14,770 --> 00:01:18,281
这个趋势即使当我们排除了一些观测值的时候也成立

22
00:01:18,281 --> 00:01:20,528
也就是我们仅仅着眼于训练集

23
00:01:20,528 --> 00:01:23,645
所以我们会看到我们的训练损失在下降

24
00:01:23,645 --> 00:01:26,907
当我们增加模型的灵活性的时候不断地下降

25
00:01:26,907 --> 00:01:32,741
让我们把这条曲线标注为我们的训练损失

26
00:01:32,741 --> 00:01:37,936
特别地 是关于我们所估计的模型参数 w帽的损失

27
00:01:37,936 --> 00:01:42,080
现在让我们来弄清楚w 帽究竟代表了什么

28
00:01:42,080 --> 00:01:49,533
对于每一个复杂度层次的模型
比如线性模型 二次模型等等

29
00:01:49,533 --> 00:01:52,791
我们所要做的 就是去最优化

30
00:01:52,791 --> 00:01:55,980
并且为线性模型找到一组参数w 帽

31
00:01:55,980 --> 00:01:59,640
我们会在所有可能的直线当中搜索
搜索那条最小化训练损失的线

32
00:01:59,640 --> 00:02:01,290
还记得我们所说过的吗

33
00:02:01,290 --> 00:02:06,890
在好几页幻灯片之前我们曾经说过
我们用来估计模型的方法就是

34
00:02:06,890 --> 00:02:12,220
最小化与我们的训练集上观测值的误差

35
00:02:12,220 --> 00:02:14,320
这就是我们如何获得线性模型的参数w 帽的方法

36
00:02:14,320 --> 00:02:17,780
然后我们就用w 帽去计算训练损失

37
00:02:17,780 --> 00:02:20,620
接下来让我们考察所有可能的二次曲线拟合

38
00:02:20,620 --> 00:02:24,240
在所有的二次曲线上最小化训练损失

39
00:02:24,240 --> 00:02:27,102
这就是我们得到二次曲线的w 帽的方法

40
00:02:27,102 --> 00:02:31,929
然后我们画出关于w hat的训练损失

41
00:02:31,929 --> 00:02:34,308
那些二次曲线的w 帽等等诸如此类

42
00:02:34,308 --> 00:02:37,348
好的 我们同样也可以来讨论测试损失 但是

43
00:02:37,348 --> 00:02:42,228
这里会稍稍地复杂一些
让我们来考虑一下

44
00:02:42,228 --> 00:02:45,755
当我们增加模型的次数的时候
测试损失会发生什么呢？

45
00:02:45,755 --> 00:02:49,969
如果你还记得那个13次多项式拟合的模型
我们所看到的是

46
00:02:49,969 --> 00:02:54,340
那条疯狂而扭曲的曲线
所作出的预测是十分糟糕的

47
00:02:54,340 --> 00:02:59,210
所以当我们考虑把测试集排除在外
拟合13次多项式模型的时候

48
00:02:59,210 --> 00:03:04,480
仅仅使用训练数据 
我们会看到一条扭曲而疯狂的拟合曲线

49
00:03:04,480 --> 00:03:09,520
接着当我们考察测试集中的观测数据
就是那些我们

50
00:03:09,520 --> 00:03:14,900
排除在外的数据
我们可能会发现相比那些实际的数据 我们的预测非常糟糕

51
00:03:16,050 --> 00:03:20,376
所以符合我们预期的是
在某一个点上

52
00:03:20,376 --> 00:03:23,678
我们的测试损失很可能会开始上升

53
00:03:23,678 --> 00:03:28,769
所以测试损失的函数曲线
很可能看上去像下面这样

54
00:03:28,769 --> 00:03:34,228
在某些时间段当中测试损失可能是下降的
但是超过一个点之后

55
00:03:36,028 --> 00:03:39,743
损失开始重新地上升

56
00:03:39,743 --> 00:03:46,349
这就是测试损失的变化曲线

57
00:03:46,349 --> 00:03:50,272
关于我们所拟合的这些模型

58
00:03:50,272 --> 00:03:54,607
这些模型

59
00:03:54,607 --> 00:03:59,160
是用训练数据来拟合的

60
00:04:00,720 --> 00:04:04,174
这些曲线就是训练损失

61
00:04:04,174 --> 00:04:06,912
和测试损失关于模型复杂度的函数关系所应该呈现的样子

62
00:04:06,912 --> 00:04:10,561
那么我们如何使用这些思想
去实际上选择一个模型

63
00:04:10,561 --> 00:04:14,697
或者说模型的复杂度
然后基于我们选择的模型去作出预测

64
00:04:14,697 --> 00:04:17,851
我们会在之后的课程中更加深入地讨论这些细节
在回归分析的课程

65
00:04:17,851 --> 00:04:19,256
以及分类的课程中

66
00:04:19,256 --> 00:04:22,425
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community