1
00:00:00,000 --> 00:00:04,106
[음악]

2
00:00:04,106 --> 00:00:09,158
고려 대상인 각각의 모델 차수에 대해

3
00:00:09,158 --> 00:00:12,441
예를 들어 직선 모델이나

4
00:00:12,441 --> 00:00:17,367
이차곡선 모델,

5
00:00:17,367 --> 00:00:23,700
13차 다항식까지 다뤘습니다

6
00:00:25,140 --> 00:00:30,322
물론 더 고차 모델도 고려할 수는 있습니다

7
00:00:30,322 --> 00:00:32,790
테스트 오류는 어떻게 되나요?

8
00:00:32,790 --> 00:00:34,200
죄송합니다. 테스트 오류가 아니라

9
00:00:34,200 --> 00:00:35,559
훈련 오류부터 시작하죠

10
00:00:35,559 --> 00:00:37,090
훨씬 이해하기가 쉽습니다

11
00:00:37,090 --> 00:00:37,920
훈련 오류

12
00:00:39,510 --> 00:00:45,520
모델 차수를 증가시키면 시킬수록

13
00:00:45,520 --> 00:00:50,470
훈련 데이터 세트의 결과에
더 적합하게 맞춰집니다

14
00:00:50,470 --> 00:00:53,260
즉 훈련 오류는 모델 차수를 증가시킬수록

15
00:00:54,390 --> 00:00:59,320
감소하죠

16
00:00:59,320 --> 00:01:01,000
전에 봤던 곡선을 되짚어 봅시다

17
00:01:01,000 --> 00:01:04,335
회귀직선, 이차회귀곡선에서

18
00:01:04,335 --> 00:01:09,450
모든 결과에 부합하는 13차 다항식에

19
00:01:09,450 --> 00:01:10,860
대응하는 잔차제곱합입니다

20
00:01:10,860 --> 00:01:14,770
잔차제곱합이 점점 감소함을 확인할 수 있습니다

21
00:01:14,770 --> 00:01:18,281
몇몇 결과를 따로 빼놓은
훈련 데이터 세트를 보면

22
00:01:18,281 --> 00:01:20,528
이 가정이 참이라는 사실을
확인할 수 있습니다

23
00:01:20,528 --> 00:01:23,645
모델의 유연성을 증가시킬수록

24
00:01:23,645 --> 00:01:26,907
훈련 오류가 감소하는 것이죠

25
00:01:26,907 --> 00:01:32,741
여기에 예측 모델 파라미터 w 모자라고

26
00:01:32,741 --> 00:01:37,936
적어두죠

27
00:01:37,936 --> 00:01:42,080
w 모자가 무엇인지를 확실히 하고
넘어가죠

28
00:01:42,080 --> 00:01:49,533
직선 모델, 이차곡선 모델 등의
모델 복잡도를 최적화하고

29
00:01:49,533 --> 00:01:52,791
직선 모델 파라미터 w 모자를

30
00:01:52,791 --> 00:01:55,980
찾을 것입니다

31
00:01:55,980 --> 00:01:59,640
가능한 모든 선을 탐색해 훈련 오류를
최소화합니다

32
00:01:59,640 --> 00:02:01,290
몇 슬라이드 전에 말씀드렸는데,

33
00:02:01,290 --> 00:02:06,890
모델을 예측하는 방법은 훈련 데이터 세트
결과의 오류를

34
00:02:06,890 --> 00:02:12,220
최소화하는 것이라고 했습니다

35
00:02:12,220 --> 00:02:14,320
직선 모델의 w 모자를 그렇게 구하고

36
00:02:14,320 --> 00:02:17,780
그 w 모자에 대응하는 훈련 오류를
계산합니다

37
00:02:17,780 --> 00:02:20,620
가능한 모든 이차회귀곡선을 살펴봅니다

38
00:02:20,620 --> 00:02:24,240
모든 이차회귀곡선에 대한 훈련 오류를
최소화해서

39
00:02:24,240 --> 00:02:27,102
이차곡선 모델의 w 모자를 구합니다

40
00:02:27,102 --> 00:02:31,929
그런 다음 이차곡선 모델의 w 모자에

41
00:02:31,929 --> 00:02:34,308
대응하는 훈련 오류 그래프를 그리는 것입니다

42
00:02:34,308 --> 00:02:37,348
테스트 오류에 대해서도 논해볼 수 있지만

43
00:02:37,348 --> 00:02:42,228
이건 좀 복잡한데 모델 차수를 증가시킬수록

44
00:02:42,228 --> 00:02:45,755
어떻게 될까요?

45
00:02:45,755 --> 00:02:49,969
꾸불꾸불한 13차 다항식 곡선을 기억하신다면

46
00:02:49,969 --> 00:02:54,340
아시겠지만 예측 정확도가 떨어집니다

47
00:02:54,340 --> 00:02:59,210
테스트 데이터를 따로 빼놓는다고 할 때

48
00:02:59,210 --> 00:03:04,480
훈련 데이터에만 13차 다항식을 적용하면
꾸불꾸불한 곡선이 나올 겁니다

49
00:03:04,480 --> 00:03:09,520
그런 다음 테스트 결과인 빼놓은 주택에

50
00:03:09,520 --> 00:03:14,900
적용해 보면 예측이 실제 수치와
동떨어져 있을 확률이 높습니다

51
00:03:16,050 --> 00:03:20,376
그러므로 예상가능한 건 어느 지점부터

52
00:03:20,376 --> 00:03:23,678
테스트 오류가 증가하리란 점입니다

53
00:03:23,678 --> 00:03:28,769
테스트 오류 곡선은 주로 다음과 같은
모습이 되는데

54
00:03:28,769 --> 00:03:34,228
특정 지점까지는 오류가 감소하지만

55
00:03:36,028 --> 00:03:39,743
그 후로는 다시 증가합니다

56
00:03:39,743 --> 00:03:46,349
모델이 훈련 데이터에 의해

57
00:03:46,349 --> 00:03:50,272
학습되었을 때

58
00:03:50,272 --> 00:03:54,607
모델에 대한 테스트 오류가

59
00:03:54,607 --> 00:03:59,160
여기 이 곡선이 됩니다

60
00:04:00,720 --> 00:04:04,174
훈련 오류와 테스트 오류를

61
00:04:04,174 --> 00:04:06,912
모델 복잡도에 대한 함수로 나타내면
이런 곡선이 됩니다

62
00:04:06,912 --> 00:04:10,561
이런 개념을 통해 예측을 위한

63
00:04:10,561 --> 00:04:14,697
모델, 모델 복잡도를 어떻게 선택할지에 대해선

64
00:04:14,697 --> 00:04:17,851
회귀와 분류 강의에서 훨씬 자세히

65
00:04:17,851 --> 00:04:19,256
다룰 예정입니다

66
00:04:19,256 --> 00:04:22,425
[음악]