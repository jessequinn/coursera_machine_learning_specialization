1
00:00:00,000 --> 00:00:04,039
[MUSIC]

2
00:00:04,039 --> 00:00:07,696
In this module, we've seen how regression
can be used to predict house prices and

3
00:00:07,696 --> 00:00:10,600
also be useful in a wide
range of other applications.

4
00:00:10,600 --> 00:00:14,575
So, in the introduction to this course,
Carlos introduced this machine

5
00:00:14,575 --> 00:00:17,908
learning pipeline,
where we go from data, which gets shoved

6
00:00:17,908 --> 00:00:22,098
into some machine learning method, and
we use that to derive intelligence.

7
00:00:22,098 --> 00:00:26,128
Well, let's dig into this block diagram
and expand it, now that we've seen

8
00:00:26,128 --> 00:00:29,982
these some of these machine learning
tools, in a little bit more detail.

9
00:00:29,982 --> 00:00:34,575
Okay, so now we know what we actually use
to fit our data is some training data set,

10
00:00:34,575 --> 00:00:36,436
so that's gonna be our data.

11
00:00:36,436 --> 00:00:39,768
And in our housing application,

12
00:00:39,768 --> 00:00:45,242
where we're going to predict
the price of some house,

13
00:00:45,242 --> 00:00:51,787
the data that we collected was,
we had this table of the house ID,

14
00:00:51,787 --> 00:00:58,936
and some set of house attributes,
as well as the house's sales price.

15
00:01:02,434 --> 00:01:06,242
And we had this for a whole bunch
of houses in our neighborhood, and

16
00:01:06,242 --> 00:01:09,330
we collected this data into some table.

17
00:01:09,330 --> 00:01:12,090
So, that represented
our training data set.

18
00:01:13,340 --> 00:01:17,270
And then we took that data, and what we
did was shoved it through some feature

19
00:01:17,270 --> 00:01:20,960
extractor, which in this case is
a very simple feature extractor,

20
00:01:20,960 --> 00:01:25,000
where we just choose some
subset of the house attributes.

21
00:01:25,000 --> 00:01:29,570
So, in the examples we looked at,
X, our set of features,

22
00:01:29,570 --> 00:01:35,290
represented things, like,
we looked at square feet of the house,

23
00:01:35,290 --> 00:01:39,370
and we also looked at number of bathrooms.

24
00:01:40,500 --> 00:01:43,300
And we talked about possibly
using more features.

25
00:01:43,300 --> 00:01:45,730
Again, we'll talk about that more
in the regression course, but

26
00:01:45,730 --> 00:01:49,730
those were two that we
examined in this module.

27
00:01:49,730 --> 00:01:51,820
And so then,
what did we do with these features?

28
00:01:51,820 --> 00:01:55,105
Well, our goal was to
take these features and

29
00:01:55,105 --> 00:01:59,957
have some type of model that led to
a prediction of the house price.

30
00:01:59,957 --> 00:02:04,426
Okay, so our output, the intelligence that

31
00:02:04,426 --> 00:02:09,373
we're deriving,
is the predicted house price.

32
00:02:12,133 --> 00:02:15,392
And we're going to do this for
every house in our training data set.

33
00:02:15,392 --> 00:02:18,870
We're gonna take its associated features,
and

34
00:02:18,870 --> 00:02:23,700
shove it through this machine learning
model, and predict the house price.

35
00:02:23,700 --> 00:02:26,010
And what's the machine learning
model we talked about?

36
00:02:26,010 --> 00:02:28,375
Well, in this case, it's regression.

37
00:02:31,705 --> 00:02:36,670
That's our specific machine learning
model that we're looking at here.

38
00:02:37,950 --> 00:02:42,506
Okay, but remember that this machine
learning model had some set of parameters.

39
00:02:42,506 --> 00:02:44,554
Okay, so the parameters we call W.

40
00:02:44,554 --> 00:02:47,650
These are the weights on our features.

41
00:02:48,820 --> 00:02:53,770
So, for example, it's the weight on square
feet or number of bathrooms, and so on.

42
00:02:54,870 --> 00:02:57,509
More technically,
these are called regression coefficients.

43
00:02:59,610 --> 00:03:02,520
And we talked about estimating
these parameters from data,

44
00:03:02,520 --> 00:03:05,600
so our W hat is our estimate
of these parameters.

45
00:03:05,600 --> 00:03:07,630
And how did we talk about doing that?

46
00:03:07,630 --> 00:03:10,400
Well, we took our predicted output, so

47
00:03:10,400 --> 00:03:15,700
our predicted house price, and
we compared it to the true house price.

48
00:03:15,700 --> 00:03:20,080
So, the actual sales price that we
recorded in our training data table.

49
00:03:20,080 --> 00:03:24,950
So, Y, here, is our actual sales

50
00:03:24,950 --> 00:03:29,290
price for the houses in our training data.

51
00:03:29,290 --> 00:03:32,320
And we compare to
the predicted house price.

52
00:03:32,320 --> 00:03:36,040
And we use a quality metric to measure
how well we're doing with our prediction,

53
00:03:37,040 --> 00:03:41,050
using our model, using W hat as
the parameters of that model.

54
00:03:42,120 --> 00:03:43,090
Well, how well are we doing?

55
00:03:43,090 --> 00:03:44,660
What was the error metric we talked about?

56
00:03:45,880 --> 00:03:51,910
The error metric we talked about was
something called residual sum of squares,

57
00:03:51,910 --> 00:03:56,600
where we just sum up the square difference
between the actual house sales price and

58
00:03:56,600 --> 00:04:00,487
the predicted house sales price, summing
over all houses in our training data set.

59
00:04:01,570 --> 00:04:05,170
Okay, so our quality metric is
gonna take our predictions and

60
00:04:05,170 --> 00:04:10,300
our actual house sales observations,
spit out this error, and

61
00:04:10,300 --> 00:04:15,760
it's gonna go into a machine learning
algorithm that's gonna be used to update

62
00:04:15,760 --> 00:04:19,600
the weights,
update our parameters of our model.

63
00:04:19,600 --> 00:04:23,310
And we're gonna talk about this
machine learning algorithm, or

64
00:04:23,310 --> 00:04:27,950
different variants of it, a lot more
in the actual course on regression.

65
00:04:27,950 --> 00:04:32,810
But this is the overall flowchart for
this machine learning method for

66
00:04:32,810 --> 00:04:34,610
our house prediction problem.

67
00:04:34,610 --> 00:04:38,190
And this loop here,
where we're taking our predictions,

68
00:04:38,190 --> 00:04:42,170
computing our error relative to
the actual house sales prices,

69
00:04:42,170 --> 00:04:46,210
and updating the weights or
our model parameters.

70
00:04:46,210 --> 00:04:49,410
This process tends to
happen in an iterative way,

71
00:04:49,410 --> 00:04:52,960
where we update values again and again.

72
00:04:52,960 --> 00:04:57,930
Okay, so if we abstract a way, what we
see is we have some training data set.

73
00:04:57,930 --> 00:05:00,320
We have some feature extraction process.

74
00:05:00,320 --> 00:05:02,450
We have some machine learning model.

75
00:05:02,450 --> 00:05:06,306
And it's gonna produce some intelligence,
which in this case is a prediction.

76
00:05:06,306 --> 00:05:11,636
And we're gonna assess the quality of our
intelligence with some quality measure.

77
00:05:11,636 --> 00:05:15,946
And we're gonna use that error or
accuracy, depending which way we're

78
00:05:15,946 --> 00:05:21,046
thinking about measuring it, to adjust our
model parameters using some algorithm.

79
00:05:21,046 --> 00:05:25,820
And we're gonna see this type of flow for
machine learning again and again.

80
00:05:27,030 --> 00:05:29,350
In this module,
we've seen how to take our data and

81
00:05:29,350 --> 00:05:32,240
derive intelligence using
something called regression,

82
00:05:32,240 --> 00:05:36,500
where we have a model that relates
our features to our output.

83
00:05:37,700 --> 00:05:41,840
And we talked about this in the context
of predicting house values, and

84
00:05:41,840 --> 00:05:45,970
you also work through a really
interesting IPython notebook.

85
00:05:45,970 --> 00:05:50,481
And from this, you should be able to
deploy really interesting regression

86
00:05:50,481 --> 00:05:51,992
models in practice now.

87
00:05:51,992 --> 00:05:55,849
[MUSIC]