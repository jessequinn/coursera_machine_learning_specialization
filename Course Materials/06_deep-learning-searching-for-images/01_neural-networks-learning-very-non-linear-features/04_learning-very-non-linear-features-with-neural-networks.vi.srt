1
00:00:00,000 --> 00:00:04,692
[NHẠC]

2
00:00:04,692 --> 00:00:07,416
Vâng chúng ta đã nói về ứng dụng của việc tìm

3
00:00:07,416 --> 00:00:10,850
những đôi giày đẹp hoặc váy chỉ dựa trên các đặc điểm hình ảnh.

4
00:00:10,850 --> 00:00:14,080
Kỹ thuật mà chúng ta sẽ sử dụng hôm nay được gọi là nghiên cứu sâu.

5
00:00:14,080 --> 00:00:17,510
Cụ thể nó dựa trên một cái gọi là mạng thần kinh.

6
00:00:17,510 --> 00:00:21,260
Nhưng trước khi chúng ta hiểu điều này hãy nói về sự đại diện dữ liệu.

7
00:00:21,260 --> 00:00:22,806
Chúng ta đã thảo luận những thứ như là TFIDF và

8
00:00:22,806 --> 00:00:27,650
các mô hình từ, nhưng bạn biểu thị dữ liệu
 như thế nào khi mà nó là hình ảnh?

9
00:00:29,090 --> 00:00:31,910
Điều đó được gọi là các đặc trưng và là phần quan trọng của học máy.

10
00:00:33,050 --> 00:00:37,150
Do đó khi mà bạn nói về học máy, chúng ta sẽ đưa ra một số đầu vào.

11
00:00:37,150 --> 00:00:40,200
Chúng ta đang thực hiện phân loại, chúng ta đã nói về phân tích cảm tính.

12
00:00:40,200 --> 00:00:43,160
Bạn đưa ra một câu nó sẽ đi qua mô hình phân loại và

13
00:00:43,160 --> 00:00:46,780
chúng ta quyết định câu đó là tích cực hay tiêu cực.

14
00:00:46,780 --> 00:00:49,300
Trong phân loại hình ảnh, mục đích là để đi từ hình ảnh,

15
00:00:49,300 --> 00:00:52,990
đây là đầu vào của tôi, các điểm ảnh.

16
00:00:52,990 --> 00:00:55,920
Trong trường hợp này, đây là con chó của tôi
 và tôi muốn phân loại nó là

17
00:00:55,920 --> 00:00:59,660
chó săn Labrador khác với các loài khác.

18
00:00:59,660 --> 00:01:03,070
Chúng ta đã thảo luận, các đặc điểm là đại diện của dữ liệu

19
00:01:03,070 --> 00:01:05,000
mà sử dụng để đưa vào bộ phân loại.

20
00:01:06,060 --> 00:01:08,060
Có rất nhiều các đại diện, ví dụ văn bản

21
00:01:08,060 --> 00:01:11,050
chúng ta đã nói về các từ và TFIDF.

22
00:01:11,050 --> 00:01:13,400
Với những hình ảnh có rất nhiều các đại diện khác.

23
00:01:13,400 --> 00:01:15,270
Chúng ta sẽ thảo luận một vài điều trong bài học này.

24
00:01:16,330 --> 00:01:18,900
Nhưng hôm nay chúng ta sẽ tập trung vào mạng thần kinh,

25
00:01:18,900 --> 00:01:21,820
cái mà cung cấp sự đại diện phi tuyến cho dữ liệu.

26
00:01:23,195 --> 00:01:25,080
Bây giờ hãy quay lại với phân loại.

27
00:01:25,080 --> 00:01:26,850
Hãy cùng nhau xem lại.

28
00:01:26,850 --> 00:01:30,710
Chúng ta thảo luận về các bộ phân loại
 tuyến tính cái mà tạo ra đường này hoặc

29
00:01:30,710 --> 00:01:35,630
ranh giới quyết định tuyến tính giữa lớp tích cực và lớp tiêu cực.

30
00:01:35,630 --> 00:01:39,921
Và ranh giới được biểu thị bằng điểm w0+

31
00:01:39,921 --> 00:01:45,730
w1 x1 x2 và vân vân.

32
00:01:45,730 --> 00:01:50,160
Một mặt , về mặt tích cực điểm lớn hơn 0 và

33
00:01:50,160 --> 00:01:52,690
về mặt tiêu cực thì điểm nhỏ hơn 0.

34
00:01:52,690 --> 00:01:54,920
Nếu tôi có chức năng điểm số tốt này,

35
00:01:54,920 --> 00:01:58,180
tôi có thể phân chia các kết quả tích cực từ các kết quả tiêu cực.

36
00:01:58,180 --> 00:02:02,410
Trong mạng noron chúng ta sẽ biểu thị các bộ phân loại sử dụng graph.

37
00:02:03,530 --> 00:02:08,070
Và ở đây chúng ta có một nút cho mỗi đặc trưng x1, x2, tất cả cách

38
00:02:08,070 --> 00:02:13,730
tới đặc trưng dth, xd và một nút cho đầu ra y, cái mà chúng ta dự đoán.

39
00:02:13,730 --> 00:02:16,950
Đặc điểm đầu tiên x1 được nhân với trọng số w1, vì thế

40
00:02:16,950 --> 00:02:18,700
tôi sẽ đặt trọng số đó bên cạnh.

41
00:02:18,700 --> 00:02:21,870
X2 được nhân với trọng số w2, tôi sẽ đặt nó bên cạnh,

42
00:02:21,870 --> 00:02:26,850
tới xd được nhân với wd đặt cuối cùng.

43
00:02:26,850 --> 00:02:30,970
Và trọng số cuối cùng w0 không được nhân với các đặc trưng nhưng

44
00:02:30,970 --> 00:02:34,900
được nhân với 1, vì thế chúng ta đặt ở trên đầu.

45
00:02:34,900 --> 00:02:40,340
Và nếu bạn giả sử việc nhân w0 qua wd

46
00:02:40,340 --> 00:02:44,850
với x1 qua xd và hệ số 1, bạn sẽ có được điểm.

47
00:02:44,850 --> 00:02:48,400
Khi điểm lớn hơn 0, chúng ta nói đầu ra là 1 và

48
00:02:48,400 --> 00:02:51,550
khi điểm nhỏ hơn 0 chúng ta nói đầu ra là 0.

49
00:02:51,550 --> 00:02:56,650
Đây là một ví dụ nhỏ, một mạng nhỏ.

50
00:02:56,650 --> 00:03:01,470
Chúng ta mô tả bộ phân loại tuyến tính nhỏ như một mạng thần kinh,

51
00:03:01,470 --> 00:03:02,940
như một mạng thần kinh một lớp.

52
00:03:02,940 --> 00:03:05,770
Điều này có thể biểu thị gì?

53
00:03:05,770 --> 00:03:10,620
Hãy dùng chức năng x1 hoặc x2.

54
00:03:10,620 --> 00:03:14,240
Chúng ta có thể biểu thị bằng việc sử dụng
 mạng thân kinh nhỏ này phải không?

55
00:03:14,240 --> 00:03:17,140
Hãy định nghĩa chức năng một chút.

56
00:03:17,140 --> 00:03:22,891
chúng ta có biến x1,

57
00:03:22,891 --> 00:03:26,910
x2 và đầu ra y.

58
00:03:26,910 --> 00:03:28,680
Có một số khả năng.

59
00:03:28,680 --> 00:03:32,998
X1 có thể bằng 0, x2 có thể bằng 0 và khi nó là x1 hoặc x2

60
00:03:32,998 --> 00:03:36,340
thì đầu ra y sẽ là 0.

61
00:03:36,340 --> 00:03:40,272
Khi x1 bằng 1 và x2 bằng 0 thì đầu ra bằng 1.

62
00:03:40,272 --> 00:03:43,360
Khi x1 bằng 0, x2 bằng 1 thì đầu ra bằng 1,

63
00:03:43,360 --> 00:03:47,300
tương tự khi cả hai bằng 1 thì đầu ra bằng 1.

64
00:03:47,300 --> 00:03:54,080
Chúng ta muốn xác định điểm để giá trị lớn hơn

65
00:03:54,080 --> 00:03:59,890
0 cho ba hàng cuối, nhưng nó nhỏ hơn 0 cho hàng đầu tiên.

66
00:03:59,890 --> 00:04:01,390
Vậy làm cách nào để chúng ta làm điều đó? 

67
00:04:01,390 --> 00:04:03,870
Ví dụ có nhiều cách làm nhưng

68
00:04:03,870 --> 00:04:06,020
nếu tôi đặt trọng số 1.

69
00:04:06,020 --> 00:04:11,620
Khi mỗi một cạnh x1 và x2, và chúng ta nghĩ đến điểm, điểm

70
00:04:11,620 --> 00:04:16,830
của hàng đầu tiên bằng 0 và điểm của các hàng khác lớn hơn 0.

71
00:04:16,830 --> 00:04:18,890
Chúng ta muốn thêm sự phân tách, vì thế

72
00:04:18,890 --> 00:04:21,190
chúng ta có thể đặt giá trị âm lên cạnh đầu tiên.

73
00:04:21,190 --> 00:04:26,200
-0.5 và hãy xem điều gì xảy ra với điểm.

74
00:04:26,200 --> 00:04:33,366
Khi x1 bằng 0 và x2 bằng 0 thì điểm là -0.5 và

75
00:04:33,366 --> 00:04:38,460
tôi có điểm nhỏ hơn 0, điểm của tôi đúng, đầu ra của tôi là đúng.

76
00:04:38,460 --> 00:04:44,610
Khi x1 bằng 1 và x2 bằng 0, tôi có điểm là 0.5.

77
00:04:44,610 --> 00:04:48,220
Tương tự khi x1 bằng 0 và x2 bằng 1.

78
00:04:48,220 --> 00:04:52,680
Cuối cùng khi cả hai bằng 1 tôi có điểm là 1.5.

79
00:04:52,680 --> 00:04:58,300
Với các trọng số đơn giản trên các cạnh, tôi biểu thị x1 hoặc x2.

80
00:04:59,470 --> 00:05:02,280
Bây giờ chúng ta có thể biểu thị x1 hoặc x2 chứ?

81
00:05:04,040 --> 00:05:09,560
Tương tự chúng ta có thể đặt trọng số 1 trên cạnh x1 và

82
00:05:09,560 --> 00:05:16,810
x2 nhưng trong trường hợp này chúng ta chỉ muốn
 chuyển đổi khi cả x1 và x2 cùng bằng 1.

83
00:05:16,810 --> 00:05:21,860
Thay vì đặt -0.5 trên đỉnh, chúng ta đặt -1.5.

84
00:05:21,860 --> 00:05:27,830
Nếu bạn điền vào bảng như chúng ta đã làm với ví dụ đầu tiên,

85
00:05:27,830 --> 00:05:31,320
bạn sẽ thấy rằng chúng ta biểu thị x1 và

86
00:05:31,320 --> 00:05:34,190
x2 sử dụng mạng thần kinh đơn giản.

87
00:05:34,190 --> 00:05:38,180
Một mạng thân kinh một lớp về cơ bản giống với

88
00:05:38,180 --> 00:05:43,350
bộ phân loại tuyến tính cơ bản mà chúng ta đã học trong khóa học này.

89
00:05:43,350 --> 00:05:46,280
Một bộ phân loại tuyến tính đơn giản không biểu thị điều gì?

90
00:05:46,280 --> 00:05:49,200
Chúng ta đã nói nó có thể biểu thị x1 hoặc x2.

91
00:05:49,200 --> 00:05:52,020
Nó có thể đại diện x1 và x2 nhưng chức năng là gì,

92
00:05:52,020 --> 00:05:53,700
một chức năng đơn giản không thể biểu thị là gì?

93
00:05:54,710 --> 00:05:56,350
Vâng đây là một ví dụ.

94
00:05:57,350 --> 00:06:00,760
Không có phân cách cộng và trừ trong ví dụ.

95
00:06:00,760 --> 00:06:02,730
Chức năng này được gọi là XOR.

96
00:06:02,730 --> 00:06:05,830
Tôi thích gọi nó là bộ đếm.

97
00:06:05,830 --> 00:06:07,560
Bất cứ khi nào bạn tìm ví dụ bộ đếm,

98
00:06:07,560 --> 00:06:10,220
thứ đầu tiên phải thử là XOR.

99
00:06:10,220 --> 00:06:14,940
Trong trường hợp này các đặc trưng tuyến tính chúng ta đã mô tả không đủ và

100
00:06:14,940 --> 00:06:18,380
chúng ta cần một số các đặc trưng
phi tuyến tính, và đây là khi

101
00:06:18,380 --> 00:06:22,110
bạn dùng mạng và chúng ta sẽ thấy một ví dụ về điều đó.

102
00:06:22,110 --> 00:06:25,040
Hãy cùng xem lại XOR là gì.

103
00:06:25,040 --> 00:06:30,680
XOR có một giá trị khi X1 là đúng và

104
00:06:30,680 --> 00:06:35,300
X2 là sai vì thế không phải x2 hoặc không phải x1,

105
00:06:35,300 --> 00:06:39,000
x1 là sai hoặc 0 và x2 có giá trị 1.

106
00:06:39,000 --> 00:06:43,350
Chúng ta có thể đại diện điều này với mạng nơ ron như thế nào?

107
00:06:43,350 --> 00:06:47,650
Hãy gọi thuật ngữ đầu tiên là z1, thuật ngữ thứ 2 là z2.

108
00:06:49,500 --> 00:06:52,310
Cái mà chúng ta sẽ làm là xây dựng mạng nơ ron để đai diện

109
00:06:52,310 --> 00:06:56,512
không trực tiếp đầu vào x1 và x2 để dự đoán y, nhưng

110
00:06:56,512 --> 00:07:01,660
không dự đoán các giá trị trung gian giữa z1 và z2, sau đó những điều này sẽ dự đoán y.

111
00:07:03,040 --> 00:07:03,920
Hãy lấy z1.

112
00:07:03,920 --> 00:07:09,280
Chúng ta đại diện mạng nơ ron như thế nào, chỉ một mạng nơ ron mà có thể dự đoán z1.

113
00:07:10,560 --> 00:07:14,100
Chúng ta đã thảo luận một chút nhưng ở đây có.

114
00:07:14,100 --> 00:07:17,820
Nó hơi khác một chút so với các trường hợp trước đây.

115
00:07:17,820 --> 00:07:23,480
Bởi vì khi chúng ta phủ nhận, chúng ta nói x2, chúng ta đặt -1 vào cạnh và

116
00:07:23,480 --> 00:07:26,690
chúng ta đặt +1 trên x1 và -0,5 vào đó.

117
00:07:26,690 --> 00:07:28,510
Bây giờ chúng ta có sự đại diện cho z1.

118
00:07:30,050 --> 00:07:35,663
Tương tự với z2, chúng ta đặt kí hiệu trừ trên cạnh x1,

119
00:07:35,663 --> 00:07:42,617
cạnh này ở đây, x1 tới z2, chúng ta đặt +1 trên cạnh x2 tới z2 và

120
00:07:42,617 --> 00:07:49,230
-0,5 tiếp theo, bây giờ nó đại diện z2.

121
00:07:50,430 --> 00:07:55,450
Và bước cuối cùng, nếu z1 tồn tại, tất cả chúng ta phải làm là or chúng.

122
00:07:55,450 --> 00:07:59,810
Và chúng ta đã biết cách để or các biến.

123
00:07:59,810 --> 00:08:03,360
Nó chỉ là 1, -0,5.

124
00:08:03,360 --> 00:08:08,280
Và đây là một khoảng thời gian tuyệt với cho chúng ta.

125
00:08:08,280 --> 00:08:13,160
Bây giờ chúng ta đã xây dựng mạng nơ ron sâu đầu tiên,

126
00:08:13,160 --> 00:08:17,430
không phải siêu sâu, có hai tầng nhưng thú vị.

127
00:08:19,370 --> 00:08:21,360
Chúng ta chỉ xây dựng mạng nơ ron đầu tiên của chúng ta.

128
00:08:21,360 --> 00:08:24,880
Nó có hai tầng mạng nơ ron nhưng nói chung

129
00:08:24,880 --> 00:08:28,050
có các tầng chuyển đổi dữ liệu của chúng ta.

130
00:08:28,050 --> 00:08:30,820
Và chúng ta sử dụng các bộ chuyển đổi để tạo ra các tính năng phi tuyến tính và

131
00:08:30,820 --> 00:08:34,200
chúng ta sẽ thấy một số ví dụ về điều đó trong thao tác máy tính.

132
00:08:34,200 --> 00:08:36,100
Bây giờ mạng nơ ron đã có khoảng

133
00:08:36,100 --> 00:08:40,200
50 năm trước, gần lâu bằng học máy.

134
00:08:40,200 --> 00:08:44,030
Tuy nhiên chúng không được ưu chuộng những năm 90 bởi vì

135
00:08:44,030 --> 00:08:46,890
sự cổ điển có một thời gian khó khăn để có độ chính xác cao trong các mạng nơ ron.

136
00:08:46,890 --> 00:08:49,740
Nhưng mọi thứ thay đổi khoảng 10 năm trước,

137
00:08:49,740 --> 00:08:51,910
bởi vì hai thứ sau.

138
00:08:51,910 --> 00:08:56,650
Đầu tiên nó là nhiều dữ liệu bởi vì mạng nơ ron có quá nhiều, nhiều,

139
00:08:56,650 --> 00:08:58,150
nhiều tầng.

140
00:08:58,150 --> 00:09:01,830
Nhiều tầng bạn cần nhiều dữ liệu có thể huấn luyện tất cả các tầng.

141
00:09:01,830 --> 00:09:02,840
Chúng có nhiều thông số.

142
00:09:04,030 --> 00:09:07,050
Chúng ta sẽ xem mạng nơ ron thú vị với 60 triệu thông số.

143
00:09:07,050 --> 00:09:09,370
Vì thế chúng ta cần nhiều dữ liệu để huấn luyện chúng.

144
00:09:09,370 --> 00:09:12,310
Gần đây chúng ta đã đưa ra nhiều

145
00:09:12,310 --> 00:09:14,830
dữ liệu từ các nguồn khác nhau đặc biệt là web.

146
00:09:15,860 --> 00:09:20,840
Điều thứ hai thay đổi lớn mà tạo ra mạng nơ ron sâu

147
00:09:20,840 --> 00:09:22,940
là sự cải tiến trong các nguồn tính.

148
00:09:22,940 --> 00:09:25,760
Bởi vì chúng ta phải xử lí các mạng nơ ron lớn hơn và nhiều dữ liệu hơn,

149
00:09:25,760 --> 00:09:30,550
chúng ta cần các máy tính nhanh hơn và GPU được thiết kế cho

150
00:09:30,550 --> 00:09:33,070
việc tăng tốc đồ họa cho các trò chơi.

151
00:09:33,070 --> 00:09:37,150
Hóa ra là công cụ chính xác để xây dựng và

152
00:09:37,150 --> 00:09:39,920
sử dụng mạng nơ ron với nhiều dữ liệu.

153
00:09:39,920 --> 00:09:41,570
Bởi vì GPU và

154
00:09:41,570 --> 00:09:44,800
bởi vì mạng nơ ron sâu, mọi thứ đã thay đổi.

155
00:09:44,800 --> 00:09:48,338
Bây giờ chúng ta có nhiều tác động trong thế giới.

156
00:09:48,338 --> 00:09:52,359
[NHẠC]