1
00:00:00,185 --> 00:00:04,747
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:04,747 --> 00:00:08,230
我们已经看到深度神经网络非常酷

3
00:00:08,230 --> 00:00:12,097
并且准确率非常高
但是建模和学习过程可能会非常困难

4
00:00:12,097 --> 00:00:14,640
并且需要大量的数据

5
00:00:14,640 --> 00:00:17,510
所以下一步我们要介绍一些更激动人心的部分

6
00:00:17,510 --> 00:00:21,240
即深度特征 它们能帮助建立神经网络

7
00:00:21,240 --> 00:00:23,690
甚至当你没有很多数据的时候

8
00:00:23,690 --> 00:00:29,340
所以当你回头看我们的数据
图片分类管道

9
00:00:29,340 --> 00:00:35,730
给定一张图片 我们先检测一些特征
或者其他的一些代表性的部分

10
00:00:35,730 --> 00:00:42,220
我们可以使用一些简单的分类器
比如说线性分类器

11
00:00:42,220 --> 00:00:45,280
现在问题是我们能不能

12
00:00:45,280 --> 00:00:48,660
使用那些从神经网络中学习来的特征

13
00:00:48,660 --> 00:00:54,390
即这些位于角落的 边缘的甚至
脸部的特征

14
00:00:55,410 --> 00:00:56,940
所以我们能否从不一样的角度入手？

15
00:00:58,830 --> 00:00:59,720
方法就是

16
00:00:59,720 --> 00:01:03,350
当你已经知道了深度特征 可以使用迁移学习

17
00:01:03,350 --> 00:01:06,940
迁移学习其实是一个很老的方法
提出来已经有些年了

18
00:01:06,940 --> 00:01:12,100
但是对近些年深度神经网络的发展影响很大

19
00:01:12,100 --> 00:01:16,500
具体的思路是 在你拥有很多的数据的时候

20
00:01:16,500 --> 00:01:17,510
训练神经网络

21
00:01:17,510 --> 00:01:21,109
比如 如果我们有一个区分猫和狗的任务

22
00:01:22,110 --> 00:01:27,590
我们训练了一个八层 一千六百万参数的复杂网络

23
00:01:27,590 --> 00:01:31,500
最后我们就得到了一个非常准确的
猫狗分类器

24
00:01:31,500 --> 00:01:35,910
现在假使我们有一个新的任务
而且只有很少量的数据

25
00:01:35,910 --> 00:01:41,080
比方说从上百个不同种类中检测椅子

26
00:01:41,080 --> 00:01:45,150
 大象 汽车还有相机

27
00:01:45,150 --> 00:01:51,420
那我们能不能使用从猫狗神经网络中学习到的特征

28
00:01:51,420 --> 00:01:57,209
再加上一个简单的分类器
来获取一个准确的101-类的分类器呢？

29
00:01:58,620 --> 00:02:00,660
方法就是使用迁移学习

30
00:02:00,660 --> 00:02:06,270
我们在猫狗分类器中学习到的特征能被迁移到

31
00:02:06,270 --> 00:02:10,590
新的任务当中 比如说检测大象 相机等

32
00:02:11,890 --> 00:02:14,730
为了更好的理解迁移学习深度神经网络

33
00:02:14,730 --> 00:02:19,120
让我们更改下之前的深度神经网络学习方法

34
00:02:19,120 --> 00:02:22,270
这是一个猫狗分类深度神经网络

35
00:02:22,270 --> 00:02:25,660
对任务一来说
这个神经网络非常准确

36
00:02:25,660 --> 00:02:27,410
对猫狗分类而言

37
00:02:27,410 --> 00:02:31,970
如果你注意到最后的几层
就会发现它们主要用来进行猫和狗分类

38
00:02:31,970 --> 00:02:33,212
它们的目的非常特定

39
00:02:33,212 --> 00:02:36,295
就像我之前展示的一个例子中

40
00:02:36,295 --> 00:02:37,860
在最后一层中有颜色检测

41
00:02:39,050 --> 00:02:41,510
现在中间的那些层更加一般化

42
00:02:41,510 --> 00:02:45,470
它们可能代表角落 边缘 圆

43
00:02:45,470 --> 00:02:51,310
弯弯曲曲的模式和其他一些真正能从猫和狗分类

44
00:02:51,310 --> 00:02:57,500
推广到101类别分类的特征

45
00:02:57,500 --> 00:03:02,453
所以现在我们介绍一下如何处理第二个任务
即101类别下的分类

46
00:03:02,453 --> 00:03:07,944
我们知道了猫狗分类的深度神经网络可以适用于
任务2

47
00:03:07,944 --> 00:03:09,672
现在 如果你想想看

48
00:03:09,672 --> 00:03:14,005
这个神经网络中的最后一块是专门针对猫和狗的

49
00:03:14,005 --> 00:03:17,429
所以它可能对椅子的检测不是非常有用

50
00:03:17,429 --> 00:03:22,385
所以我们可以去掉最后的一些层
比如最后一层

51
00:03:22,385 --> 00:03:27,287
我们保持前面各层的权重不变

52
00:03:27,287 --> 00:03:30,026
因为它们将会是非常好的特征

53
00:03:30,026 --> 00:03:34,629
运用这些特征再加上一个简单的线性分类器

54
00:03:34,629 --> 00:03:39,149
我们就能用很少的椅子 汽车 大象和相机数据

55
00:03:39,149 --> 00:03:41,507
训练一个模型

56
00:03:44,201 --> 00:03:47,853
回到之前的那个例子

57
00:03:47,853 --> 00:03:49,910
我们有三层

58
00:03:49,910 --> 00:03:53,800
第一层检测对角边和普通边缘

59
00:03:53,800 --> 00:03:57,510
第二层检测弯曲模式和角落

60
00:03:57,510 --> 00:04:01,580
第三层和颜色和脸有关

61
00:04:01,580 --> 00:04:07,030
我们现在能把这些层运用到新的任务中
但是我们需要非常小心

62
00:04:07,030 --> 00:04:11,773
第三层可能太特殊但是第一和第二层会非常有用

63
00:04:11,773 --> 00:04:15,598
所以现在我们了解了迁移学习的理论

64
00:04:15,598 --> 00:04:20,481
现在我们回顾一下使用深度特征的深度学习的流程

65
00:04:20,481 --> 00:04:24,580
我们从一些标注过的数据开始
不需要大量数据 少量数据就够了

66
00:04:24,580 --> 00:04:27,720
然后我们要从深度神经网络中抽取特征

67
00:04:27,720 --> 00:04:30,110
就像之前介绍的

68
00:04:30,110 --> 00:04:35,021
我准备把数据分成两部分 一块作为训练数据
另一块作为验证测试数据

69
00:04:35,021 --> 00:04:38,488
接着我打算训练一个简单的分类器
比如线性分类器

70
00:04:38,488 --> 00:04:41,330
或者支持向量机等一些简单的模型

71
00:04:41,330 --> 00:04:45,670
就像我之前证实的
因为我们选用的分类器非常简单

72
00:04:45,670 --> 00:04:47,900
并不需要调整很多参数

73
00:04:47,900 --> 00:04:49,100
非常简单

74
00:04:49,100 --> 00:04:51,840
很容易用少量数据完成训练并且效果很好

75
00:04:52,920 --> 00:04:56,570
事实上 我们可以看到一个具体的应用
这个应用性能很好

76
00:04:56,570 --> 00:05:00,830
而这个应用正是使用了我们介绍的方法

77
00:05:00,830 --> 00:05:04,970
这个应用位于这一单元的开始
在我给你们展示如何购买新衣服的时候

78
00:05:04,970 --> 00:05:10,020
我们没有很多关于衣服的视觉描述数据

79
00:05:10,020 --> 00:05:16,940
但是我们使用了一些葱imagenet中抽取的特征
来提供给用户良好的购物体验

80
00:05:18,030 --> 00:05:22,550
现在你可能会问这些深度特征有多普遍?

81
00:05:22,550 --> 00:05:27,540
它们真的能用于一些有趣的而且极度不寻常的任务么?

82
00:05:28,780 --> 00:05:30,540
它们普遍可能会让你震惊

83
00:05:31,750 --> 00:05:33,345
事实上 比如说垃圾回收

84
00:05:33,345 --> 00:05:36,530
有一家叫compology的公司

85
00:05:36,530 --> 00:05:38,190
非常有意思

86
00:05:38,190 --> 00:05:43,540
他们试图重新定义垃圾回收

87
00:05:43,540 --> 00:05:48,570
一般情况下 垃圾车挨个回收各个房子和商店
的垃圾

88
00:05:48,570 --> 00:05:51,780
每天或者每周一次

89
00:05:52,830 --> 00:05:56,690
他们想要做出一些改变 优化垃圾车的路径

90
00:05:56,690 --> 00:06:00,930
他们试图将垃圾回收所用的时间降到最低

91
00:06:00,930 --> 00:06:04,100
他们的方法是在垃圾车上安装相机

92
00:06:04,100 --> 00:06:06,540
目的是检测垃圾的种类和数量

93
00:06:06,540 --> 00:06:14,480
显然我们并没有大量的关于很满的垃圾桶的标注数据

94
00:06:14,480 --> 00:06:19,480
他们在做这个的时候借助于深度特征
和一些少量的人工标注数据

95
00:06:19,480 --> 00:06:24,780
然后训练出了一个垃圾检测器

96
00:06:24,780 --> 00:06:29,877
然后能够优化垃圾车的路径 更好的提供服务

97
00:06:29,877 --> 00:06:36,650
而且降低了卡车收集垃圾所需的时间

98
00:06:36,650 --> 00:06:38,823
所以深度特征非常有用
甚至对垃圾回收来说

99
00:06:38,823 --> 00:06:44,399
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community