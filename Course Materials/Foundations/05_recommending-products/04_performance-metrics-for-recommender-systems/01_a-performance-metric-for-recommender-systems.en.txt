[MUSIC] So we've talked at great length about how
to form predictions using different types of recommender systems. But a question is, how do we assess
the difference in performance for these different systems
we might consider using? Well imagine we want to recommend
products to a new parent, and this is the set of all possible
products that we might recommend. And a user likes a subset of these
products which are represented by these magenta squares. And our goal, of course, is to discover
the products that the user likes from the purchases that they've made. Because we don't actually know which
products they like, that's our goal, okay? So a question is, why don't we just use
something like classification accuracy to measure the performance
of a recommender system? So in this case, we could think about
just counting how many items we guessed that they liked
versus they did not like and compare that to how many of those items
they actually liked versus did not like. So Carlos talked about
using that type of metric when he was talking about
the sentiment analysis case study. But the issue here is actually multifold. One is the fact that we really
care more about what the person liked than what they didn't like and often
we're faced with very imbalanced classes. So, for example, there are lots and
lots and lots of products out there, but typically a user's only gonna
like a very small subset of them. And so if we use this type of metric,
we can get very good accuracy by just saying that the user
won't like any of the items. So not recommending anything will get pretty good performance
according to this metric. But another issue is something else which relates to the cost of making
these different decisions. So often we're gonna assume that
the user has a limited attention span, and so we can only recommend a certain
number of items for that user to look at. So there is a much larger cost
if out of this very small set of items we're allowed to recommend
to this person there's no liked item. That has a much higher cost than if we
missed some of the user's liked items in this set of recommended products. So instead,
we're gonna talk about a different metric, or different metrics which
are called precision and recall. Let's start by discussing recall. So for a given a recommender system, it's
gonna recommend some set of products to me, and I'm highlighting those
by the colored pictures. So this is a recommended item. This is a recommended item,
this is a recommended item and so on. Where as the grayed out pictures are items
that were not recommended for me. Okay, so I haven't done
a comprehensive annotation here, but hopefully you get the picture. And when I'm measuring recall, what I'm gonna look at is I'm gonna
look at all the items I liked. So all of these magenta boxes. And I'm gonna ask how many of the items that I liked were
actually recommended to me. And so I'm gonna compute that fraction,
so let's do that. So each of the magenta boxes, so
here's one that was recommended to me. Two that were recommended to me, three that were recommended to me
out of five items that I like. So the recall, is three-fifths. And so recall is gonna measure how
much a recommended set of items cover the things that I'm interested in,
things that I actually like. On the other hand,
there's something called precision. When we talk about precision
what we're gonna look at is all of the recommended items. So when we're talking about recall
our world when we were measuring this fraction here was
looking at the magenta boxes. That was the world that we looked at
everything else could disappear from the slide. But when we are talking about precision,
we're gonna look at all the recommended items and then everything else
can disappear from the slide. So the recommended items
are highlighted by these green boxes. What we are going to look at out of the
recommended items if that is our entire world What fraction of those
items were items that I liked? Okay, so in this case there are one, two, three items that I liked and
were shown and a total of 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11 items that were shown. So this would be the precision. And so when we're thinking about precision
we're thinking about basically how much garbage do I have to look at compared
to the number of items that I like. So, it's a measure of when I
have a limited attention span, how much am I gonna be wasting my
efforts on products that I do not like? [MUSIC]