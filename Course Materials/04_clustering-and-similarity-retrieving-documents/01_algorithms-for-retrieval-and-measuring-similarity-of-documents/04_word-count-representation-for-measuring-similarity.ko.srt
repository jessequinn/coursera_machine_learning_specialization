1
00:00:00,000 --> 00:00:03,754
[음악]

2
00:00:03,754 --> 00:00:07,691
우선 문서를 어떻게 표현하는지

3
00:00:07,691 --> 00:00:08,937
설명드리겠습니다

4
00:00:08,937 --> 00:00:12,771
아마 문서 표현에 가장 인기있는 방법은

5
00:00:12,771 --> 00:00:13,851
bag-of-words(단어주머니) 모델인데

6
00:00:13,851 --> 00:00:17,670
문서에서 단어 순서를 무시하는 방식입니다

7
00:00:17,670 --> 00:00:20,870
bag-of-words 모델이라 불리는 이유는

8
00:00:20,870 --> 00:00:24,940
주머니에다 문서의 모든 단어를 쓸어넣고

9
00:00:24,940 --> 00:00:28,350
뒤섞은 다음 새로운 문서를 만들어도

10
00:00:28,350 --> 00:00:31,540
원 문서에서 순서대로 정리된 단어와

11
00:00:31,540 --> 00:00:34,630
정확히 같은 표현이 되기 때문이죠

12
00:00:36,800 --> 00:00:40,540
다음으로 단어 순서 같은 구조를

13
00:00:40,540 --> 00:00:41,380
고려하기보다 문서에 등장하는

14
00:00:41,380 --> 00:00:46,400
모든 단어의 등장 빈도를 셉니다

15
00:00:46,400 --> 00:00:49,060
구체적인 예를 한번 들어보죠

16
00:00:49,060 --> 00:00:53,290
이 문서에서 문장 하나만 있다고 가정하고

17
00:00:53,290 --> 00:00:58,820
문장은 Carlos calls the sport futbol,
Emily calls the sport soccer입니다

18
00:01:00,650 --> 00:01:06,050
실제로는 두 문장 같지만 아무튼 이게 문서 전체입니다

19
00:01:06,050 --> 00:01:09,010
이제 이 짧은 문서에서

20
00:01:09,010 --> 00:01:13,170
단어 빈도를 세서 벡터로 만듭니다

21
00:01:13,170 --> 00:01:17,160
벡터는 대상 언어의

22
00:01:17,160 --> 00:01:19,310
사전으로 정의됩니다

23
00:01:19,310 --> 00:01:24,280
사전에서 단어 하나는 이름인 Carlos일지도 모르죠

24
00:01:25,320 --> 00:01:30,540
벡터에는 sport란 단어의 인덱스도 어딘가 있을 겁니다

25
00:01:32,600 --> 00:01:38,170
And then, somewhere else we have the word
futbol luckily in our English vocabulary
운좋게도 futbol이란 단어가 영어 사전에 있고

26
00:01:38,170 --> 00:01:44,710
Emily가 마지막 항목이라고 하죠

27
00:01:44,710 --> 00:01:45,740
어떤 단어가 빠졌죠?

28
00:01:45,740 --> 00:01:50,450
calls와 the가 빠졌죠

29
00:01:51,840 --> 00:01:53,856
Carlos가 몇 개 있죠?

30
00:01:53,856 --> 00:01:55,480
하나밖에 없죠

31
00:01:55,480 --> 00:01:57,403
the가 몇 개 있죠?

32
00:01:57,403 --> 00:02:00,060
the는 두 개 있죠

33
00:02:00,060 --> 00:02:03,671
calls 두 개, sport 두 개

34
00:02:03,671 --> 00:02:09,320
futbol 하나, 그리고 soccer를 잊었는데 하나죠

35
00:02:09,320 --> 00:02:13,740
Emily 하나, 여기서 soccer를 넣고

36
00:02:13,740 --> 00:02:18,740
이게 인덱스라 가정하면 단어수 벡터는 이런 모습이겠죠

37
00:02:20,200 --> 00:02:23,440
문서에서 다른 모든 항목은 0이 됩니다

38
00:02:24,440 --> 00:02:28,370
다른 항목은 고양이, 개, 나무처럼

39
00:02:28,370 --> 00:02:32,401
사전에는 있지만 문서에 등장하지 않는

40
00:02:32,401 --> 00:02:37,280
단어를 나타냅니다

41
00:02:38,400 --> 00:02:39,850
등장하는 단어수를 세는

42
00:02:39,850 --> 00:02:45,220
아주아주 커다란 희소벡터입니다

43
00:02:45,220 --> 00:02:48,976
단어수만으로 문서를 표현하는 방법을

44
00:02:48,976 --> 00:02:50,613
알아봤습니다

45
00:02:50,613 --> 00:02:51,965
bag-of-words 모델입니다

46
00:02:51,965 --> 00:02:55,659
여러 문서 사이의 유사도를 측정하는 법을

47
00:02:55,659 --> 00:02:58,892
알아볼 텐데 문서가 서로 얼마나 연관되어 있나

48
00:02:58,892 --> 00:03:02,890
알기 위해 필요하기 때문입니다

49
00:03:02,890 --> 00:03:07,430
카를로스가 기사를 읽는데 그가 관심을 가질만한
기사가 어떤 게 있을까요?

50
00:03:07,430 --> 00:03:12,250
이게 축구와 유명 아르헨티나 선수

51
00:03:12,250 --> 00:03:18,290
메시에 대한 기사의 카운트 벡터라고 할게요

52
00:03:18,290 --> 00:03:22,410
파란색을 칠한 또 다른 기사와

53
00:03:22,410 --> 00:03:24,227
그에 딸린 단어수입니다

54
00:03:24,227 --> 00:03:29,826
이 기사는 또 다른 유명 축구선수 펠레에 관한 것입니다

55
00:03:29,826 --> 00:03:32,954
발음이 맞나요?

56
00:03:32,954 --> 00:03:33,895
>> 펠레
>> 펠레

57
00:03:33,895 --> 00:03:38,921
[웃음] 유사도를 측정할 때

58
00:03:38,921 --> 00:03:46,130
벡터의 스칼라곱을 계산합니다

59
00:03:46,130 --> 00:03:49,260
벡터의 모든 항에 대해

60
00:03:49,260 --> 00:03:53,900
두 단어수 벡터 각각의 항을 곱합니다

61
00:03:53,900 --> 00:03:57,490
그리고 전체를 더합니다

62
00:03:57,490 --> 00:04:01,527
이렇게 계산하면 1 곱하기 3,

63
00:04:01,527 --> 00:04:04,667
다른 항들은 곱하면 0이 되고

64
00:04:04,667 --> 00:04:10,410
5번째 항에 5 곱하기 2가 있습니다

65
00:04:10,410 --> 00:04:12,910
벡터 전체에 곱셈을 하면

66
00:04:12,910 --> 00:04:15,360
모든 항의 합은 13이 됩니다

67
00:04:15,360 --> 00:04:19,470
축구 기사 둘 사이의 유사도를 측정해봤습니다

68
00:04:20,690 --> 00:04:22,880
이제 다른 기사와 비교할 건데

69
00:04:22,880 --> 00:04:27,540
아프리카의 분쟁이 주제입니다

70
00:04:27,540 --> 00:04:32,620
이 기사에 등장하는 단어수를 예를 들어볼게요

71
00:04:32,620 --> 00:04:36,360
이 기사 간의 유사도 측정법인 스칼라곱으로

72
00:04:36,360 --> 00:04:39,780
곱하고 더하면 유사도는

73
00:04:39,780 --> 00:04:43,880
이 경우 0이 됩니다

74
00:04:43,880 --> 00:04:47,170
단어수로 문서 간의 유사도를

75
00:04:47,170 --> 00:04:50,709
측정할 때 나타나는 문제를 알아보죠

76
00:04:51,810 --> 00:04:55,700
그러기 위해 초록, 파란 기사를 다시 봅니다

77
00:04:55,700 --> 00:04:58,700
단어수 벡터와 계산으로 돌아가보면

78
00:04:58,700 --> 00:05:02,350
똑같이 축구가 주제인 두 기사 간의 유사도는

79
00:05:02,350 --> 00:05:05,820
13으로 나옵니다

80
00:05:05,820 --> 00:05:06,750
그러면

81
00:05:06,750 --> 00:05:10,570
문서 길이를 두 배로 늘릴 때 어떻게 되나 보죠

82
00:05:10,570 --> 00:05:15,360
원 문서에서 등장하는 모든 단어는

83
00:05:15,360 --> 00:05:17,760
새 문서에서 빈도가 두 배가 됩니다

84
00:05:17,760 --> 00:05:23,380
단어수 벡터는 간단히 원래 벡터의 2배가 되죠

85
00:05:23,380 --> 00:05:26,826
이렇게 유사도를 다시 계산하면

86
00:05:26,826 --> 00:05:30,858
유사도는 이제 52로 나옵니다

87
00:05:30,858 --> 00:05:31,580
생각해봅시다

88
00:05:31,580 --> 00:05:35,258
두 문서의 관계는 이전과

89
00:05:35,258 --> 00:05:39,435
동일합니다

90
00:05:39,435 --> 00:05:44,117
같은 스포츠가 주제인데

91
00:05:44,117 --> 00:05:48,601
길이가 두 배라고 더 유사하답니다

92
00:05:48,601 --> 00:05:53,880
카를로스가 긴 문서에 관심 있다고 결론 내릴 수 있겠네요

93
00:05:53,880 --> 00:05:59,120
카를로스가 짧은 문서를 읽고 있었다면 어떻게 되나요

94
00:05:59,120 --> 00:06:02,870
문서 검색에서 그다지 타당한 방법이 아닙니다

95
00:06:02,870 --> 00:06:07,110
긴 문서에 심하게 편향되니까요

96
00:06:07,110 --> 00:06:09,920
이걸 어떻게 극복할지 고민해봅시다

97
00:06:09,920 --> 00:06:10,950
한 가지 방법은

98
00:06:12,370 --> 00:06:15,540
아주 간단하게 벡터를 정규화하는 것이죠

99
00:06:15,540 --> 00:06:17,740
단어수 벡터에서 노름(norm)을

100
00:06:17,740 --> 00:06:19,910
계산해냅니다

101
00:06:19,910 --> 00:06:23,560
벡터 노름 계산을 하려면

102
00:06:23,560 --> 00:06:29,670
모든 항을 제곱해서 더한 다음 다시 제곱근을 씌우죠

103
00:06:29,670 --> 00:06:30,624
이 경우

104
00:06:30,624 --> 00:06:35,420
1 제곱 더하기 5 제곱 더하기 3 제곱 더하기 1 제곱에
제곱근을 씌웁니다

105
00:06:35,420 --> 00:06:38,730
그러면 6이란 숫자가 나오는데

106
00:06:38,730 --> 00:06:44,180
정규화된 단어수 벡터가 슬라이드 밑 부분에 나옵니다

107
00:06:44,180 --> 00:06:48,210
모든 대상 기사에 대해 길이와 관계없이

108
00:06:48,210 --> 00:06:51,733
동등한 위치를 부여하게 됩니다

109
00:06:51,733 --> 00:06:55,280
그런 다음 정규화된 벡터로 검색을 하는 것이죠

110
00:06:55,280 --> 00:06:57,189
[음악]