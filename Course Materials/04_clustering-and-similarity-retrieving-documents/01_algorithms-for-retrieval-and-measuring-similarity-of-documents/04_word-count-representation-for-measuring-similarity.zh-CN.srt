1
00:00:00,000 --> 00:00:03,754
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:03,754 --> 00:00:07,691
首先我们需要讨论如何表示

3
00:00:07,691 --> 00:00:08,937
我们要考虑的文档

4
00:00:08,937 --> 00:00:12,771
也许最流行的一种来表示文档的模型是

5
00:00:12,771 --> 00:00:13,851
词袋模型

6
00:00:13,851 --> 00:00:17,670
这个模型忽略了文档中单词的顺序信息

7
00:00:17,670 --> 00:00:20,870
之所以这个模型被成为词袋模型
假设我们拿一个口袋

8
00:00:20,870 --> 00:00:24,940
把文档里所有的单词扔进这个口袋 摇一摇

9
00:00:24,940 --> 00:00:28,350
这样把所有单词都打乱了顺序而生成的文档

10
00:00:28,350 --> 00:00:31,540
跟单词有序的原始文档在词袋模型里对应的表示

11
00:00:31,540 --> 00:00:34,630
是完全一样的

12
00:00:36,800 --> 00:00:40,540
与其考虑文档的结构

13
00:00:40,540 --> 00:00:41,380
或是单词的顺序

14
00:00:41,380 --> 00:00:46,400
我们要做的仅仅是计算
每个单词在文档中出现的次数

15
00:00:46,400 --> 00:00:49,060
我们来看一个具体的例子

16
00:00:49,060 --> 00:00:53,290
假设这个文档只包含一句话

17
00:00:53,290 --> 00:00:58,820
这句话说的是Carlos称足球为futbol
Emily称足球为soccer

18
00:01:00,650 --> 00:01:06,050
我猜这应该算两个句子 
它们构成这个文档的全部内容

19
00:01:06,050 --> 00:01:09,010
为了计算每个单词在文档中出现的次数

20
00:01:09,010 --> 00:01:13,170
我们考虑一个向量

21
00:01:13,170 --> 00:01:17,160
这个向量定义在我们所考虑的语言的

22
00:01:17,160 --> 00:01:19,310
词汇表中

23
00:01:19,310 --> 00:01:24,280
也许词汇表中有个单词是名字Carlos

24
00:01:25,320 --> 00:01:30,540
向量中的另一个位置是单词sport(运动）

25
00:01:32,600 --> 00:01:38,170
某个位置是单词futbol （足球）
假设很幸运这个单词在我写的这个英语词汇表里

26
00:01:38,170 --> 00:01:44,710
Emily在最后一个位置

27
00:01:44,710 --> 00:01:45,740
还差哪个单词?

28
00:01:45,740 --> 00:01:50,450
还漏掉了单词calls 和单词the

29
00:01:51,840 --> 00:01:53,856
好了 所以Carlos出现了几次？

30
00:01:53,856 --> 00:01:55,480
只有一次

31
00:01:55,480 --> 00:01:57,403
单词the出现了几次呢?

32
00:01:57,403 --> 00:02:00,060
我们有两个the

33
00:02:00,060 --> 00:02:03,671
两个calls 两个sport

34
00:02:03,671 --> 00:02:09,320
一个futbol 我漏写了单词soccer

35
00:02:09,320 --> 00:02:13,740
Emily一次 让我们把单词soccer放在这里

36
00:02:13,740 --> 00:02:18,740
假设这就是单词索引 这个是单词统计向量

37
00:02:20,200 --> 00:02:23,440
对这个文档来说 其他位置都是0

38
00:02:24,440 --> 00:02:28,370
其他的这些位置对应其他所有在词汇表里的单词

39
00:02:28,370 --> 00:02:32,401
比如单词cat

40
00:02:32,401 --> 00:02:37,280
单词dog tree 以及任何你能想到的单词

41
00:02:38,400 --> 00:02:39,850
所以这是一个很长很长的

42
00:02:39,850 --> 00:02:45,220
用来表示单词在文档中出现次数的稀疏向量

43
00:02:45,220 --> 00:02:48,976
好了 刚刚我们讨论了仅用单词统计来

44
00:02:48,976 --> 00:02:50,613
表示文档

45
00:02:50,613 --> 00:02:51,965
也就是词袋模型

46
00:02:51,965 --> 00:02:55,659
现在我们要讨论怎样度量不同文档的相似度

47
00:02:55,659 --> 00:02:58,892
因为我们将用这个度量来找到

48
00:02:58,892 --> 00:03:02,890
与某个文档相关的文档等等 像我们之前讨论过的那样

49
00:03:02,890 --> 00:03:07,430
假设Carlos正在阅读一篇文章
其他他可能感兴趣的文章有哪些呢?

50
00:03:07,430 --> 00:03:12,250
假设对这篇关于足球的文章 我们有一个对

51
00:03:12,250 --> 00:03:18,290
阿根廷著名球星梅西（Messi）的名字的计数

52
00:03:18,290 --> 00:03:22,410
假设有另一篇文章 在这里显示成蓝色

53
00:03:22,410 --> 00:03:24,227
和对应的单词统计

54
00:03:24,227 --> 00:03:29,826
这篇文章是关于另一著名球星贝利（Pele）

55
00:03:29,826 --> 00:03:32,954
是这样发音吗?

56
00:03:32,954 --> 00:03:33,895
Pele
Pele

57
00:03:33,895 --> 00:03:38,921
[笑声] 所以若我们想要度量相似度

58
00:03:38,921 --> 00:03:46,130
可以简单地计算这两个向量的点乘

59
00:03:46,130 --> 00:03:49,260
也就是说对向量中的每一个元素

60
00:03:49,260 --> 00:03:53,900
我们计算两个单词统计向量对应位置的元素乘积

61
00:03:53,900 --> 00:03:57,490
再把所有乘积相加

62
00:03:57,490 --> 00:04:01,527
这里我写出了计算式子 有1乘以3

63
00:04:01,527 --> 00:04:04,667
其他位置元素相乘都是0

64
00:04:04,667 --> 00:04:10,410
除了第5个位置是5乘以2

65
00:04:10,410 --> 00:04:12,910
如果就这样将所有位置元素相乘

66
00:04:12,910 --> 00:04:15,360
再求和得到13

67
00:04:15,360 --> 00:04:19,470
这个数量化了这两篇关于足球的文章的相似度

68
00:04:20,690 --> 00:04:22,880
但现在再来跟另一篇文章比较

69
00:04:22,880 --> 00:04:27,540
这篇文章恰好是关于非洲某个冲突事件

70
00:04:27,540 --> 00:04:32,620
这里我写出了这篇文章对应的单词统计向量

71
00:04:32,620 --> 00:04:36,360
我们看到 当我们用之前向量点乘方法

72
00:04:36,360 --> 00:04:39,780
来计算这两篇文章相似度时

73
00:04:39,780 --> 00:04:43,880
得到相似度为0

74
00:04:43,880 --> 00:04:47,170
接下来我们说说这种

75
00:04:47,170 --> 00:04:50,709
用单词统计度量文章相似度的方法的问题

76
00:04:51,810 --> 00:04:55,700
为了说明 
让我们看看之前看过的这两篇绿色和蓝色的文章

77
00:04:55,700 --> 00:04:58,700
我再重复一下这两个单词统计向量

78
00:04:58,700 --> 00:05:02,350
和我们之前计算的这两篇关于足球文章的

79
00:05:02,350 --> 00:05:05,820
相似度为13

80
00:05:05,820 --> 00:05:06,750
好了

81
00:05:06,750 --> 00:05:10,570
但是现在我们看看 
如果将文档复制成两倍长度将会发生什么

82
00:05:10,570 --> 00:05:15,360
所以原文档的每个单词

83
00:05:15,360 --> 00:05:17,760
在这个两倍长文档都出现两次

84
00:05:17,760 --> 00:05:23,380
所以新的单词统计向量变成2乘以原向量

85
00:05:23,380 --> 00:05:26,826
所以当我们再次计算相似度时

86
00:05:26,826 --> 00:05:30,858
这两个两倍长文档的相似度是52

87
00:05:30,858 --> 00:05:31,580
现在我们来想一想

88
00:05:31,580 --> 00:05:35,258
我们刚刚说的是 这两篇文章的

89
00:05:35,258 --> 00:05:39,435
内容上的联系如之前一样

90
00:05:39,435 --> 00:05:44,117
它们都讲的是足球运动

91
00:05:44,117 --> 00:05:48,601
但若把每篇文章复制成两倍长度 它们就更相似

92
00:05:48,601 --> 00:05:53,880
我们说 确实 Carlos对这篇两倍长文章更感兴趣

93
00:05:53,880 --> 00:05:59,120
那么当Carlos在读短的文章时会发生什么

94
00:05:59,120 --> 00:06:02,870
这在我们做文章检索时并不太说得通

95
00:06:02,870 --> 00:06:07,110
这种方法更倾向于长的文章

96
00:06:07,110 --> 00:06:09,920
现在让我们想想如何解决这个问题

97
00:06:09,920 --> 00:06:10,950
一种直接了当的办法是

98
00:06:12,370 --> 00:06:15,540
归一化这个向量

99
00:06:15,540 --> 00:06:17,740
所以我们用这个单词统计向量

100
00:06:17,740 --> 00:06:19,910
计算向量的范数

101
00:06:19,910 --> 00:06:23,560
如果你还记得如何计算向量的范数

102
00:06:23,560 --> 00:06:29,670
只需要计算向量中元素的平方的总和 然后取其平方根

103
00:06:29,670 --> 00:06:30,624
举个例子举个例子

104
00:06:30,624 --> 00:06:35,420
这里我们有1的平方加上5的平方加上3的平方
加上1的平方的平方根

105
00:06:35,420 --> 00:06:38,730
最后计算结果是6

106
00:06:38,730 --> 00:06:44,180
得到的归一化后的向量显示在屏幕下方

107
00:06:44,180 --> 00:06:48,210
这种处理 使得我们可以将所有的

108
00:06:48,210 --> 00:06:51,733
不同长度的文章 置于平等地位

109
00:06:51,733 --> 00:06:55,280
接着 在检索中使用归一化后的向量

110
00:06:55,280 --> 00:06:57,189
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community