[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community 首先我们需要讨论如何表示 我们要考虑的文档 也许最流行的一种来表示文档的模型是 词袋模型 这个模型忽略了文档中单词的顺序信息 之所以这个模型被成为词袋模型
假设我们拿一个口袋 把文档里所有的单词扔进这个口袋 摇一摇 这样把所有单词都打乱了顺序而生成的文档 跟单词有序的原始文档在词袋模型里对应的表示 是完全一样的 与其考虑文档的结构 或是单词的顺序 我们要做的仅仅是计算
每个单词在文档中出现的次数 我们来看一个具体的例子 假设这个文档只包含一句话 这句话说的是Carlos称足球为futbol
Emily称足球为soccer 我猜这应该算两个句子 
它们构成这个文档的全部内容 为了计算每个单词在文档中出现的次数 我们考虑一个向量 这个向量定义在我们所考虑的语言的 词汇表中 也许词汇表中有个单词是名字Carlos 向量中的另一个位置是单词sport(运动） 某个位置是单词futbol （足球）
假设很幸运这个单词在我写的这个英语词汇表里 Emily在最后一个位置 还差哪个单词? 还漏掉了单词calls 和单词the 好了 所以Carlos出现了几次？ 只有一次 单词the出现了几次呢? 我们有两个the 两个calls 两个sport 一个futbol 我漏写了单词soccer Emily一次 让我们把单词soccer放在这里 假设这就是单词索引 这个是单词统计向量 对这个文档来说 其他位置都是0 其他的这些位置对应其他所有在词汇表里的单词 比如单词cat 单词dog tree 以及任何你能想到的单词 所以这是一个很长很长的 用来表示单词在文档中出现次数的稀疏向量 好了 刚刚我们讨论了仅用单词统计来 表示文档 也就是词袋模型 现在我们要讨论怎样度量不同文档的相似度 因为我们将用这个度量来找到 与某个文档相关的文档等等 像我们之前讨论过的那样 假设Carlos正在阅读一篇文章
其他他可能感兴趣的文章有哪些呢? 假设对这篇关于足球的文章 我们有一个对 阿根廷著名球星梅西（Messi）的名字的计数 假设有另一篇文章 在这里显示成蓝色 和对应的单词统计 这篇文章是关于另一著名球星贝利（Pele） 是这样发音吗? Pele
Pele [笑声] 所以若我们想要度量相似度 可以简单地计算这两个向量的点乘 也就是说对向量中的每一个元素 我们计算两个单词统计向量对应位置的元素乘积 再把所有乘积相加 这里我写出了计算式子 有1乘以3 其他位置元素相乘都是0 除了第5个位置是5乘以2 如果就这样将所有位置元素相乘 再求和得到13 这个数量化了这两篇关于足球的文章的相似度 但现在再来跟另一篇文章比较 这篇文章恰好是关于非洲某个冲突事件 这里我写出了这篇文章对应的单词统计向量 我们看到 当我们用之前向量点乘方法 来计算这两篇文章相似度时 得到相似度为0 接下来我们说说这种 用单词统计度量文章相似度的方法的问题 为了说明 
让我们看看之前看过的这两篇绿色和蓝色的文章 我再重复一下这两个单词统计向量 和我们之前计算的这两篇关于足球文章的 相似度为13 好了 但是现在我们看看 
如果将文档复制成两倍长度将会发生什么 所以原文档的每个单词 在这个两倍长文档都出现两次 所以新的单词统计向量变成2乘以原向量 所以当我们再次计算相似度时 这两个两倍长文档的相似度是52 现在我们来想一想 我们刚刚说的是 这两篇文章的 内容上的联系如之前一样 它们都讲的是足球运动 但若把每篇文章复制成两倍长度 它们就更相似 我们说 确实 Carlos对这篇两倍长文章更感兴趣 那么当Carlos在读短的文章时会发生什么 这在我们做文章检索时并不太说得通 这种方法更倾向于长的文章 现在让我们想想如何解决这个问题 一种直接了当的办法是 归一化这个向量 所以我们用这个单词统计向量 计算向量的范数 如果你还记得如何计算向量的范数 只需要计算向量中元素的平方的总和 然后取其平方根 举个例子举个例子 这里我们有1的平方加上5的平方加上3的平方
加上1的平方的平方根 最后计算结果是6 得到的归一化后的向量显示在屏幕下方 这种处理 使得我们可以将所有的 不同长度的文章 置于平等地位 接着 在检索中使用归一化后的向量 [背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community