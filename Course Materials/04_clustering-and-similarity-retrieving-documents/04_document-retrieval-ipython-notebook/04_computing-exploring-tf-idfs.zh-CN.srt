1
00:00:00,000 --> 00:00:04,128
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:04,128 --> 00:00:08,040
让我们真正着手计算TF/IDF

3
00:00:08,040 --> 00:00:11,760
现在 我无法只计算TF/IDF
顺便提一下 这是一个重要的注意点

4
00:00:11,760 --> 00:00:13,190
我们没法单独计算

5
00:00:13,190 --> 00:00:18,560
奥巴马文章的TF/IDF 是因为TF/IDF 取决于整个文集

6
00:00:18,560 --> 00:00:21,750
你需要把那些出现在每篇文章中的单词标准化

7
00:00:21,750 --> 00:00:22,780
你需要把那些出现在每篇文章中的单词标准化

8
00:00:22,780 --> 00:00:25,620
我证明给你看 我已经在整个文集中计算过了

9
00:00:25,620 --> 00:00:29,087
现在让我们开始做这个吧

10
00:00:29,087 --> 00:00:33,302
开始吧！

11
00:00:33,302 --> 00:00:38,124
我会计算

12
00:00:38,124 --> 00:00:44,462
整个文集的TF-IDF

13
00:00:44,462 --> 00:00:46,320
我会分两步来做

14
00:00:47,660 --> 00:00:51,712
首先我要计算整个文集中 各个单词的数量

15
00:00:51,712 --> 00:00:57,330
所以我在people 中添加一列叫做单词计数(word_count)

16
00:00:57,330 --> 00:01:01,660
我们之前对奥巴马做过类似的 现在我们要对所有人做这个

17
00:01:01,660 --> 00:01:02,160
我们之前对奥巴马做过类似的 现在我们要对所有人做这个

18
00:01:02,160 --> 00:01:10,494
所以我要调出graphlab.text_analytics.count_words 这个函数

19
00:01:10,494 --> 00:01:14,304
然后写下输入值

20
00:01:14,304 --> 00:01:18,837
输入值会是text这一列

21
00:01:18,837 --> 00:01:22,370
换句话说 我会对text 这一列的进行单词计数

22
00:01:23,500 --> 00:01:25,750
为了以防混淆

23
00:01:25,750 --> 00:01:31,010
我们直接打印出people

24
00:01:31,010 --> 00:01:33,780
所以我会打印出people的前几列

25
00:01:33,780 --> 00:01:35,430
恩 我们执行了代码

26
00:01:35,430 --> 00:01:40,634
你看到我们有URI 也就是网页地址这一列  人物的名字

27
00:01:40,634 --> 00:01:46,254
然后在最右边 有单词计数这一列 新的一列

28
00:01:46,254 --> 00:01:50,860
好的 下一步我们就要计算TF/IDF了

29
00:01:50,860 --> 00:01:55,364
就像单词计数一样 你要使用你自己的TF/IDF 系统

30
00:01:55,364 --> 00:01:57,588
会让你花上一些时间完成

31
00:01:57,588 --> 00:02:01,086
Graphlocate已经准备就绪了

32
00:02:01,086 --> 00:02:05,949
我们准备使用这个来让整个过程变得简单一些

33
00:02:05,949 --> 00:02:09,730
所以我会调用graphlab.text_analytics这个函数

34
00:02:09,730 --> 00:02:14,820
就像之前调用单词计数一样

35
00:02:14,820 --> 00:02:17,450
你要做的就是 需要一个输入值

36
00:02:17,450 --> 00:02:20,975
就像我们给单词计数那个函数也赋了一个输入值一样

37
00:02:22,750 --> 00:02:26,296
然后它就会计算TF/IDF了

38
00:02:26,296 --> 00:02:29,780
让我给你看看 最后的结果是什么样的

39
00:02:30,900 --> 00:02:33,560
额 我这边打错了个字

40
00:02:33,560 --> 00:02:35,671
应该是word_count

41
00:02:35,671 --> 00:02:38,629
不是word_counts

42
00:02:38,629 --> 00:02:43,390
这样我会在整个文集中 一共50000篇文章

43
00:02:43,390 --> 00:02:47,440
来计算单词的频率 并标准化

44
00:02:47,440 --> 00:02:52,150
最后我们的结果会是一张表 对每篇文章

45
00:02:52,150 --> 00:02:59,150
有一个TF/IDF的字典

46
00:02:59,150 --> 00:03:03,830
我们之前应该做的都是正确的 我准备再添加新的一列

47
00:03:03,830 --> 00:03:09,220
对于人物这个表格 新的一列会是叫做TF/IDF

48
00:03:09,220 --> 00:03:14,510
我准备在这一列储存我们的TF/IDF的值

49
00:03:14,510 --> 00:03:17,360
这也在一个表格里面 也就是TF-IDF 这个表格doc这一列

50
00:03:19,350 --> 00:03:20,930
恩 我们成功的添加了

51
00:03:20,930 --> 00:03:25,880
我们现在有了每篇文章的TF/IDF 并且储存在里面

52
00:03:25,880 --> 00:03:27,700
让我们检查一下

53
00:03:27,700 --> 00:03:33,283
这是我们要做的

54
00:03:33,283 --> 00:03:39,565
我们要检查奥巴马这篇文章的TF-IDF

55
00:03:39,565 --> 00:03:43,530
我们要检查奥巴马这篇文章的TF/IDF

56
00:03:47,500 --> 00:03:50,657
我们之前对于单词计数和排序 进行了检查

57
00:03:50,657 --> 00:03:53,547
我们也会把TF-IDF的值进行排序

58
00:03:53,547 --> 00:03:56,703
所以我会重新读取奥巴马的变量

59
00:03:56,703 --> 00:04:02,530
在最新的版本中 我们新添加了两列

60
00:04:02,530 --> 00:04:07,800
所以我会选择people中 

61
00:04:07,800 --> 00:04:14,320
people等于Barack Obama的那些行

62
00:04:16,120 --> 00:04:20,700
所以我创建了一个奥巴马 就像我们之前单词计数里做过的一样

63
00:04:20,700 --> 00:04:29,150
我创建了一个obama_tfidf_table 然后可以进行排序

64
00:04:29,150 --> 00:04:30,310
这是一个字典

65
00:04:30,310 --> 00:04:32,580
我们要做和之前一样的

66
00:04:32,580 --> 00:04:35,150
先存储然后再排序

67
00:04:35,150 --> 00:04:37,296
这就是我们要做的

68
00:04:37,296 --> 00:04:41,400
实际上 我不会再建立一个表格 而是在一行内搞定它

69
00:04:41,400 --> 00:04:43,837
我要一行完成

70
00:04:43,837 --> 00:04:47,469
所以我的代码就是

71
00:04:47,469 --> 00:04:50,824
我选取

72
00:04:50,824 --> 00:04:56,388
奥巴马中tf-idf这一列 这样看起来会漂亮些

73
00:04:56,388 --> 00:05:00,460
然后.stack 这个指令可以把字典中我想要的

74
00:05:00,460 --> 00:05:02,580
分成两列

75
00:05:02,580 --> 00:05:07,422
所以我要存储tf-idf的值

76
00:05:07,422 --> 00:05:13,804
所以输出值的新两列的名字会是

77
00:05:13,804 --> 00:05:19,324
word 和 tf-idf

78
00:05:19,324 --> 00:05:25,547
让我给你看些新的东西

79
00:05:25,547 --> 00:05:32,212
不好 我这边忘记加引号了

80
00:05:32,212 --> 00:05:36,725
让我给你看一点python的小技巧

81
00:05:36,725 --> 00:05:38,300
很有用的小技巧

82
00:05:38,300 --> 00:05:41,880
我会在这行代码的末尾加上一些指令

83
00:05:41,880 --> 00:05:43,959
比如说.sort

84
00:05:45,540 --> 00:05:52,730
这样我就会对tf-idf这一列进行排序

85
00:05:52,730 --> 00:05:59,590
然后我输入 asceding=false 进行降序排列

86
00:05:59,590 --> 00:06:02,920
所以说我之前用了很多行代码 现在我用一行代码就搞定了

87
00:06:02,920 --> 00:06:06,087
这样我就收集到了奥巴马的tf-idf这一列

88
00:06:06,087 --> 00:06:10,139
然后分开储存到word 和tf-idf这两列

89
00:06:10,139 --> 00:06:13,920
并且降序排序

90
00:06:13,920 --> 00:06:16,070
从最高到最低

91
00:06:16,070 --> 00:06:19,530
如果你记住的话 在我们运行之前

92
00:06:19,530 --> 00:06:24,475
在我们之前对单词计数做了类似的事

93
00:06:24,475 --> 00:06:27,250
最普遍的单词就是then in and of 这些

94
00:06:27,250 --> 00:06:30,260
然后就是to his Obama act a he这些单词

95
00:06:30,260 --> 00:06:35,010
这些单词通常不包含什么特殊的信息 除了Obama（奥巴马）这个单词

96
00:06:36,320 --> 00:06:39,980
让我们对TF-IDF执行它

97
00:06:39,980 --> 00:06:44,180
我们可以看到 最具有信息的单词就是奥巴马

98
00:06:44,180 --> 00:06:47,220
这也很合理 因为整篇文章都是有关奥巴马的

99
00:06:47,220 --> 00:06:50,630
然后剩下的就是art Iraq control law 依次排序 （艺术 伊拉克 控制 法律）

100
00:06:50,630 --> 00:06:54,690
military involvement response democratic 和 democratic party（军师 参与 回应 民主 民主党）

101
00:06:54,690 --> 00:06:59,669
你可以看到单词

102
00:06:59,669 --> 00:07:05,171
都和奥巴马的活动有着重要的联系

103
00:07:05,171 --> 00:07:09,309
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community