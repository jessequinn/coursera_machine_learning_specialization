1
00:00:00,000 --> 00:00:04,128
[음악]

2
00:00:04,128 --> 00:00:08,040
TF-IDF를 실제로 계산해 보죠

3
00:00:08,040 --> 00:00:11,760
이건 주의해야 할 점인데

4
00:00:11,760 --> 00:00:13,190
오바마 문서의 TF-IDF만을 따로 떼서

5
00:00:13,190 --> 00:00:18,560
계산할 수 없는데 TF-IDF는
전체 말뭉치에 종속적이기 때문입니다

6
00:00:18,560 --> 00:00:21,750
모든 문서에서 등장하는 단어수를

7
00:00:21,750 --> 00:00:22,780
정규화해야만 하죠

8
00:00:22,780 --> 00:00:25,620
그러니 전체 말뭉치부터 계산해야 합니다

9
00:00:25,620 --> 00:00:29,087
한 번 해볼까요

10
00:00:29,087 --> 00:00:33,302
그럼

11
00:00:33,302 --> 00:00:38,124
말뭉치의

12
00:00:38,124 --> 00:00:44,462
TF-IDF를 계산합니다

13
00:00:44,462 --> 00:00:46,320
두 단계로 나누어서 진행합니다

14
00:00:47,660 --> 00:00:51,712
먼저 전체 말뭉치의 단어수를 계산합니다

15
00:00:51,712 --> 00:00:57,330
인물 표에 word_count란 열을 추가합니다

16
00:00:57,330 --> 00:01:01,660
현재는 바락 오바마에 대해서만 되어 있는데

17
00:01:01,660 --> 00:01:02,160
모든 사람을 대상으로 합니다

18
00:01:02,160 --> 00:01:10,494
graphlab.text_analytics.count_words을 호출하고

19
00:01:10,494 --> 00:01:14,304
입력으로 텍스트 열을

20
00:01:14,304 --> 00:01:18,837
넣습니다

21
00:01:18,837 --> 00:01:22,370
즉 텍스트 열의 단어수를 셉니다

22
00:01:23,500 --> 00:01:25,750
분명히 하자면 그렇죠

23
00:01:25,750 --> 00:01:31,010
그다음 SFrame people을 출력합니다

24
00:01:31,010 --> 00:01:33,780
SFrame의 처음 몇 줄을 출력합니다

25
00:01:33,780 --> 00:01:35,430
실행하면 이렇게 나오죠

26
00:01:35,430 --> 00:01:40,634
URI 열과, 위치, 웹페이지, 이름,

27
00:01:40,634 --> 00:01:46,254
텍스트, 단어수 사전이 오른쪽에 추가되어있습니다

28
00:01:46,254 --> 00:01:50,860
좋습니다. 이제 TF-IDF를 계산하죠

29
00:01:50,860 --> 00:01:55,364
단어수와 같이 TF-IDF 시스템을 직접 구현해야 되지만

30
00:01:55,364 --> 00:01:57,588
시간이 걸릴 것입니다

31
00:01:57,588 --> 00:02:01,086
graphlab에 이미 구현되어 있으니

32
00:02:01,086 --> 00:02:05,949
시간을 단축하기 위해 구현된 걸 씁니다

33
00:02:05,949 --> 00:02:09,730
graphlab.text_analytics을 호출합니다

34
00:02:09,730 --> 00:02:14,820
단어수와 같이 tf_idf란 함수가 있습니다

35
00:02:14,820 --> 00:02:17,450
입력만 넣으면 되는데

36
00:02:17,450 --> 00:02:20,975
word_count를 넣습니다

37
00:02:22,750 --> 00:02:26,296
그러면 TF-IDF가 출력됩니다

38
00:02:26,296 --> 00:02:29,780
어떤 모습일지 보여드리죠

39
00:02:30,900 --> 00:02:33,560
아 오타가 있었네요

40
00:02:33,560 --> 00:02:35,671
word_count가 되어야 합니다

41
00:02:35,671 --> 00:02:38,629
word_counts가 아니라요

42
00:02:38,629 --> 00:02:43,390
문서 50000개의 전체 말뭉치애서

43
00:02:43,390 --> 00:02:47,440
단어 빈도를 계산, 정규화합니다

44
00:02:47,440 --> 00:02:52,150
그러면 각 문서에 대한 표가 나오게 되는데

45
00:02:52,150 --> 00:02:59,150
각 문서의 TF-IDF 사전입니다

46
00:02:59,150 --> 00:03:03,830
인물 표에 새로운 열 TF-IDF를

47
00:03:03,830 --> 00:03:09,220
추가합니다

48
00:03:09,220 --> 00:03:14,510
방금 계산한 TF-IDF를 저장합니다

49
00:03:14,510 --> 00:03:17,360
표 하나에 전부 있고 그중 docs 열입니다

50
00:03:19,350 --> 00:03:20,930
됐죠
방금 추가했습니다

51
00:03:20,930 --> 00:03:25,880
모든 문서에 대한 TF-IDF를 계산해서 넣었습니다

52
00:03:25,880 --> 00:03:27,700
검토하죠

53
00:03:27,700 --> 00:03:33,283
이제

54
00:03:33,283 --> 00:03:39,565
오바마 문서의 TF-IDF를

55
00:03:39,565 --> 00:03:43,530
검토할 겁니다

56
00:03:47,500 --> 00:03:50,657
단어수 벡터를 조사하고 정렬했듯이

57
00:03:50,657 --> 00:03:53,547
TF-IDF를 조사하고 정렬할 겁니다

58
00:03:53,547 --> 00:03:56,703
최종 버전에서 새로운 열 두 개를 추가했으니

59
00:03:56,703 --> 00:04:02,530
오바마 변수를 다시 읽어들입니다

60
00:04:02,530 --> 00:04:07,800
인물 중에서 이름이 바락 오바마인

61
00:04:07,800 --> 00:04:14,320
사람을 찾습니다

62
00:04:16,120 --> 00:04:20,700
오바마를 생성했고 단어수 때와 같이

63
00:04:20,700 --> 00:04:29,150
obama_tfidf_table를 만들어서 정렬합니다

64
00:04:29,150 --> 00:04:30,310
사전 형식입니다

65
00:04:30,310 --> 00:04:32,580
전과 같은 방식으로 정렬합니다

66
00:04:32,580 --> 00:04:35,150
쌓고 나서 정렬합니다

67
00:04:35,150 --> 00:04:37,296
이제 해보죠

68
00:04:37,296 --> 00:04:41,400
표를 만들지 않고 한 줄로 처리합니다

69
00:04:41,400 --> 00:04:43,837
아 한 줄로 해볼게요

70
00:04:43,837 --> 00:04:47,469
아까 했던 것처럼

71
00:04:47,469 --> 00:04:50,824
오바마 변수에서

72
00:04:50,824 --> 00:04:56,388
TF-IDF 열만 골라내면 깔끔하게 나옵니다

73
00:04:56,388 --> 00:05:00,460
스택 메소드를 호출하면 사전을 입력 받아

74
00:05:00,460 --> 00:05:02,580
두 열로 쌓습니다

75
00:05:02,580 --> 00:05:07,422
TF-IDF를 쌓게 되죠

76
00:05:07,422 --> 00:05:13,804
새 열 이름을 출력하는데

77
00:05:13,804 --> 00:05:19,324
이름은 단어와 TF-IDF가 됩니다

78
00:05:19,324 --> 00:05:25,547
신기한 걸 하나 보여드리죠

79
00:05:25,547 --> 00:05:32,212
아 괄호를 닫지 않았네요

80
00:05:32,212 --> 00:05:36,725
파이썬에서 다양한 방법으로 쓸 수 있는

81
00:05:36,725 --> 00:05:38,300
요령 하나를 보여드리죠

82
00:05:38,300 --> 00:05:41,880
이 뒤로 sort 함수를 체이닝합니다

83
00:05:41,880 --> 00:05:43,959
.sort를 입력합니다

84
00:05:45,540 --> 00:05:52,730
TF-IDF 열의 출력을 정렬합니다

85
00:05:52,730 --> 00:05:59,590
오름차순을 거짓으로 설정합니다

86
00:05:59,590 --> 00:06:02,920
이전엔 몇 줄에 걸쳐 써야 했던 걸
이제는 한 줄로 됩니다

87
00:06:02,920 --> 00:06:06,087
오바마의 TF-IDF 열에서

88
00:06:06,087 --> 00:06:10,139
단어 열, TF-IDF 열을 쌓아서

89
00:06:10,139 --> 00:06:13,920
내림차순으로 정렬합니다

90
00:06:13,920 --> 00:06:16,070
높은 데서 낮은 순으로요

91
00:06:16,070 --> 00:06:19,530
이건 돌리기 전에 어땠는지 회상해보죠

92
00:06:19,530 --> 00:06:24,475
단어수만 셌을 땐 이랬습니다

93
00:06:24,475 --> 00:06:27,250
가장 많이 나오는 단어는 the, in, and, of

94
00:06:27,250 --> 00:06:30,260
his, Obama, act, a, he 순이었죠

95
00:06:30,260 --> 00:06:35,010
오바마 빼고는 별로 가치가 없는 정보입니다

96
00:06:36,320 --> 00:06:39,980
TF-IDF를 실행해보죠

97
00:06:39,980 --> 00:06:44,180
여기서 가장 정보가치가 높은 단어는 오바마인데

98
00:06:44,180 --> 00:06:47,220
문서가 그의 관한 것임을 상기해보면
당연한 결과죠

99
00:06:47,220 --> 00:06:50,630
그다음 art, Iraq, control, law, ordered,

100
00:06:50,630 --> 00:06:54,690
military, involvement, response,
democratic, 민주당의 민주 순입니다

101
00:06:54,690 --> 00:06:59,669
오바마에 관한 주요 단어들이

102
00:06:59,669 --> 00:07:05,171
여럿 등장함을 알 수 있죠

103
00:07:05,171 --> 00:07:09,309
[음악]