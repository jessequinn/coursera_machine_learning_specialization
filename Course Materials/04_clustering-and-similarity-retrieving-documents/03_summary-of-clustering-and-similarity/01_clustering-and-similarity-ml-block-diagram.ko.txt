이 모듈에서는 문서 검색과 데이터의 잠재 구조를 파악하는 클러스터링의 개념을 알아봤고 이런 클러스터링이 유용하게 쓰일 수 있는 여러 분야도 살펴봤습니다 클러스터링 알고리즘의 작업흐름을 짚고 넘어가죠 지금 이 작업흐름을 이미 안다고 생각한다면 다른 두 모듈에서도 보았기 때문일 겁니다 정신차리세요! 이건 좀 다를 겁니다 훈련 데이터에 대해 공부했었죠 문서 클러스터링의 훈련 데이터는 문서 ID와 문서 텍스트 테이블입니다 엄청나게 많은 문서가 있습니다 각 문서에는 텍스트가 딸려 있지요 여기서 몇몇 특징 집합을 뽑아낼 겁니다 문서를 표현하는 여러 방법을 알아봤었죠 여기서 예로 들건 TF-IDF입니다 단어 빈도-역문서 빈도 표현법이죠 이 표현법을 기반으로 문서를 클러스터링 해볼 겁니다 기계학습 모델에 이 특징을 집어넣습니다 이 경우 클러스터링 모델이 되겠지요 각 문서에 대한 결과값은 클러스터 라벨입니다 결과값 y^이 클러스터 라벨이 됩니다 여기가 재밌는 부분인데요 클러스터 라벨의 정확도를 평가해야 하기 때문입니다 진짜 클러스터 라벨이 아니라 예측 또는 추정 클러스터 라벨입니다 하지만 비교 대상으로 삼을
진짜 클러스터 라벨이 존재하지 않죠 그러니 이 y는 없는 겁니다 말씀드렸듯이 비지도 학습 환경이라 그렇습니다 비지도요 좋아요. y는 없지만 어떻게든 클러스터링의 정확도를 평가할 기준이 필요합니다 k-means 알고리즘의 보로노이 다이어그램인데 클러스터 중심 집합과 데이터가 있습니다 데이터는 이렇게 생겼을 것입니다
잘 모르겠네요 그냥 점을 몇 개 그리죠 정확도 기준, 즉 품질 측정은 클러스터링의 일관성을 통해 합니다 즉 각 샘플에서 할당된 클러스터 중심까지의 거리입니다 클러스터링 알고리즘이 좋다면
거리는 아주 짧아지겠죠 목표는 거리 최소화인데 정확도와 거리를 측정하려면 데이터가 필요합니다 TF-IDF 벡터가 필요하죠 이건 여기로 가고 클러스터 중심도 필요합니다 w^은 모델 파라미터인 k-means 알고리즘의 현재 추정값입니다 이게 클러스터죠 철자에 맞게 쓸 수 있는지 볼까요
클러스터 중심 w^이 나타내는 것입니다 이 거리를 측정하기 위해선 w^도 필요합니다 실제 클러스터 라벨로 정확도를 측정하기보다 문서 표현법과 클러스터 중심으로 대신하겠습니다 클러스터 중심까지의 거리인 품질 기준에 입력합니다 이건 오차 기준, 오차가 아니죠 기준, 이런... 품질 기준입니다 단어를 쓰진 않을게요 조금 헷갈릴 거 같아서요 클러스터 중심까지의 거리라고만 쓰겠습니다 알고리즘은 어떤 거였죠? k-means를 클러스터링을 하는데 썼습니다 물론 다른 것도 있지만 우선 k-means에 집중하죠 k-means이 어떤 역할을 하고 있지요? 이 다이어그램을 다시 그려보죠
다른 색으로 그려볼게요 그게 시간상 낫겠네요 k-means는 이 거리합을 최소화합니다 이를 위해 반복적으로 갱신해서 이전 w^을 이 점들의 무게중심을 나타내는 새로운 w^으로 이동합니다 이 점들은 이동하게 되지요 이 점은 샘플 바로 위로 갑니다 이게 클러스터링의 작업흐름입니다 추상적으로 한 번 더 설명드리죠 문서를 가져다 모종의 방법, 단어수, TF-IDF나 이걸 정규화시킨 결과값으로 표현합니다 문서 표현을 위한 방법으로는 바이그램, 트라이그램 등이 있습니다 k-means와 같은 클러스터링 알고리즘이
클러스터링 라벨을 내놓으면 클러스터링 모델 파라미터인 클러스터 중심을 할당된 샘플까지의 거리를 통해 반복적으로 재조정합니다 이 모듈에서는 다른 모듈에서와 달리 알고리즘의 작동 방식에 대한 설명을 드렸습니다 특히 클러스터링에 대해서는 k-means 알고리즘, 문서 검색, 최근접 이웃 검색 등에 대한 알고리즘을 자세히 설명하였고 IPython 노트북을 통해 위키피디아 항목 검색을 진행하게 됩니다 이 시점에서 뉴스 기사 검색 시스템을 구축할 수 있어야 합니다 뉴스가 아니라도 제가 지금 떠올릴 수 없는
아주 멋진 검색 시스템을요 물론 흥미로운 예제가 많이 있습니다 그러니 밖에 나가서 제 대신에
멋진 아이디어를 떠올려 보세요 [음악]