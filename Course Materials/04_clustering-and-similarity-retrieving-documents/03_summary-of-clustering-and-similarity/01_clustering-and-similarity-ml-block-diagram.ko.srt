1
00:00:00,820 --> 00:00:06,140
이 모듈에서는 문서 검색과

2
00:00:06,140 --> 00:00:10,920
데이터의 잠재 구조를 파악하는

3
00:00:10,920 --> 00:00:15,780
클러스터링의 개념을 알아봤고 이런 클러스터링이

4
00:00:15,780 --> 00:00:19,890
유용하게 쓰일 수 있는 여러 분야도 살펴봤습니다

5
00:00:19,890 --> 00:00:22,960
클러스터링 알고리즘의 작업흐름을 짚고 넘어가죠

6
00:00:24,560 --> 00:00:27,290
지금 이 작업흐름을 이미 안다고 생각한다면

7
00:00:27,290 --> 00:00:29,710
다른 두 모듈에서도 보았기 때문일 겁니다

8
00:00:29,710 --> 00:00:30,380
정신차리세요!

9
00:00:30,380 --> 00:00:31,850
이건 좀 다를 겁니다

10
00:00:33,330 --> 00:00:35,780
훈련 데이터에 대해 공부했었죠

11
00:00:35,780 --> 00:00:37,420
문서 클러스터링의 훈련 데이터는

12
00:00:37,420 --> 00:00:43,870
문서 ID와

13
00:00:43,870 --> 00:00:50,550
문서 텍스트 테이블입니다

14
00:00:50,550 --> 00:00:52,820
엄청나게 많은 문서가 있습니다

15
00:00:52,820 --> 00:00:55,690
각 문서에는 텍스트가 딸려 있지요

16
00:00:55,690 --> 00:00:57,610
여기서 몇몇 특징 집합을 뽑아낼 겁니다

17
00:00:57,610 --> 00:01:01,428
문서를 표현하는 여러 방법을 알아봤었죠

18
00:01:01,428 --> 00:01:06,863
여기서 예로 들건 TF-IDF입니다

19
00:01:06,863 --> 00:01:10,560
단어 빈도-역문서 빈도 표현법이죠

20
00:01:12,520 --> 00:01:14,620
이 표현법을 기반으로 문서를

21
00:01:14,620 --> 00:01:17,770
클러스터링 해볼 겁니다

22
00:01:17,770 --> 00:01:21,850
기계학습 모델에 이 특징을 집어넣습니다

23
00:01:21,850 --> 00:01:24,694
이 경우 클러스터링 모델이 되겠지요

24
00:01:29,500 --> 00:01:33,720
각 문서에 대한 결과값은 클러스터 라벨입니다

25
00:01:33,720 --> 00:01:38,490
결과값 y^이 클러스터 라벨이 됩니다

26
00:01:40,140 --> 00:01:43,110
여기가 재밌는 부분인데요

27
00:01:43,110 --> 00:01:46,520
클러스터 라벨의 정확도를 평가해야 하기 때문입니다

28
00:01:46,520 --> 00:01:50,070
진짜 클러스터 라벨이 아니라

29
00:01:50,070 --> 00:01:57,370
예측 또는 추정 클러스터 라벨입니다

30
00:01:58,890 --> 00:02:02,370
하지만 비교 대상으로 삼을
진짜 클러스터 라벨이 존재하지 않죠

31
00:02:02,370 --> 00:02:07,130
그러니 이 y는 없는 겁니다

32
00:02:08,280 --> 00:02:13,840
말씀드렸듯이 비지도 학습 환경이라 그렇습니다

33
00:02:15,620 --> 00:02:16,520
비지도요

34
00:02:18,500 --> 00:02:19,460
좋아요.

35
00:02:19,460 --> 00:02:20,570
y는 없지만 어떻게든 클러스터링의

36
00:02:20,570 --> 00:02:24,740
정확도를 평가할 기준이 필요합니다

37
00:02:24,740 --> 00:02:30,680
k-means 알고리즘의 보로노이 다이어그램인데

38
00:02:30,680 --> 00:02:36,633
클러스터 중심 집합과 데이터가 있습니다

39
00:02:38,551 --> 00:02:40,947
데이터는 이렇게 생겼을 것입니다
잘 모르겠네요

40
00:02:40,947 --> 00:02:42,750
그냥 점을 몇 개 그리죠

41
00:02:44,590 --> 00:02:49,290
정확도 기준, 즉 품질 측정은

42
00:02:49,290 --> 00:02:54,700
클러스터링의 일관성을 통해 합니다

43
00:02:54,700 --> 00:02:58,275
즉 각 샘플에서 할당된 클러스터 중심까지의

44
00:02:58,275 --> 00:03:00,209
거리입니다

45
00:03:02,682 --> 00:03:07,990
클러스터링 알고리즘이 좋다면
거리는 아주 짧아지겠죠

46
00:03:09,050 --> 00:03:14,050
목표는 거리 최소화인데

47
00:03:14,050 --> 00:03:19,020
정확도와 거리를 측정하려면 데이터가 필요합니다

48
00:03:19,020 --> 00:03:21,690
TF-IDF 벡터가 필요하죠

49
00:03:22,760 --> 00:03:29,330
이건 여기로 가고 클러스터 중심도 필요합니다

50
00:03:29,330 --> 00:03:33,690
w^은 모델 파라미터인 k-means 알고리즘의

51
00:03:33,690 --> 00:03:36,780
현재 추정값입니다

52
00:03:36,780 --> 00:03:39,930
이게 클러스터죠

53
00:03:42,190 --> 00:03:46,190
철자에 맞게 쓸 수 있는지 볼까요
클러스터 중심

54
00:03:46,190 --> 00:03:47,933
w^이 나타내는 것입니다

55
00:03:47,933 --> 00:03:52,636
이 거리를 측정하기 위해선 w^도 필요합니다

56
00:03:52,636 --> 00:03:57,845
실제 클러스터 라벨로 정확도를 측정하기보다

57
00:03:57,845 --> 00:04:03,280
문서 표현법과 클러스터 중심으로 대신하겠습니다

58
00:04:03,280 --> 00:04:06,797
클러스터 중심까지의 거리인

59
00:04:06,797 --> 00:04:11,852
품질 기준에 입력합니다

60
00:04:16,599 --> 00:04:20,780
이건 오차 기준, 오차가 아니죠

61
00:04:20,780 --> 00:04:22,210
기준,

62
00:04:22,210 --> 00:04:22,710
이런...

63
00:04:25,460 --> 00:04:26,770
품질 기준입니다

64
00:04:29,930 --> 00:04:32,090
단어를 쓰진 않을게요

65
00:04:32,090 --> 00:04:35,180
조금 헷갈릴 거 같아서요

66
00:04:35,180 --> 00:04:38,240
클러스터 중심까지의 거리라고만 쓰겠습니다

67
00:04:38,240 --> 00:04:39,920
알고리즘은 어떤 거였죠?

68
00:04:39,920 --> 00:04:43,350
k-means를 클러스터링을 하는데 썼습니다

69
00:04:43,350 --> 00:04:46,158
물론 다른 것도 있지만 우선 k-means에 집중하죠

70
00:04:46,158 --> 00:04:47,270
k-means이 어떤 역할을 하고 있지요?

71
00:04:47,270 --> 00:04:54,300
이 다이어그램을 다시 그려보죠
다른 색으로 그려볼게요

72
00:04:54,300 --> 00:04:56,320
그게 시간상 낫겠네요

73
00:04:57,320 --> 00:05:02,980
k-means는 이 거리합을 최소화합니다

74
00:05:02,980 --> 00:05:07,540
이를 위해 반복적으로 갱신해서

75
00:05:07,540 --> 00:05:11,870
이전 w^을 이 점들의 무게중심을 나타내는

76
00:05:13,680 --> 00:05:20,290
새로운 w^으로 이동합니다

77
00:05:20,290 --> 00:05:24,040
이 점들은 이동하게 되지요

78
00:05:24,040 --> 00:05:27,520
이 점은 샘플 바로 위로 갑니다

79
00:05:29,600 --> 00:05:34,900
이게 클러스터링의 작업흐름입니다

80
00:05:34,900 --> 00:05:37,130
추상적으로 한 번 더 설명드리죠

81
00:05:37,130 --> 00:05:41,575
문서를 가져다 모종의 방법, 단어수, TF-IDF나

82
00:05:41,575 --> 00:05:44,440
이걸 정규화시킨 결과값으로 표현합니다

83
00:05:44,440 --> 00:05:48,000
문서 표현을 위한 방법으로는

84
00:05:48,000 --> 00:05:49,400
바이그램, 트라이그램 등이 있습니다

85
00:05:50,500 --> 00:05:55,950
k-means와 같은 클러스터링 알고리즘이
클러스터링 라벨을 내놓으면 

86
00:05:55,950 --> 00:06:01,400
클러스터링 모델 파라미터인

87
00:06:01,400 --> 00:06:07,410
클러스터 중심을 할당된 샘플까지의 거리를 통해

88
00:06:07,410 --> 00:06:15,620
반복적으로 재조정합니다

89
00:06:15,620 --> 00:06:20,020
이 모듈에서는 다른 모듈에서와 달리

90
00:06:20,020 --> 00:06:24,030
알고리즘의 작동 방식에 대한 설명을 드렸습니다

91
00:06:24,030 --> 00:06:28,190
특히 클러스터링에 대해서는 k-means 알고리즘,

92
00:06:28,190 --> 00:06:31,690
문서 검색, 최근접 이웃 검색 등에 대한

93
00:06:31,690 --> 00:06:34,570
알고리즘을 자세히 설명하였고

94
00:06:34,570 --> 00:06:37,520
IPython 노트북을 통해

95
00:06:37,520 --> 00:06:39,900
위키피디아 항목 검색을 진행하게 됩니다

96
00:06:39,900 --> 00:06:42,190
이 시점에서 뉴스 기사 검색 시스템을

97
00:06:42,190 --> 00:06:46,630
구축할 수 있어야 합니다

98
00:06:46,630 --> 00:06:51,770
뉴스가 아니라도 제가 지금 떠올릴 수 없는
아주 멋진 검색 시스템을요

99
00:06:51,770 --> 00:06:53,760
물론 흥미로운 예제가 많이 있습니다

100
00:06:53,760 --> 00:06:57,611
그러니 밖에 나가서 제 대신에
멋진 아이디어를 떠올려 보세요

101
00:06:57,611 --> 00:07:01,299
[음악]