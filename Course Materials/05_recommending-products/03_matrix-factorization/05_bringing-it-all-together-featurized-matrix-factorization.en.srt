1
00:00:00,000 --> 00:00:03,930
[MUSIC]

2
00:00:03,930 --> 00:00:08,228
Okay, so we saw in our feature-based
classification approach that we were able

3
00:00:08,228 --> 00:00:11,400
to handle cases where we might
have very limited user data.

4
00:00:11,400 --> 00:00:14,950
And on the other hand,
in our matrix factorization approach,

5
00:00:14,950 --> 00:00:19,190
we saw that we were able to capture
relationships between users and

6
00:00:19,190 --> 00:00:24,130
items and in particular learn features
of those users and those items.

7
00:00:24,130 --> 00:00:26,960
And a question is, whether we can
have some integrated approach

8
00:00:26,960 --> 00:00:29,310
to get the benefits of both worlds.

9
00:00:29,310 --> 00:00:34,030
So importantly the features of our
classification based approach, or

10
00:00:34,030 --> 00:00:37,530
something like that can
capture things like context,

11
00:00:37,530 --> 00:00:42,860
time of day, what I just saw,
user information, past purchases.

12
00:00:42,860 --> 00:00:47,560
Whereas the features that are discovered
from matrix factorization

13
00:00:47,560 --> 00:00:50,850
can capture groups of users
who behave similarly.

14
00:00:50,850 --> 00:00:55,710
So for example, women from Seattle
who teach and are also a mom.

15
00:00:56,910 --> 00:01:00,730
Okay so the question is how we combine
these two different approaches.

16
00:01:00,730 --> 00:01:02,390
Well it's very straightforward.

17
00:01:02,390 --> 00:01:05,810
What we can do is we
can take a new user for

18
00:01:05,810 --> 00:01:10,250
which we have no past purchase
information, and we can use

19
00:01:12,900 --> 00:01:16,170
just features specified by that user.

20
00:01:16,170 --> 00:01:19,830
Such as the person's age,
gender and so on,

21
00:01:19,830 --> 00:01:23,550
to predict the ratings
that a person might have.

22
00:01:23,550 --> 00:01:29,440
Likewise, as we get more and
more data from that user,

23
00:01:29,440 --> 00:01:33,570
we can weight more heavily on our
matrix factorization approach and

24
00:01:33,570 --> 00:01:39,670
use those learn features, more strongly
when we're forming our recommendations.

25
00:01:39,670 --> 00:01:45,277
So it's very simple to think about
combining the ideas of a user-specified

26
00:01:45,277 --> 00:01:50,660
feature-based model with our learned
features from matrix factorization.

27
00:01:50,660 --> 00:01:52,716
And gradually switch between the two,

28
00:01:52,716 --> 00:01:56,713
depending on how much data's available
from each user or for each product.

29
00:01:59,879 --> 00:02:03,280
And this idea of blending
models is really popular.

30
00:02:04,510 --> 00:02:08,690
And one example of where it's
really been shown to have impact in

31
00:02:08,690 --> 00:02:12,830
recommenders systems was this
classic example that we mentioned at

32
00:02:12,830 --> 00:02:16,800
the beginning of this module
of the Netflix competition.

33
00:02:16,800 --> 00:02:20,140
So this competition was a competition for

34
00:02:20,140 --> 00:02:26,020
who could provide the best predicted
ratings for users on Netflix,

35
00:02:26,020 --> 00:02:31,960
and the data set consisted of a hundred
million different user ratings and movies.

36
00:02:31,960 --> 00:02:37,557
There's almost 18,000 different movies,
nearly 500,000 unique users,

37
00:02:37,557 --> 00:02:42,636
and the goal was to predict 3,000,000
ratings to the highest accuracy,

38
00:02:42,636 --> 00:02:45,400
and the prize was a $1,000,000.

39
00:02:45,400 --> 00:02:50,460
So there are a lot of people very
interested in competing for this prize,

40
00:02:50,460 --> 00:02:56,060
and what we see in this table
here is the leading team.

41
00:02:56,060 --> 00:02:58,700
And their model actually blended

42
00:02:58,700 --> 00:03:02,580
over a hundred different models
to get their performance.

43
00:03:02,580 --> 00:03:05,911
And so
this type of ensemble approach we're gonna

44
00:03:05,911 --> 00:03:09,006
discuss more in
the classification module but

45
00:03:09,006 --> 00:03:14,403
this notion of combining models to get
performance that exceeds the performance

46
00:03:14,403 --> 00:03:19,587
of any of the individual models Is a very
common and very powerful technique.