1
00:00:00,000 --> 00:00:04,338
[음악]

2
00:00:04,338 --> 00:00:08,644
인기 높은 물품의 문제를 해결하기 위해

3
00:00:08,644 --> 00:00:13,340
동시발생 행렬의 정규화를 고려해볼 수 있습니다

4
00:00:13,340 --> 00:00:17,290
한 가지 방법은 자카드 유사도라

5
00:00:17,290 --> 00:00:18,010
합니다

6
00:00:19,048 --> 00:00:21,870
동시발생 행렬의 정규화란 개념을

7
00:00:21,870 --> 00:00:25,270
짚고 넘어가려고 하는데

8
00:00:25,270 --> 00:00:29,450
클러스터링과 유사도 모듈에서 배운 것과 비슷합니다

9
00:00:29,450 --> 00:00:34,940
TF-IDF, 단어 빈도 역문서 빈도를 논할 때

10
00:00:34,940 --> 00:00:38,800
문서들을 살펴보면 아주 흔한 단어들이

11
00:00:38,800 --> 00:00:43,540
다른 중요한 단어를 밀어냈었죠

12
00:00:43,540 --> 00:00:47,090
이렇게 TF-IDF를 사용해 문서를 표현하는

13
00:00:47,090 --> 00:00:51,480
원시 단어수를 재정규화했습니다

14
00:00:51,480 --> 00:00:52,260
이 경우

15
00:00:52,260 --> 00:00:57,310
인기 있는 물품을 반영하는 것도 비슷합니다

16
00:00:58,430 --> 00:01:01,110
작동하는 법도 매우 직관적이고요

17
00:01:01,110 --> 00:01:06,290
물품 i와 j를 구입한 사람수를

18
00:01:06,290 --> 00:01:06,930
셉니다

19
00:01:08,220 --> 00:01:14,000
i와 j를 구입한 사람의 숫자는

20
00:01:14,000 --> 00:01:18,010
이전에 행렬에 있었죠

21
00:01:18,010 --> 00:01:19,840
이게 원시 카운트입니다

22
00:01:19,840 --> 00:01:22,410
이걸 각 품목 어느쪽이든 구입한 사람수로

23
00:01:22,410 --> 00:01:25,349
정규화합니다

24
00:01:26,600 --> 00:01:33,461
i나 j를 구입한 사람수입니다

25
00:01:33,461 --> 00:01:37,500
간단히 벤 다이어그램을 그려보면 확실히 알 수 있죠

26
00:01:40,370 --> 00:01:44,047
이게 물품 i를 구입한 사람들이고

27
00:01:48,700 --> 00:01:53,879
이게 물품 j를 구입한 사람들이며

28
00:01:55,672 --> 00:02:00,712
여기 음영 처리된 부분이 i와 j를
둘 다 구입한 사람들입니다

29
00:02:04,150 --> 00:02:08,337
이제 가지고 있던 카운트에서

30
00:02:08,337 --> 00:02:12,213
i와 j를 모두 구입한, 음영 처리된 부분이
분자가 됩니다

31
00:02:12,213 --> 00:02:16,200
총면적으로 정규화합니다

32
00:02:16,200 --> 00:02:21,212
색깔을 바꿔서 잘 보이게 하죠

33
00:02:27,421 --> 00:02:36,110
i 또는 j를 구입한 순 사용자 전체에 동그라미 칩니다

34
00:02:36,110 --> 00:02:37,671
이게 분모가 됩니다

35
00:02:40,671 --> 00:02:45,519
동시발생 행렬을 정규화하는 방법의 하나입니다

36
00:02:45,519 --> 00:02:49,875
코사인 유사도와 같은 방법도 고려해볼 수 있는데

37
00:02:49,875 --> 00:02:53,690
이런 기준들에 대해선 이후에 설명하겠습니다

38
00:02:55,540 --> 00:02:57,980
이 방법에는 한계도 있습니다

39
00:02:57,980 --> 00:03:01,570
한 가지 문제는 오로지 현재 페이지만

40
00:03:01,570 --> 00:03:04,490
반영된다는 점인데 방금 산 기린 소피만이

41
00:03:04,490 --> 00:03:07,260
추천에 반영되게 됩니다

42
00:03:07,260 --> 00:03:10,220
지금까지의 모든 구매 이력을 뒤져서

43
00:03:10,220 --> 00:03:11,830
추천을 하지는 않습니다

44
00:03:13,800 --> 00:03:18,300
접근법을 바꿔 어떻게 구매 이력을

45
00:03:18,300 --> 00:03:19,880
반영할 수 있는지 알아보죠

46
00:03:21,270 --> 00:03:25,390
아주 간단한 접근법은 상품 점수의

47
00:03:25,390 --> 00:03:28,350
가중 평균을 구하는 것입니다

48
00:03:28,350 --> 00:03:30,490
구매 이력의 각 물품에 대해

49
00:03:30,490 --> 00:03:32,740
구체적인 예를 들어 볼까요

50
00:03:32,740 --> 00:03:38,800
아마존에서 지금까지 기저귀와 우유만 샀다고 할게요

51
00:03:38,800 --> 00:03:42,860
이런 저를 위한 추천을 하고 싶은데

52
00:03:42,860 --> 00:03:48,210
이럴 땐 추천 후보인 모든 품목을 대상으로

53
00:03:48,210 --> 00:03:51,910
다음과 같은 점수를 계산합니다

54
00:03:51,910 --> 00:03:55,580
아기 물티슈를 추천해야 하는지

55
00:03:55,580 --> 00:03:57,970
알아본다고 하죠

56
00:03:57,970 --> 00:03:59,250
이 경우

57
00:03:59,250 --> 00:04:03,820
기저귀 구매를 기반으로 아기 물티슈 추천을

58
00:04:03,820 --> 00:04:08,760
얼마나 했는지 가중 평균을 계산합니다

59
00:04:08,760 --> 00:04:11,400
이전에 말씀드린 기법들을 사용하죠

60
00:04:11,400 --> 00:04:14,270
기저귀 행을 보고 사람들이

61
00:04:14,270 --> 00:04:17,650
아기 물티슈를 얼마나 샀나 봅니다

62
00:04:17,650 --> 00:04:20,930
다음으로 우유 행을 보고 우유 산 사람 중에

63
00:04:20,930 --> 00:04:24,340
얼마나 아기 물티슈를 샀나 봅니다

64
00:04:24,340 --> 00:04:29,040
두 결과의 평균을 취해서 구매 이력이 주어졌을 때

65
00:04:30,490 --> 00:04:34,170
아기 물티슈를 살 확률이 얼마나 되나 봅니다

66
00:04:35,930 --> 00:04:39,360
물론 간단한 가중 평균이 아닌 다른 기법도 가능한데

67
00:04:39,360 --> 00:04:44,250
최근 구매 이력의 비중을

68
00:04:44,250 --> 00:04:46,980
높이는 것입니다

69
00:04:48,250 --> 00:04:51,560
그런 다음 추천할 때는 가중 평균 점수를

70
00:04:51,560 --> 00:04:55,670
정렬해서 가장 높은 상품을 추천하는 거죠

71
00:04:55,670 --> 00:04:59,274
이전과 아주 유사하지만

72
00:04:59,274 --> 00:05:02,962
구매 이력 기반으로 가중치를 합친다는 게 다릅니다

73
00:05:05,004 --> 00:05:07,580
그럼에도 이 방법에는 한계가 존재합니다

74
00:05:07,580 --> 00:05:12,890
시간과 같은 문맥 정보를 직접 활용하지 않습니다

75
00:05:12,890 --> 00:05:17,760
나이와 성별 같은 사용자 특징도 보지 않는데

76
00:05:17,760 --> 00:05:20,845
동시발생 행렬을 살펴보려고 할 때

77
00:05:20,845 --> 00:05:25,160
모든 사용자를 그룹으로 묶기 때문입니다

78
00:05:26,310 --> 00:05:29,030
마찬가지로 상품 특징도 보지 않습니다

79
00:05:29,030 --> 00:05:34,200
상품이나 사용자 특성을 활용해 추천하기보다

80
00:05:34,200 --> 00:05:38,550
정보가 모여만 있습니다

81
00:05:39,850 --> 00:05:42,610
여기서 마주하게 되는 큰 문제점 하나는

82
00:05:42,610 --> 00:05:43,240
콜드 스타트라 불립니다

83
00:05:43,240 --> 00:05:46,170
많은 영역에서 보게 되는 아주 중요한

84
00:05:46,170 --> 00:05:46,990
문제죠

85
00:05:46,990 --> 00:05:49,130
지금까지 논의의 연장선상에서 볼까요

86
00:05:49,130 --> 00:05:53,610
콜드 스타트 문제는 새로운 사용자나

87
00:05:53,610 --> 00:05:55,290
상품이 있을 때

88
00:05:55,290 --> 00:05:57,650
어떻게 추천을 할까 하는 것입니다

89
00:05:57,650 --> 00:06:01,830
이 상품에 대한 샘플이 전혀 없고

90
00:06:01,830 --> 00:06:06,070
판매된 적이 없기 때문에 어떤 상품과

91
00:06:06,070 --> 00:06:08,230
얼마나 자주 팔렸는지도 알지 못 합니다

92
00:06:08,230 --> 00:06:12,129
사용자도 비슷하게 구매 이력 정보가 전혀 없죠

93
00:06:12,129 --> 00:06:15,929
[음악]