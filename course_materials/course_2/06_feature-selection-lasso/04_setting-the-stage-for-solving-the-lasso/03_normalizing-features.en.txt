[MUSIC] Well, our presentation
of coordinate ascent for lasso is really simplified if we think
about normalizing our features and this is also a practically
important concept. So let's take a few minutes to discuss
this idea of normalizing features. Okay.
Well when we talk about normalizing our features what we're talking about is
taking a column of our training data, so very important that we
take a column not a row. Okay.
So I'll say it once more. We take a column not a row because
what does a column represent? Well, for example in our housing
application it might represent, all instances of the number of square
feet of houses in our training data set. So what we're gonna do is we're gonna
do an operation on square feet. That would be one column. In contrast, if I took a row we're
gonna be doing an operation for a specific observation and
that operation would be different between different observations and things
would be all on different scales between our different observations and
that wouldn't make any sense. So please never do that. Please do this observation on
columns of the training data and what's this operation we're gonna do? Well we're gonna take our column, our
specific feature like square feet over our n different observations in our training
set, and we're going to normalize each of these entries, each of these feature
values by the following quantity, and doing this operation is gonna place
each one of our features into the same numeric range, because the range of
values we might see for square feet versus number of floors or number of
bathrooms is dramatically different. After we do this transformation though,
everything will be in the same numeric range, so that's why it's a practically
important transformation but, I wanna emphasize one thing that
when you transform your features, when you normalize them. In this way or any way that you choose to
transform your features on your training dataset you have to do exactly the same
operation on your test dataset. Otherwise you're gonna be mixing up the
apples and oranges because for example, you think about transforming
your training data from Measuring square feet to measuring
square meters for every house but then your test data is
still in square feet. When I learn a model in my training data,
which is now in square meters, and I go to test it on my test data which is square
feet, it's gonna give me bogus answers. Okay, so make sure you do the same
operation on both training and test and so, if we're gonna to call this
normalizer, which we'll use this notation later, Zj, we're going to divide
by exactly the same quantity for each column of our test set. So this same Zj appears here where,
just to emphasize, we're summing over all of our training
data points in doing this operation here, and we're applying it to one
of our test data points. [MUSIC]