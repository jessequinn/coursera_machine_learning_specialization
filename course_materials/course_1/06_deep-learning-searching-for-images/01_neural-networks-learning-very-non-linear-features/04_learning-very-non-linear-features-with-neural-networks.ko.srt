1
00:00:00,000 --> 00:00:04,692
[음악]

2
00:00:04,692 --> 00:00:07,416
좋습니다 지금까지 이미지 특징을 활용해

3
00:00:07,416 --> 00:00:10,850
멋진 신발, 드레스 찾아봤습니다

4
00:00:10,850 --> 00:00:14,080
오늘 사용할 기법은 딥러닝이라고 합니다

5
00:00:14,080 --> 00:00:17,510
그중 신경망이란 걸 씁니다

6
00:00:17,510 --> 00:00:21,260
그전에 데이터 표현법을 설명드릴게요

7
00:00:21,260 --> 00:00:22,806
TF-IDF와 단어주머니(Bag-of-words)
모델을 알아봤는데

8
00:00:22,806 --> 00:00:27,650
이미지라면 어떻게 데이터를 표현해야 할까요?

9
00:00:29,090 --> 00:00:31,910
특징이라 불리는 이게
기계학습의 핵심입니다

10
00:00:33,050 --> 00:00:37,150
일반적으로 기계학습이라고 하면
입력이 주어집니다

11
00:00:37,150 --> 00:00:40,200
분류 작업을 할 텐데 감성분석은 했었죠

12
00:00:40,200 --> 00:00:43,160
문장이 주어지면 분류기 모델에 통과시켜

13
00:00:43,160 --> 00:00:46,780
긍정적, 부정적 감성인지 결정했습니다

14
00:00:46,780 --> 00:00:49,300
이미지 분류에서는 입력인 이미지 픽셀을

15
00:00:49,300 --> 00:00:52,990
통해 분류를 하는 것입니다

16
00:00:52,990 --> 00:00:55,920
이건 제 개인데 래브라도 리트리버인지

17
00:00:55,920 --> 00:00:59,660
다른 종류인지 분류하고자 합니다

18
00:00:59,660 --> 00:01:03,070
특징은 데이터 표현법이며

19
00:01:03,070 --> 00:01:05,000
분류기에 입력됩니다

20
00:01:06,060 --> 00:01:08,060
많은 표현법이 있는데 텍스트에는

21
00:01:08,060 --> 00:01:11,050
단어주머니와 TF-IDF가 있었죠

22
00:01:11,050 --> 00:01:13,400
이미지에는 다양한 표현법이 존재합니다

23
00:01:13,400 --> 00:01:15,270
이 모듈에서 그중 몇 개를 설명합니다

24
00:01:16,330 --> 00:01:18,900
오늘은 신경망에 집중하기로 하죠

25
00:01:18,900 --> 00:01:21,820
데이터의 비선형적 표현법을 제공합니다

26
00:01:23,195 --> 00:01:25,080
분류로 다시 돌아가죠

27
00:01:25,080 --> 00:01:26,850
복습을 좀 해봅시다

28
00:01:26,850 --> 00:01:30,710
선형 분류기는 이런 선을 긋거나

29
00:01:30,710 --> 00:01:35,630
긍정 클래스, 부정 클래스 사이의
선형 결정 경계를 설정합니다

30
00:01:35,630 --> 00:01:39,921
경계는 점수 w0 + w1 * x1 + w2 * x2로

31
00:01:39,921 --> 00:01:45,730
이어지는 수식으로 표현됩니다

32
00:01:45,730 --> 00:01:50,160
점수가 0보다 높은 긍정 클래스와

33
00:01:50,160 --> 00:01:52,690
0보다 낮은 부정 클래스로 나눠집니다

34
00:01:52,690 --> 00:01:54,920
점수 함수가 있으면

35
00:01:54,920 --> 00:01:58,180
긍정과 부정을 나눌 수 있습니다

36
00:01:58,180 --> 00:02:02,410
신경망에서는 이런 분류기를
그래프로 표현합니다

37
00:02:03,530 --> 00:02:08,070
x1, x2에서 d번째 특징 xd까지
각각 노드가 있고

38
00:02:08,070 --> 00:02:13,730
예측하고자 하는 결과값 y 노드가 있습니다

39
00:02:13,730 --> 00:02:16,950
첫 특징인 x1에

40
00:02:16,950 --> 00:02:18,700
간선의 가중치 w1을 곱합니다

41
00:02:18,700 --> 00:02:21,870
x2에는 두 번째 간선 가중치 w2 하는 식으로 해서

42
00:02:21,870 --> 00:02:26,850
xd에 마지막 간선의 가중치 wd 를 곱합니다

43
00:02:26,850 --> 00:02:30,970
마지막 가중치 w0은 특징과 곱하지 않고

44
00:02:30,970 --> 00:02:34,900
1을 곱하므로 맨 위에는 1을 적습니다

45
00:02:34,900 --> 00:02:40,340
가중치 w0에서 wd까지를

46
00:02:40,340 --> 00:02:44,850
특징 x1부터 xd, 계수 1까지 곱하면
점수가 나옵니다

47
00:02:44,850 --> 00:02:48,400
점수가 0보다 크면 결과값이 1이 되고

48
00:02:48,400 --> 00:02:51,550
0보다 작으면 결과값이 0이 됩니다

49
00:02:51,550 --> 00:02:56,650
이건 간단한 단층 신경망입니다

50
00:02:56,650 --> 00:03:01,470
선형 분류기를 단층 신경망으로

51
00:03:01,470 --> 00:03:02,940
나타냈습니다

52
00:03:02,940 --> 00:03:05,770
What can this one layer
neural network represent?
단층 신경망으로 뭘 표현할 수 있죠?

53
00:03:05,770 --> 00:03:10,620
함수 x1 OR x2를

54
00:03:10,620 --> 00:03:14,240
신경망으로 나타낼 수 있나요?

55
00:03:14,240 --> 00:03:17,140
함수를 좀 더 엄밀하게 정의할게요

56
00:03:17,140 --> 00:03:22,891
변수 x1, x2와

57
00:03:22,891 --> 00:03:26,910
결과값 y가 있습니다

58
00:03:26,910 --> 00:03:28,680
몇 가지 가능성이 있죠

59
00:03:28,680 --> 00:03:32,998
x1이 0이고 x2가 2이면
x1 OR x2니까

60
00:03:32,998 --> 00:03:36,340
결과값 y는 이 경우 0가 됩니다

61
00:03:36,340 --> 00:03:40,272
x1가 1이고 x2가 0이면 결과값은 1입니다

62
00:03:40,272 --> 00:03:43,360
x1가 0이고 x2가 1이면 1이고요

63
00:03:43,360 --> 00:03:47,300
마찬가지로 둘 다 1이면 1입니다

64
00:03:47,300 --> 00:03:54,080
마지막 세 행의 값이 0보다 크지만
첫 행에서는 0보다 작은

65
00:03:54,080 --> 00:03:59,890
점수 함수를 정의하고자 합니다

66
00:03:59,890 --> 00:04:01,390
어떻게 해야 할까요?

67
00:04:01,390 --> 00:04:03,870
사실 아주 다양한 방법이 있지만

68
00:04:03,870 --> 00:04:06,020
가중치 1을 각 간선

69
00:04:06,020 --> 00:04:11,620
x1, x2에 매기고 점수를 보면

70
00:04:11,620 --> 00:04:16,830
첫 번째 행의 점수는 0이고
다른 행들의 점수는 0보다 큽니다

71
00:04:16,830 --> 00:04:18,890
분리해야 하니

72
00:04:18,890 --> 00:04:21,190
음수를 첫 번째 간선에 할당합니다

73
00:04:21,190 --> 00:04:26,200
-0.5라고 하고 점수가
어떻게 변화하는지 보죠

74
00:04:26,200 --> 00:04:33,366
x1가 0이고 x2가 0일 때 점수는 -0.5이니

75
00:04:33,366 --> 00:04:38,460
결과는 0보다 작습니다
점수도 맞고 결과값도 맞네요

76
00:04:38,460 --> 00:04:44,610
x1가 1이고 x2가 0이면
점수는 0.5입니다

77
00:04:44,610 --> 00:04:48,220
x1가 0이고 x2가 1이여도 같고요

78
00:04:48,220 --> 00:04:52,680
마지막으로 둘 다 1이면 점수는 1.5입니다

79
00:04:52,680 --> 00:04:58,300
간선 가중치만 가지고 OR 함수를 표현했습니다

80
00:04:59,470 --> 00:05:02,280
AND 함수도 표현할 수 있나요?

81
00:05:04,040 --> 00:05:09,560
비슷하게 가중치 1을 각각 간선 x1와 x2에 주는데

82
00:05:09,560 --> 00:05:16,810
이 경우 x1와 x2가 둘 다 1일 때만
1이 돼야 하므로

83
00:05:16,810 --> 00:05:21,860
가장 윗 간선에 -0.5 대신 -1.5을 줍니다

84
00:05:21,860 --> 00:05:27,830
똑같은 방식으로 표를 채워보면

85
00:05:27,830 --> 00:05:31,320
신경망을 통해 AND 함수가

86
00:05:31,320 --> 00:05:34,190
표현됨을 확인할 수 있습니다

87
00:05:34,190 --> 00:05:38,180
단층 신경망은 지금까지 배운

88
00:05:38,180 --> 00:05:43,350
보통의 선형 분류기와 같습니다

89
00:05:43,350 --> 00:05:46,280
선형 분류기가 표현하지 못하는 게 뭐지요?

90
00:05:46,280 --> 00:05:49,200
OR는 가능하다고 했죠

91
00:05:49,200 --> 00:05:52,020
AND도 가능했죠

92
00:05:52,020 --> 00:05:53,700
표현 못하는 간단한 함수가 있나요?

93
00:05:54,710 --> 00:05:56,350
예제 하나 드릴게요

94
00:05:57,350 --> 00:06:00,760
선 하나만으로 플러스, 마이너스를
분리하는 건 불가능합니다

95
00:06:00,760 --> 00:06:02,730
이 함수는 XOR라고 합니다

96
00:06:02,730 --> 00:06:05,830
저는 모든 것에 대한 반례라고 부르는데요

97
00:06:05,830 --> 00:06:07,560
반례를 찾고 싶을 때

98
00:06:07,560 --> 00:06:10,220
제일 먼저 XOR를 대입해 봅니다

99
00:06:10,220 --> 00:06:14,940
이 경우 선형적 특징으론 충분하지 않아서

100
00:06:14,940 --> 00:06:18,380
비선형적 특징을 찾아야 합니다

101
00:06:18,380 --> 00:06:22,110
신경망이 활약을 하게 되는데
그 예를 지금부터 보죠

102
00:06:22,110 --> 00:06:25,040
XOR이 뭔지부터 복습할까요

103
00:06:25,040 --> 00:06:30,680
XOR는 x1이 참이고 x2가 거짓이거나

104
00:06:30,680 --> 00:06:35,300
NOT x2이거나 NOT x1일 때

105
00:06:35,300 --> 00:06:39,000
x1이 거짓, 또는 0이며 x2가 1일 때 1이 됩니다

106
00:06:39,000 --> 00:06:43,350
신경망으로 어떻게 표현할까요?

107
00:06:43,350 --> 00:06:47,650
첫 번째 항을 z1, 두 번째 항을 z2라고 합시다

108
00:06:49,500 --> 00:06:52,310
이제 신경망에서 직접 입력 x1, x2를

109
00:06:52,310 --> 00:06:56,512
통해 y를 예측하는 게 아니라

110
00:06:56,512 --> 00:07:01,660
중간값인 z1, z2부터 구한 다음
이를 통해 y를 예측합니다

111
00:07:03,040 --> 00:07:03,920
z1부터 보죠

112
00:07:03,920 --> 00:07:09,280
z1만을 예측하는 신경망을 어떻게 표현할까요

113
00:07:10,560 --> 00:07:14,100
좀 전에 설명드렸지만 한번 더 해보죠

114
00:07:14,100 --> 00:07:17,820
AND와는 조금 다릅니다

115
00:07:17,820 --> 00:07:23,480
반대값을 취해야 하니 x2에 -1을 주고

116
00:07:23,480 --> 00:07:26,690
x1에는 1, 여기는 0.5를 줍니다

117
00:07:26,690 --> 00:07:28,510
z1를 이렇게 표현할 수 있습니다

118
00:07:30,050 --> 00:07:35,663
z2에는 간선 x1에 마이너스 기호를 붙이고

119
00:07:35,663 --> 00:07:42,617
x1에서 z2로 가는 이 간선입니다
간선 x2-z2에 +1를 준 다음

120
00:07:42,617 --> 00:07:49,230
상수 간선에는 -0.5을 주면 z2이 완성됩니다

121
00:07:50,430 --> 00:07:55,450
마지막으로 z1과 z2가 있으면
그 둘을 OR하기만 하면 됩니다

122
00:07:55,450 --> 00:07:59,810
불 변수에 OR 하는 건 이미 알죠

123
00:07:59,810 --> 00:08:03,360
1, 1에 0.5를 빼줍니다

124
00:08:03,360 --> 00:08:08,280
의미 있는 순간입니다

125
00:08:08,280 --> 00:08:13,160
첫 번째 신경망을 만들어 봤습니다

126
00:08:13,160 --> 00:08:17,430
2층밖에 없어 아주 깊지는 않지만
그래도 놀랍습니다

127
00:08:19,370 --> 00:08:21,360
신경망을 처음으로 만들어 봤고요

128
00:08:21,360 --> 00:08:24,880
2층 신경망이었는데 일반적으로 신경망에는

129
00:08:24,880 --> 00:08:28,050
데이터 변환을 위한 수많은 층들이 존재합니다

130
00:08:28,050 --> 00:08:30,820
이런 변환을 통해 비선형 특징을 찾아내는데

131
00:08:30,820 --> 00:08:34,200
컴퓨터 비전에서 몇몇 예를 볼 겁니다

132
00:08:34,200 --> 00:08:36,100
신경망은 거의 50년 가깝게 우리 곁에 있었으니

133
00:08:36,100 --> 00:08:40,200
기계학습이 생겨난 시기와 비슷합니다

134
00:08:40,200 --> 00:08:44,030
하지만 90년대에 인기가 시들해졌는데

135
00:08:44,030 --> 00:08:46,890
연구자들이 신경망으로 그다지
정확도를 높이지 못했기 때문이죠

136
00:08:46,890 --> 00:08:49,740
10년 전쯤 모든 게 바뀌었는데

137
00:08:49,740 --> 00:08:51,910
두 가지 요인이 등장했기 때문입니다

138
00:08:51,910 --> 00:08:56,650
먼저 데이터가 훨씬 증가해서

139
00:08:56,650 --> 00:08:58,150
신경망에 층을 엄청나게 늘릴 수 있었습니다

140
00:08:58,150 --> 00:09:01,830
층이 늘어나면 데이터가 많아야 훈련이 가능하죠

141
00:09:01,830 --> 00:09:02,840
파라미터가 많으니까요

142
00:09:04,030 --> 00:09:07,050
6천만 파라미터의 신경망을 보게 될 겁니다

143
00:09:07,050 --> 00:09:09,370
그러니 훈련 데이터가 무척 많이 필요하죠

144
00:09:09,370 --> 00:09:12,310
최근 들어 이런 엄청난 데이터를

145
00:09:12,310 --> 00:09:14,830
웹 등 여러 채널을 통해 구할 수 있게 됐습니다

146
00:09:15,860 --> 00:09:20,840
두 번째로 컴퓨팅 자원이 발전하여

147
00:09:20,840 --> 00:09:22,940
딥 신경망이 가능해졌습니다

148
00:09:22,940 --> 00:09:25,760
신경망이 커지고 데이터가 늘어남에 따라

149
00:09:25,760 --> 00:09:30,550
빠른 컴퓨터와 GPU가 필요해졌습니다

150
00:09:30,550 --> 00:09:33,070
GPU는 원래 컴퓨터 게임 그래픽
가속을 위해 설계됐죠

151
00:09:33,070 --> 00:09:37,150
알고 보니 많은 데이터를 처리하는

152
00:09:37,150 --> 00:09:39,920
신경망을 만드는데 안성맞춤이었습니다

153
00:09:39,920 --> 00:09:41,570
GPU와

154
00:09:41,570 --> 00:09:44,800
딥 신경망 덕분에 모든 게 바뀌었습니다

155
00:09:44,800 --> 00:09:48,338
실생활에 큰 영향을 끼쳤죠

156
00:09:48,338 --> 00:09:52,359
[음악]