1
00:00:00,000 --> 00:00:03,847
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:03,847 --> 00:00:08,367
在这个模块中 我们讨论了协同过滤的基本概念

3
00:00:08,367 --> 00:00:13,883
和一系列不同的推荐系统 能够让我们

4
00:00:13,883 --> 00:00:19,280
通过人们的购买记录 来进行产品推荐

5
00:00:19,280 --> 00:00:23,840
我们研究了 在一些消费者和产品中

6
00:00:23,840 --> 00:00:28,860
在产品推荐系统的背景下 如何理解他们直接的关系

7
00:00:28,860 --> 00:00:32,560
回想一下电影推荐系统

8
00:00:32,560 --> 00:00:36,820
和你们在Ipython Notebook里面 研究的

9
00:00:36,820 --> 00:00:39,320
音乐推荐系统

10
00:00:39,320 --> 00:00:42,350
让我们重新回顾一下 机器学习的工作流程

11
00:00:42,350 --> 00:00:45,340
在我们推荐系统中

12
00:00:45,340 --> 00:00:47,400
什么是我们的训练数据

13
00:00:47,400 --> 00:00:50,614
是我们的客户

14
00:00:50,614 --> 00:00:56,885
产品 评分 这个表格

15
00:01:01,502 --> 00:01:07,084
我们所做的是 就是抽出一些特征

16
00:01:07,084 --> 00:01:10,882
比如说UserID用户ID product ID产品ID 这一对

17
00:01:15,910 --> 00:01:22,010
目标是 预测这些用户会对这些产品所给出的评分

18
00:01:22,010 --> 00:01:24,950
所以说 用户ID 产品ID 评分

19
00:01:24,950 --> 00:01:31,630
这就是我们的预测评分 也就是y帽

20
00:01:33,000 --> 00:01:35,850
如果我们仔细看 抱歉

21
00:01:35,850 --> 00:01:38,930
我应该说道 我们这个模型应该看的是什么

22
00:01:38,930 --> 00:01:44,415
这个模型 举个例子

23
00:01:44,415 --> 00:01:49,112
我们提到了很多模型 但是 我们会强调

24
00:01:49,112 --> 00:01:53,690
在矩阵因式分解课程中强调的是 因式分解

25
00:01:54,980 --> 00:01:58,280
矩阵因式分解有很多组参数

26
00:01:58,280 --> 00:02:02,770
w帽 他们是预测的参数

27
00:02:02,770 --> 00:02:05,260
就是表达预测参数的一个符号

28
00:02:05,260 --> 00:02:08,760
那什么是矩阵因式分解的参数呢

29
00:02:08,760 --> 00:02:12,120
包含了每个用户的特征

30
00:02:14,030 --> 00:02:17,067
还有每个产品的特征

31
00:02:19,446 --> 00:02:21,759
这就是我们的参数

32
00:02:21,759 --> 00:02:26,570
我们也提到了矩阵因式分解 的

33
00:02:26,570 --> 00:02:29,509
在这个例子中 除了

34
00:02:31,010 --> 00:02:35,620
我们用户ID 和产品ID 这些特征 我们可能会考虑到别的特征

35
00:02:35,620 --> 00:02:40,460
比如说用户年龄

36
00:02:40,460 --> 00:02:47,610
用户性别 产品描述 等等特征

37
00:02:47,610 --> 00:02:51,740
在这个例子中 我们可能会考虑对这些特征增加权重

38
00:02:51,740 --> 00:02:55,490
我会加入另外一个特征集

39
00:02:57,090 --> 00:03:00,100
假设是w0 这样能和w有所区分

40
00:03:00,100 --> 00:03:04,750
权重的特征集也会变成这个模型的参数

41
00:03:04,750 --> 00:03:09,600
我们会在这个课程中深入研究这些

42
00:03:09,600 --> 00:03:13,860
但是目标是 我们将会用我们预期的评分

43
00:03:13,860 --> 00:03:19,310
然后看模型能够很好地拟合数据

44
00:03:19,310 --> 00:03:23,180
我们所做的就是用实际的数据

45
00:03:23,180 --> 00:03:28,780
实际的评分 

46
00:03:30,150 --> 00:03:33,340
这些在我们的训练数据集中

47
00:03:33,340 --> 00:03:36,750
然后与预测的评分所比较

48
00:03:37,750 --> 00:03:43,042
所以说 我们提到过一种能够衡量

49
00:03:43,042 --> 00:03:47,938
预测评分和实际评分之间的误差方法 是残差平方和

50
00:03:50,526 --> 00:03:54,817
就像在回归中一样 这里还有一些别的衡量方法

51
00:03:54,817 --> 00:03:56,880
我们以后可能会说到

52
00:03:58,050 --> 00:04:02,259
重点是通过某些能够反映出 预测值和实际值之间的误差的手段

53
00:04:02,259 --> 00:04:06,367
来完成我们的机器学习的算法

54
00:04:06,367 --> 00:04:08,008
我们会把这个留到

55
00:04:08,008 --> 00:04:12,092
之后的矩阵因式分解部分详细讨论 具体算法是什么

56
00:04:12,092 --> 00:04:17,019
它所做的大概是不断地重复更新我们用户和产品的特征

57
00:04:17,019 --> 00:04:21,875
直到能够得到一个良好的预测

58
00:04:21,875 --> 00:04:24,960
使得预测值和真实值没有太大的误差

59
00:04:24,960 --> 00:04:29,247
在这个模块中你会学习到协同过滤

60
00:04:29,247 --> 00:04:32,410
这样你就能完善你的推荐系统

61
00:04:32,410 --> 00:04:35,180
你可以给你的家庭做一个礼物推荐系统

62
00:04:35,180 --> 00:04:37,740
让节日购物变得更简单

63
00:04:38,920 --> 00:04:42,625
或者你可以给你朋友做一个音乐推荐系统

64
00:04:42,625 --> 00:04:44,740
就像我们之前试做的一样

65
00:04:44,740 --> 00:04:48,297
反正协同过滤系统可以帮助你做很多酷酷的事情

66
00:04:48,297 --> 00:04:52,969
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community