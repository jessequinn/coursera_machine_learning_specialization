1
00:00:00,025 --> 00:00:04,892
[صوت] لقد بدأنا مع
وجود ألفا بشكل موحد،

2
00:00:04,892 --> 00:00:10,237
كمثل جميع نقاط التدريب، واحد فوق n، ونريد الآن تغييرها

3
00:00:10,237 --> 00:00:15,694
للتركيز أكثر على تلك نقاط البيانات الصعبة،
 حيث نقوم بالأخطاء.

4
00:00:15,694 --> 00:00:18,583
ولهذا، فإن السؤال، أين ينتج أخطاء عن ft،

5
00:00:18,583 --> 00:00:20,850
أو متى تكون نقاط البيانات ft صحيحة؟

6
00:00:20,850 --> 00:00:22,355
إذا كان يوجد في ft نقاط بيانات محددة،

7
00:00:22,355 --> 00:00:26,966
تكون فيها xi صحيحة،
 فإننا نود تقليل ألفا i، لأننا حصلنا عليها صحيحة.

8
00:00:26,966 --> 00:00:32,250
ولكن في حالة حصلنا على xi خاطئة،
 فإننا سنود زيادة ألفا i لدينا،

9
00:00:32,250 --> 00:00:37,400
ولهذا سنقوم بتصنيف منازلنا في أسلوب القرار التالي،
 ويؤدي بشكل أفضل في تلك المدخلات المحددة.

10
00:00:39,100 --> 00:00:44,020
ومجددًا، فإن نظرية AdaBoost
 تقدم إلينا بصيغة تهويل بشكل ما،

11
00:00:44,020 --> 00:00:46,100
حول كيفية تحديث الأحجام بالنسبة لi.

12
00:00:46,100 --> 00:00:49,640
ولكنك إن تفحصناها للحظات،
فسنرى أنها بديهية للغاية،

13
00:00:49,640 --> 00:00:51,980
وأنه يوجد شيء ما جيد.

14
00:00:51,980 --> 00:00:53,560
ولهذا، دعونا نلقِ نظرة سريعة عليها.

15
00:00:53,560 --> 00:00:59,600
ولهذا، فهي توضح حصول ألفا i على تحديث،
 يعتمد على إذا ما كانت ft

16
00:00:59,600 --> 00:01:05,760
قد حصلت على نقاط البيانات بشكل صحيح،
 وبشكل صائب، أو أنها قامت به بشكل خطأ.

17
00:01:07,140 --> 00:01:10,040
وفي هذه الحالة،
 فإننا سنلاحظ أننا سنقوم بزيادة حجم نقاط البيانات

18
00:01:10,040 --> 00:01:13,400
عندما نقوم بأخطاء
، وسنقوم بتقليل حجمها عندما نقوم بذلك على الوجه الصحيح.

19
00:01:13,400 --> 00:01:14,780
دعونا نلقِ نظرة على هذا.

20
00:01:16,200 --> 00:01:19,590
دعونا نستعرض واحد xi ودعونا نفترض
 أننا حصلنا عليه بشكل صحيح.

21
00:01:21,710 --> 00:01:26,510
ولهذا، فهي على السطر العلوي، ولاحظ أن المعادلة تعتمد عليها،

22
00:01:26,510 --> 00:01:30,100
مهما كانت المعاملات التي تم تعيينها لهذا المصنف،

23
00:01:30,100 --> 00:01:31,730
ولهذا، كان المصنف جيدًا.

24
00:01:31,730 --> 00:01:33,170
قمنا فقط بتغيير الطريقة للأكثر،

25
00:01:33,170 --> 00:01:36,200
ولكن إذا كانت المصنفات سيئة،
 فسنقوم بتغيير الأحجام للأقل.

26
00:01:36,200 --> 00:01:39,902
لذا دعونا نقل إن المصنف كان جيدًا،
وقمنا بإعطاء حجمه 2.3.

27
00:01:39,902 --> 00:01:43,310
لذا، ما نقوم به هنا، هو أننا نقوم برؤية الصيغة،

28
00:01:43,310 --> 00:01:48,040
نقوم بضرب ألفا i في e مرفوعًا لأس (Ŵ (t-،
 والذي يكون 2.3.

29
00:01:48,040 --> 00:01:53,310
وإذا استخدمت الآلة الحاسبة، فستلاحظ أن الناتج 0.1.

30
00:01:53,310 --> 00:01:56,395
ولهذا، قمنا بنقل نقاط البيانات إلى الجانب الصحيح الخاص بنا،

31
00:01:56,395 --> 00:02:01,040
وقمنا بضرب الحجم لنقاط البيانات تلك في 0.1،
 ولذا قمنا بالقسمة على 10.

32
00:02:01,040 --> 00:02:02,180
إذًا، ما التأثير الذي يُحدثه ذلك؟

33
00:02:03,570 --> 00:02:07,945
سنقوم بتقليل أهمية نقاط البيانات هذه،

34
00:02:07,945 --> 00:02:14,870
ff, xi, وyi، ولذا، فهي نقاط البيانات المحددة تلك.

35
00:02:16,180 --> 00:02:20,450
ولذا، دعونا نلقِ نظرة، على حالة
تكون فيها نقاط البيانات صحيحة،

36
00:02:20,450 --> 00:02:23,480
لأن التكلفة التي تعلمناها عشوائية.

37
00:02:23,480 --> 00:02:27,860
ولهذا، فإنها ستبقى صفرًا،
 كما قمنا بمناقشة ذلك في الشرائح القليلة السابقة.

38
00:02:27,860 --> 00:02:32,144
ولهذا، فإن الحجم الكلي لها 0.5 هو الحجم 0.

39
00:02:32,144 --> 00:02:37,928
ونقوم في هذه الحالة، بضرب المعامل L5،
 في e مرفوعة لأس -0،

40
00:02:37,928 --> 00:02:40,920
ويساوي ذلك 1، فماذا يعنيه ذلك؟

41
00:02:40,920 --> 00:02:45,060
يعني أنني عندما أقوم بجعل الأهمية
 لنقاط البيانات تلك متساوية،

42
00:02:45,060 --> 00:02:49,910
فإن ذلك يبدو منطقيًا،

43
00:02:49,910 --> 00:02:53,110
ولهذا، تم تصنيف ذلك على أنه مروع،
وأعطيناه حجمًا يساوي 0،

44
00:02:53,110 --> 00:02:56,830
وسنقوم بتجاهلها، وبما أننا سنقوم بتجاهلها،
 فلن تقوم بتغيير أي شيء

45
00:02:56,830 --> 00:03:00,770
حول كيفية تقييم جميع نقاط البيانات،
 وسنقوم فقط بالإبقاء عليها كما هي،

46
00:03:00,770 --> 00:03:03,680
كما لو أنه لم يحدث أي شيء،
 حيث لم يتغير أي شيء في كامل مجموعتها.

47
00:03:04,970 --> 00:03:09,490
ودعونا الآن نلقِ نظرة على الحالة الأخرى،
عندما نقوم بأخطاء بالفعل،

48
00:03:09,490 --> 00:03:14,980
ولهذا دعونا نقل إن لدينا xi غير صحيح،
لأننا قمنا بخطأ.

49
00:03:16,090 --> 00:03:18,820
ونحن في هذه الحالة، على الخط الثاني هنا،

50
00:03:18,820 --> 00:03:23,587
حيث إن كان مصنفًا جيدًا،
فسيكون به Ŵt يساوي 2.3،

51
00:03:23,587 --> 00:03:29,269
ومن ثم، فإننا سنقوم بضرب الحجم بكل مرفوع لأس يساوي 2.3.

52
00:03:29,269 --> 00:03:36,800
ولهذا فإن e مرفوعة لأس 2.3، حيث إن قمت بعملية
حسابية تساوي 9.98، فستكون بالتقريب 10.

53
00:03:36,800 --> 00:03:38,580
ولذا، يعد ذلك أكبر بعشر مرات.

54
00:03:38,580 --> 00:03:44,700
ولهذا، ما نقوم به هو زيادة الأهمية لهذا الخطأ بشكل جلي.

55
00:03:47,400 --> 00:03:50,170
ولهذا فإن المصنف التالي سيهتم بشكل أكبر بنقاط البيانات المحددة تلك،

56
00:03:50,170 --> 00:03:51,800
حيث إنها كانت خاطئة.

57
00:03:53,570 --> 00:03:57,920
وأخيرًا، وبشكل سريع جدًا، ما الذي يحدث إذا قمنا بخطأ،

58
00:03:57,920 --> 00:04:01,960
ولكن يكون لدينا هذا المصنف العشوائي
 والذي به حجم يساوي 0، والذي لا نآبه له.

59
00:04:01,960 --> 00:04:04,422
ولذا فإن ناتج الضرب هنا يساوي e مرفوعًا ل0.

60
00:04:04,422 --> 00:04:09,670
والذي مجددًا يساوي 1،
 مما يعني أن الأهمية لكلٍ من نقاط البيانات تلك متساوية.

61
00:04:12,360 --> 00:04:17,740
ولهذا، فهذا أمر جيد جدًا، حيث نرى الآن
هذا التحديث الرائع من AdaBoost،

62
00:04:17,740 --> 00:04:21,310
والذي يسبب زيادة منطقية لأحجام نقاط البيانات،

63
00:04:21,310 --> 00:04:24,740
حيث نقوم بالأخطاء ويقلل من تلك التي لا نقوم فيها بأخطاء في المحاكي

64
00:04:24,740 --> 00:04:28,380
وسنقوم باستخدامها في خوارزمية AdaBoost الخاصة بنا.

65
00:04:29,990 --> 00:04:32,300
ولذا، إن قمنا بتحديث الخوارزمية الخاصة بنا،

66
00:04:32,300 --> 00:04:35,590
أو قمنا بتكديسها من خلال أحجام موحدة،
 فسنتعلم المصنف f من t.

67
00:04:35,590 --> 00:04:40,090
قمنا بتحديثها، أو حساب معاملها Ŵt.

68
00:04:40,090 --> 00:04:43,160
ويمكننا الآن تحديث الأحجام لنقاط البيانات، ألفا i.

69
00:04:44,190 --> 00:04:48,029
باستخدام الصيغة المبسطة من الشريحة السابقة
 والتي تزيد من حجم الأخطاء

70
00:04:48,029 --> 00:04:51,414
وتقلل الأحجام للتصنيفات الصحيحة.

71
00:04:51,414 --> 00:04:55,539
[موسيقى]