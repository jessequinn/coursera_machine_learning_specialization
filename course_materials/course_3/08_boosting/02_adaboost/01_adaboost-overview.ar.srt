1
00:00:00,000 --> 00:00:04,680
[موسيقى]

2
00:00:04,680 --> 00:00:08,562
في هذه الوحدة، سنقوم بالحديث عن
خوارزمية تعزيز محددة تسمى

3
00:00:08,562 --> 00:00:09,710
AdaBoost.

4
00:00:09,710 --> 00:00:13,340
AdaBoost هي واحدة من أوائل
خوارزميات التعلم الآلي لتعزيزه.

5
00:00:13,340 --> 00:00:14,490
وهي مفيدة للغاية.

6
00:00:14,490 --> 00:00:16,710
وبسيطة للغاية في تنفيذها.

7
00:00:16,710 --> 00:00:18,400
وكذلك فعالة جدًا.

8
00:00:18,400 --> 00:00:18,940
وهناك آخرون.

9
00:00:18,940 --> 00:00:23,087
سأذكر واحدة أخرى مثيرة للاهتمام
في نهاية الوحدة ولكن

10
00:00:23,087 --> 00:00:24,825
دعونا نبدأ مع AdaBoost.

11
00:00:26,040 --> 00:00:29,332
هذه هي خوارزمية AdaBoost الشهيرة،

12
00:00:29,332 --> 00:00:35,690
والتي أنشئت بواسطة فرويند وشابيري
في عام 1999، وهي خوارزمية مدهشة ومفيدة.

13
00:00:35,690 --> 00:00:38,280
لذا يمكنك البدء برؤية كل
نقطة بيانات بنفس الطريقة.

14
00:00:38,280 --> 00:00:40,040
إذًا أنت لا تعرف أيها الأصعب،
وأيها الأسهل.

15
00:00:40,040 --> 00:00:41,310
فجميعها لها نفس الوزن.

16
00:00:41,310 --> 00:00:46,500
لذا حتى تتمكن من البدء في العمل عليها،
سوف نبدأ معها بوزن 1 على

17
00:00:46,500 --> 00:00:51,480
N، لأن ذلك يجعل كل شيء
يعمل بشكلٍ أفضل قليلًا نوعًا ما.

18
00:00:51,480 --> 00:00:54,995
وسوف نتحدث عن السبب بعد بضع شرائح،
ولكن

19
00:00:54,995 --> 00:00:58,745
نبدأ مع كافة نقاط البيانات لها
نفس ما يسمى بالوزن الموحد.

20
00:00:58,745 --> 00:01:01,455
لذا في هذه الحالة α تساوي واحدًا على n.

21
00:01:01,455 --> 00:01:06,595
ثم لكل تكرار من AdaBoost،
بينما تتابع، ستكتشف أول

22
00:01:07,705 --> 00:01:10,555
ختم قرار أو أول مصنف بسيط
أو مصنف الوزن الأول،

23
00:01:10,555 --> 00:01:12,595
والمصنف الثاني، أو
الثالث حتى الوصول إلى T.

24
00:01:12,595 --> 00:01:17,665
ما نقوم به هو أننا نحدد ft
على البيانات المرجحة α i.

25
00:01:19,030 --> 00:01:22,775
إذًا هذه هي البيانات،
هي الأوزان التي تبدأ مع 1 على N ولكن

26
00:01:22,775 --> 00:01:24,771
تصبح مختلفة على مر الزمن.

27
00:01:24,771 --> 00:01:31,132
ثم نحسب المعامل w hat t

28
00:01:31,132 --> 00:01:37,720
لهذا التصنيف الجديد ft الذي حددناه.

29
00:01:37,720 --> 00:01:40,770
وبعد ذلك يمكننا إعادة حساب الأوزان α i.

30
00:01:42,070 --> 00:01:47,213
ثم نستمر في العمل، وأخيرً بمجرد الانتهاء
نقول إن التنبؤ y hat

31
00:01:47,213 --> 00:01:52,860
هو علامة الجمع المرجح لـ f1 وf2 وf3

32
00:01:52,860 --> 00:01:57,844
وf4 مرجحة بهذه المعاملات
التي تعلمناها مما سبق.

33
00:01:59,210 --> 00:02:02,730
لذلك هناك اثنان من المسائل الأساسية
التي نكون بحاجة إلى معالجتها

34
00:02:02,730 --> 00:02:05,240
عندما نفكر في AdaBoost.

35
00:02:05,240 --> 00:02:10,616
واحدة هي كيف يمكنك حساب
المعامل w hat t،

36
00:02:10,616 --> 00:02:16,125
دعونا ندعو تلك المسألة 1
في وحدتنا اليوم.

37
00:02:16,125 --> 00:02:22,330
وبالتالي فإن المسألة 1 هي ما مدى
ثقتي في ftF في هذه الحالة؟

38
00:02:23,840 --> 00:02:26,830
لذا إن وثقت في ft كثيرًا،
ينبغي أن أعطى وزنًا عاليًا جدًا.

39
00:02:26,830 --> 00:02:29,720
وإذا وثقت ft بشكل قليل جدًا،

40
00:02:29,720 --> 00:02:34,220
ينبغي إعطاء وزن منخفض جدًا،
أو معامل منخفض جدًا، كما يجب القول.

41
00:02:34,220 --> 00:02:39,850
ثم هناك المسألة 2 حول كيف يمكنك
إعادة حساب هذا الوزن في نقاط البيانات؟

42
00:02:39,850 --> 00:02:41,311
لنطلق على هذا المسألة 2.

43
00:02:41,311 --> 00:02:46,891
وهكذا، تكون المسألة 2 هنا هي

44
00:02:46,891 --> 00:02:52,031
كيف نرجح الأخطاء بشكل أكبر؟

45
00:02:52,031 --> 00:02:54,291
حسنًا نحن نرغب في زيادة
ترجيحات الأخطاء.

46
00:02:54,291 --> 00:02:58,669
وبالتالي في الجزء الرئيسي من هذه الوحدة،
سنتحدث بشأن كيفية

47
00:02:58,669 --> 00:03:02,398
حسابك لقيمة w hat t
وكيف يمكننا تحديث قيم α i

48
00:03:02,398 --> 00:03:07,610
وسيكون الأمر بسيطًا للغاية
وبديهي بشكل نسبي ومفيدًا جدًا.

49
00:03:07,610 --> 00:03:11,869
[موسيقى]