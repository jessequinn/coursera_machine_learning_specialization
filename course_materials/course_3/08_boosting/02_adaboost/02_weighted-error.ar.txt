[موسيقى] >> دعونا نبدأ الحديث حول كيفية
القيام بحساب w hat t. وهذه الكمية حدسية، وهي تركز على
مدى معرفتنا وثقتنا في ft. التصنيف الذي تعلمناه في التكرار. لذا، على وجه التحديد،
إذا كانت ft جيدة، ونحن نحبها، وهي تقوم بعمل جيد في البيانات لدينا،
فسنريد أن تكون w hat t كبيرة. وفي الواقع، إذا كانت ft لديها دقة
كبيرة حقًا، ومعدل خطأ منخفض جدًا، فسنريد wt أن تكون كبيرة جدًا. ومع ذلك إذا كانت ft سيئة حقًا، إذا كان حقًا سيئة في حساب
التنبؤات، ينبغي علينا خفض ترجيحها. يجب ألا نثق بهذا التصويت بشكلٍ خاص. لذلك بعبارة أخرى، كيف نقيس
إذا ما كان التصنيف جيدًا أم لا؟ وكما قلنا، فإن ft تكون جيدة إذا كان
لديها خطأ تدريب منخفض. ولكن عليك أن تتذكر أن
لدينا بيانات مرجحة. لذا فما نهتم به حقًا هو مدى دقتها
في التعامل مع البيانات المرجحة. على سبيل المثال، إذا كنا نقوم بترجيح
نقاط البيانات محددة أكثر لأنها حقًا عالية، وهي ترتكب الكثير من الأخطاء
عليها، فنحن نريد أن نتأكد أن التصنيف لديه معدل خطأ منخفض
في تلك الأخطاء الصعبة للغاية. ولذا دعونا نتعرف على قياس الخطأ
في البيانات المرجحة. إن قياس الخطأ والبيانات المرجحة يشبه إلى حدٍ كبير
قياس الخطأ في البيانات العادية. لديك نقطة بيانات. على سبيل المثال، كان السوشي رائعًا وهو مصنف كإيجابي،
ولكن الآن لدينا ترجيح. وفي هذه الحالة، α، التي يحتمل أن تكون قيمتها 1.2. لذا فهذه نقطة بيانات يمكن القول
إنها ذات أهمية أعلى من المتوسط. لذا فنحن نريد قياس الإجمالي
المرجح للأمثلة الصحيحة والإجمالي المرجح للأخطاء. ولذلك سنأخذ التصنيف الذي عرفناه، f لـ t،
ونقوم بتغذية هذا التقييم، وفي هذه الحالة، السوشي كان رائعًا، ولكن يمكننا إخفاء التسمية،
وفي هذه الحالة كانت إيجابية. والآن نقوم بمقارنة التنبؤ. على سبيل المثال، دعنا نقول إن y
hat كان زائد واحد لهذا الإدخال. والأمر نفسه إذا كان لدينا اثنان من التسميات الصحيحة،
لذا نقوم بإضافة الترجيح 1.2 إلى ترجيح
الأمثلة الأخرى الصحيحة التي رأيناها. إذًا هذا رائع. ولكن لنفترض أن لدينا نقطة بيانات أخرى. كان الطعام مقبولًا، الذي
يصنف حقًا كسلبي وقد تحدثنا عن هذا المثال من قبل. نقوم بتغذية "الطعام كان مقبولًا" للتصنيف. ونقوم بإخفاء التسمية. ناقص 1.
ولكن تصنيفنا يصبح مشوشًا. وهو لا يعرف المرجعية الثقافية،
كان الطعام مقبولًا، وهو يعتقد أنها مثال إيجابي،
وy hat هو زائد 1، وهذا خطأ. لذا نأخذ ترجيح نقطة البيانات هذه 0.5 ونقوم بإضافتها إلى
الترجيح الكلي للأخطاء. لذا نستمر في إضافة ترجيح الأخطاء
مقابل ترجيح التصنيفات الصحيحة. ونستخدم ذلك لقياس الخطأ. والآن بعد أن شهدنا فكرة بديهية عما يكون عليه الخطأ المرجح،
دعنا نكتب المعادلات للخطأ مرجح، حتى يمكننا أن نكون متأكدين
مما إذا كان علينا أن ننفذه. إذًا أول شيء نحتاج إليه هو قياس
الترجيح الكلي لكل الأخطاء، لذا فإن مجموع أخطائنا لترجيح
نقاط البيانات تلك . لذلك هذا هو المجموع عبر نقطة البيانات،
إذًا i تساوي 1 حتى N، من مؤشر يقول،
هل كان هذا خطأ؟ إذًا هلy hat مختلفة عن yi؟ لذا فإن هذا يقيس إذا ما كان هذا
خطأ، وإذا كان ذلك خطأ فإننا لا نقوم بحسابه كخطأ، ولكن نحسبه
وفقًا للترجيح الذي تمتلكه نقطة البيانات تلك. لذا سنقوم بترجيح تلك المساهمة
بواسطة α i. والآن، لحساب الخطأ،
سنقوم بتطبيعه حتى يصبح رقمًا بين الصفر والواحد وبالتالي علينا أن قسمته على
الترجيح الكلي لكافة نقاط البيانات. لذا فهو المجموع على i تساوي 1 حتى N
لترجيح كافة نقاط بيانات i. وهذه هي الكميتان اللتان نهتم بهما حقًا، ويمكن الإشارة إلى الخطأ المرجح
بالمجموع مقسومًا على ترجيح الأخطاء مقسومًا على
الترجيح الكلي لجميع نقاط البيانات. الأمر بسيط للغاية، أفضل خطأ ممكن
قد تأمل في الحصول عليه هو 0.0. الآن، أسوأ خطأ هو 1.0، مما يعني أننا نصنع أخطاءً
في كل مكان. ولكن لاحظ أنه إذا كنا نصنع
أخطاء في كل مكان، إذا قمنا ببدء حريق جماعي
فسنضع كل شيء في نصابه الصحيح. لذا إحدى الطرق للتفكير في ذلك أنه
في أسوأ الحالات الممكنة ببعض الطرق كيف يعمل التصنيف العشوائي. لذلك فإن التصنيف العشوائي سوف
يحصل على خطأ 0.5، وقد ناقشنا هذا في الدورة الأولى حول
كيف يحصل التصنيف العشوائي على خطأ 0.5 لمشكلة تصنيف
ثنائية مثل هذه. لذلك الآن بعد أن ناقشنا الخطأ المرجح،
دعونا ننظر في كيف يمكننا تحديث المعامل w hat
t للدالة f التي عرفناها. >> [موسيقى]