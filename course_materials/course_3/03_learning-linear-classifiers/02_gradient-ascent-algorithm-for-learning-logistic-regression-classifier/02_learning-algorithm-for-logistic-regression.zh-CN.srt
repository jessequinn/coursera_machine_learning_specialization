1
00:00:00,058 --> 00:00:04,547
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community

2
00:00:04,547 --> 00:00:05,420
好的，多么令人兴奋

3
00:00:05,420 --> 00:00:09,840
让我们回忆一下梯度下降，它讲了些什么

4
00:00:09,840 --> 00:00:13,050
离散模型是

5
00:00:13,050 --> 00:00:16,870
最大化似然函数和估计值

6
00:00:16,870 --> 00:00:19,260
我们可以解决一些数学问题

7
00:00:19,260 --> 00:00:23,380
现在，让我们深入学习并看一看

8
00:00:23,380 --> 00:00:24,240
逻辑回归的实际学习算法

9
00:00:24,240 --> 00:00:26,110
这个学习算法相当的简单

10
00:00:27,130 --> 00:00:30,888
因此，尽管我们已经了解了一些数学表达式，现在我们将

11
00:00:30,888 --> 00:00:32,968
通过编写几行代码来实现该算法

12
00:00:34,512 --> 00:00:38,404
逻辑回归的最终梯度下降算法

13
00:00:38,404 --> 00:00:42,924
我们需要做的就是对每一个参数wj求偏导

14
00:00:42,924 --> 00:00:45,690
那似然函数对参数wj求偏导是什么样的

15
00:00:45,690 --> 00:00:48,160
另外，求该导数

16
00:00:48,160 --> 00:00:51,670
需要对似然函数求对数，即对数似然

17
00:00:51,670 --> 00:00:53,580
我讲解释一下为什么是这样

18
00:00:53,580 --> 00:00:58,490
在稍后的高级课程部分，这是选修的

19
00:00:58,490 --> 00:01:00,830
对似然函数求导

20
00:01:02,320 --> 00:01:06,310
似然函数的导数等于

21
00:01:06,310 --> 00:01:08,930
数据点的和，我们将考虑每个数据点

22
00:01:08,930 --> 00:01:12,620
是否对导数有影响，一些会使导数变大

23
00:01:12,620 --> 00:01:16,610
一些会使导数变小，但我们要对他们求和

24
00:01:16,610 --> 00:01:24,350
指示函数表示后的结果是不同的

25
00:01:24,350 --> 00:01:29,410
数据点加1，表明该点是正的

26
00:01:29,410 --> 00:01:32,510
所以我要在底部指定它

27
00:01:34,090 --> 00:01:35,290
让我们拿笔标记一下

28
00:01:36,550 --> 00:01:43,410
这个函数表明输出为1

29
00:01:43,410 --> 00:01:48,020
如果yi为正样本

30
00:01:48,020 --> 00:01:55,160
如果yi为负样本输出为0

31
00:01:55,160 --> 00:01:57,190
这就是指示函数的意思

32
00:01:57,190 --> 00:02:02,050
这就是此处的定义

33
00:02:02,050 --> 00:02:04,180
这是正样本吗？

34
00:02:04,180 --> 00:02:09,253
第二部分，指示函数值和

35
00:02:09,253 --> 00:02:11,646
无模型的预测结果不同

36
00:02:11,646 --> 00:02:16,639
模型预测xi为正的概率是多少

37
00:02:20,508 --> 00:02:25,181
换句话说，这与真实值不同

38
00:02:25,181 --> 00:02:30,700
这是一个正样本，模型的似然也将是一个正例

39
00:02:30,700 --> 00:02:34,490
对特征值xj加权重

40
00:02:34,490 --> 00:02:36,960
例如，这是awesomes的个数

41
00:02:36,960 --> 00:02:40,260
所以如果之后的点有很多awesomes

42
00:02:40,260 --> 00:02:43,430
将会对导数值产生较大影响

43
00:02:43,430 --> 00:02:45,310
因为系数将扩大20倍

44
00:02:45,310 --> 00:02:50,500
如果我们有0个awesomes，将不会有任何影响

45
00:02:50,500 --> 00:02:54,325
因为无论系数大还是小都不会有什么区别

46
00:02:54,325 --> 00:02:55,685
这就是我们这样加权的原因

47
00:02:56,805 --> 00:03:01,007
这就是我们将要实现的求导

48
00:03:01,007 --> 00:03:05,829
[背景音乐]
翻译: RyukaSuu |审阅: 19waa
Coursera Global Translator Community