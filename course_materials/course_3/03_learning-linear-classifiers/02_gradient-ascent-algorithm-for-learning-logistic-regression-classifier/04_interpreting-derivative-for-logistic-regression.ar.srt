1
00:00:00,000 --> 00:00:04,064
[موسيقى]

2
00:00:04,064 --> 00:00:08,480
حسنًا، فقد رأينا مثال رقمي حول كيفية
حساب تلك المشتقات.

3
00:00:08,480 --> 00:00:11,630
إنها عمليات حسابية بسيطة للغاية.

4
00:00:11,630 --> 00:00:15,030
والآن، دعونا نعد إلى تفسير ما
يقصد بالمشتقة.

5
00:00:15,030 --> 00:00:20,920
لنفترض أن لدينا معلمة محددة
نحاول تحديثها،وهي Wj

6
00:00:20,920 --> 00:00:25,830
ولدينا نقطة بيانات محددة وهي xi،
وبالنظر إلى قيمتها

7
00:00:25,830 --> 00:00:30,400
يتضح أن في xi فإن (hj(xi
تساوي القيمة 1.

8
00:00:30,400 --> 00:00:32,750
لنفترض أن هذا ما قد حدث،

9
00:00:32,750 --> 00:00:37,980
لذا، ما القيمة التي لدى نقطة البيانات هذه
على المستوى الكلي للمشتقة؟

10
00:00:37,980 --> 00:00:42,890
فإذا أطلقنا على هذه القيمة المسمى Δi،

11
00:00:42,890 --> 00:00:47,450
واخترت أن تكون قيمة (hj(xi هي 1
 حتى لا نقلق بعد ذلك

12
00:00:47,450 --> 00:00:51,150
حيال قيمة السمة، ونتمكن من التركيز
على الاختلاف فقط.

13
00:00:51,150 --> 00:00:53,180
ودعونا نفسر هذا الاختلاف.

14
00:00:53,180 --> 00:00:57,810
لذا، دعونا ننظر أولَا إلى الحالة حيث
تكون قيمة yi موجبة،

15
00:00:58,830 --> 00:01:01,850
حيث أن هذا مثال تدريب إيجابي.

16
00:01:01,850 --> 00:01:07,490
ويؤكد النموذج الذي لدينا أن هذا
مثال تدريب إيجابي.

17
00:01:07,490 --> 00:01:13,030
لذا، يفترض أن الاحتمالية y = +1،
تساوي 1 تقريبًا.

18
00:01:13,030 --> 00:01:15,060
لنفسر ما يحدث هنا.

19
00:01:15,060 --> 00:01:19,850
في هذه الحالة فإن Δi ستكون

20
00:01:19,850 --> 00:01:25,210
مساوية للفرق بين 1،

21
00:01:25,210 --> 00:01:29,430
حيث أن دالة المؤشر مستبعدة هنا،
والاحتمالية هنا

22
00:01:29,430 --> 00:01:35,230
والتي تساوي 1 تقريبًا، وبالتالي فهذه
المعادلة ستساوي صفرًا تقريبًا.

23
00:01:35,230 --> 00:01:39,960
وبعبارة أخرى، فإن نقطة
البيانات موجبة،

24
00:01:39,960 --> 00:01:43,070
ويعمل النموذج من منطلق أن هذه
نقطة بيانات موجبة.

25
00:01:43,070 --> 00:01:50,271
لذا، فكون القيمة هنا هي صفر، فإن هذا
يعني لا تغير أي شيء.

26
00:01:50,271 --> 00:01:54,510
ووفقًا لمنظور هذه المعلمة، لا
يجب تغيير أي شيء.

27
00:01:56,260 --> 00:01:57,900
مما يجعل الأمر منطقيًا.

28
00:01:57,900 --> 00:01:59,070
لقد فهمت الأمر بشكل صحيح.

29
00:01:59,070 --> 00:02:02,450
دعونا نرى ما قد يحدث إذا فهمت
الأمر بشكل خاطئ تمامًا.

30
00:02:02,450 --> 00:02:07,540
وهذه هي الحالة الثانية، حيث يوجد
مثال تدريب إيجابي ولكن

31
00:02:07,540 --> 00:02:10,800
الاحتمالية y = +1 تساوي القيمة 0 تقريبًا.

32
00:02:10,800 --> 00:02:14,300
ونحن نفهم مثال التدريب هذا
بشكل خاطئ تمامًا.

33
00:02:14,300 --> 00:02:18,846
في هذه الحالة فإن Δi هي الفرق بين

34
00:02:18,846 --> 00:02:23,040
المؤشر والذي هو القيمة 1

35
00:02:23,040 --> 00:02:28,590
والاحتمالية هنا تساوي القيمة 0، لذا فإن
المعادلة هنا تساوي 1 تقريبًا.

36
00:02:28,590 --> 00:02:30,420
لذا، فإن Δi كبيرة حقًا.

37
00:02:30,420 --> 00:02:33,990
وماذا يعني هذا؟

38
00:02:33,990 --> 00:02:38,560
هذا يعني أن نقطة البيانات تلك
تتطلب أن نقوم بزيادة

39
00:02:40,930 --> 00:02:45,500
المعامل Wj، وهو المعامل
الذي حاولنا زيادته.

40
00:02:45,500 --> 00:02:52,990
ويشير ذلك إلى دفع المشتقة لأعلى، وإضافة القيمة
دلتا التي تجعل من المعادلة إيجابية.

41
00:02:52,990 --> 00:02:58,270
وتذكر أن إذا كانت قيمة (hj(x
تساوي رقمًا موجبًا

42
00:02:58,270 --> 00:03:02,080
وتم ضربها في معامل أكبر، لأننا
جعلنا قيمتها أكبر قليلًا،

43
00:03:02,080 --> 00:03:07,676
فهذا يعني أن مجموع hi

44
00:03:07,676 --> 00:03:14,490
يصبح أكبر، مما يعني أن الاحتمالية

45
00:03:14,490 --> 00:03:20,630
(y=+1|xi,w) قيمتها تزيد أيضًا.

46
00:03:20,630 --> 00:03:22,070
وهذا أمر بديهي للغاية.

47
00:03:23,110 --> 00:03:26,910
لذا، إذا فهمنا نقطة البيانات بشكل خاطئ،
فسنحصل على Δi الموجبة هذه

48
00:03:26,910 --> 00:03:29,430
مما يؤدي إلى زيادة المعلمة، مما
يؤدي إلى زيادة المجموع

49
00:03:29,430 --> 00:03:32,060
مما يؤدي في الخطوة التالية

50
00:03:32,060 --> 00:03:36,090
إلى جعل الاحتمالية الموجبة لنقطة البيانات
هذه ذات قيمة أعلى.

51
00:03:37,140 --> 00:03:39,130
لذا، سنذهب في الاتجاه الصحيح.

52
00:03:39,130 --> 00:03:44,060
والآن، دعونا نخوض في هذا الأمر بشكل أسرع قليلًا،
حيث يمكننا النظر في حالة حيث

53
00:03:44,060 --> 00:03:47,390
تكون قيمة yi سالبة، وسنحصل على نفس
القيمة ولكن بعلامة معكوسة.

54
00:03:47,390 --> 00:03:50,450
إذن، على سبيل المثال، إذا
كانت قيمة yi سالبة

55
00:03:50,450 --> 00:03:55,060
ولكني أفهم عملية التنبؤ بشكل صحيح،
حيث أن هذه نقطة بيانات سالبة.

56
00:03:55,060 --> 00:03:58,757
فسنرى أن Δi تساوي تقريبًا

57
00:03:58,757 --> 00:04:02,410
القيمة 0، مما يعني ألا
تغير أي شيء.

58
00:04:02,410 --> 00:04:06,920
فهذا منطقي، لقد حصلت على كل شيء بشكل صحيح،
فلما قد أغير أي شيء؟

59
00:04:06,920 --> 00:04:12,430
ومع ذلك، في حالة كون نقطة
البيانات سالبة، ولكن

60
00:04:12,430 --> 00:04:17,840
عملية التنبؤ التي قمت بها كانت بناءً على
نقطة بيانات إيجابية، فإن Δi

61
00:04:17,840 --> 00:04:22,760
ستكون الفرق بين المؤشر والذي
في تلك الحالة يساوي 0،

62
00:04:22,760 --> 00:04:25,960
والاحتمالية والتي تساوي 1 تقريبًا.

63
00:04:25,960 --> 00:04:30,500
لذا فإن Δi هذه ستكون سالبة،
وتساوي تقريبًا القيمة -1.

64
00:04:30,500 --> 00:04:36,752
مما يؤدي إلى تناقص قيمة Wj

65
00:04:36,752 --> 00:04:41,320
مما يعني أن مجموع

66
00:04:41,320 --> 00:04:47,090
القيمة xi سيتناقص

67
00:04:47,090 --> 00:04:52,620
وسيؤدي إلى تناقص قيمة الاحتمالية

68
00:04:52,620 --> 00:04:57,187
(y=+1|xi,w)

69
00:04:57,187 --> 00:05:00,814
.

70
00:05:00,814 --> 00:05:01,930
رائع.

71
00:05:01,930 --> 00:05:07,260
إذا كانت نقطة بيانات سالبة وتم فهمها بشكل خاطئ،
فإننا سنقلل قيمة المعامل

72
00:05:07,260 --> 00:05:10,870
لجعل احتمالية كونه موجبًا أقل

73
00:05:10,870 --> 00:05:12,280
وزيادة احتمالية كونه سالبًا.

74
00:05:13,710 --> 00:05:14,240
رائع.

75
00:05:14,240 --> 00:05:19,340
فقد خضنا خلال القليل من التفسير حول
كيف يمكن لمعامل التدرج هذا

76
00:05:19,340 --> 00:05:24,930
أن يساعدنا في دفع المعاملات بقيم أكبر
بالنسبة لأمثلة التدريب الموجبة.

77
00:05:24,930 --> 00:05:29,001
ودفعها بقيم أٌصغر في حالات
أمثلة التدريب السالبة،

78
00:05:29,001 --> 00:05:32,698
وهو بالضبط ما كنا نريده بالنسبة
لدالة المجموع تلك.