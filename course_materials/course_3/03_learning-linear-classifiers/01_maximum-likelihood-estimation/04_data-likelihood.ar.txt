[موسيقى] قبل أن نتابع إلى الهبوط التدريجي نحن بحاجة إلى معرفة مقياس
الجودة الذي نحاول تحسينه . حيث إن مقياس الجودة هو الذي
سيستدعي احتمال البيانات. لذلك دعونا نبدأ ونستكشف
هذا المفهوم بالضبط. لنحصل على فهم أفضل لاحتمال البيانات، دعونا نبدأ من بعض الأمثلة البسيطة
ونحاول أن نفهم ما تحاول w القيام به، ما الذي نحاول القيام به هنا
في مسألة التعلم. فلنقل أن لدينا نقطة البيانات هذه التي
لديها اثنان awesomes وواحدة awful، دعونا نطلق على هذا الإدخال x1. وسنقوم بمحاولة إخراج y1
وهو شعور إيجابي. فهذا هو استعراض للشعور الإيجابي. إذا كان لدينا تصنيف جيد حقًا،
إذا كانت ws جيدة، ما الذي سيحدث؟ حسنًا لهذا الإدخال الخاصة سوف تقوم بإخراج
y hat لـ 1 أيضًا يساوي +1. وبعبارة أخرى،
تتوافق y hat مع تسمية y الحقيقية. إذًا ماذا نفعل حتى تتفق
y hat مع تسمية y الحقيقية، سنستخدم الانحدار اللوجستي. حسنًا سنحاول إيجاد w التي تجعل الاحتمالية أن y = +1، عندما يكون الإدخال هو x1. وبالنسبة للمتغير w، فسنجعله
كبيرًا قدر الإمكان. وبعبارة أخرى، نحن نريد أن نجري
الاحتمالية أن y = +1، عندما x1، وعدد مرات awesome هو 2 وx2، عدد مرات awful هو 1 للمتغير w. وسنقوم بجعل هذه الاحتمالية
كبيرة قدر الإمكان. ولكن كان ذلك لمثال إيجابي. وسنقوم بجعل احتمالية
y = +1 كبيرة قدر الإمكان. والآن لنأخذ مثالًا آخر. دعونا نطلق على هذا المثال x2، حيث لدينا
0 مرة awesome و2 مرة awful، يجب أن يكون تقييم سيء، مطعم سيء. وبذلك يكون الشعور لـ y2 هو -1. حتى إذا كان تصنيفنا جيد، إذا كان w جيدًا، في هذه الحالة عندما ينبغي
توقع أن y hat 2 = -1. لذا، تتفق مع التسمية الحقيقية. إذًا في هذه الحالة، نحن لا نقوم
بتكبير احتمالية y = 1. ولكن، نحن تقوم بتكبير احتمالية
أن y =-1 عندما يكون الإدخال هو x2
للمتغير w. وبعبارة أخرى، عندما يكون الإدخال x1، فسوف نقوم بتكبير
احتمالية أن y = +1. وعندما نضع x2 1
تصبح الاحتمالية y =-1. وهذا هو ما يحاول احتمال البيانات القيام به،
ولكن دعونا نبحث في الأمر ونحاول أن نفهم بشكل أفضل قليلًا. والآن ليس لدينا مجرد مثالين على التدريب،
بل لدينا طن من الأمثلة. لدينا مجموعة بيانات كبيرة. إذًا ما الذي نحاول القيام به؟ حسنًا دعونا ننظر إلى المثال الأول. في المثال الأول، نحن نريد أن نزيد الاحتمالية، نظرًا لأن هذا مثال إيجابي،
فنحن نريد زيادة الاحتمالية بأن y يساوي +1
عندما يكون لإدخال هو x1. والمتغيرات هي w، لذا ففي هذه الحالة تكون احتمالية أن y = +1 عندما يكون عدد مرات awesome هو 2 وعدد مرات awful هو 1،
والمتغير هو w. ولذلك نحن نحاول أن نجعل احتمالية أن y = +1
مع معرفة x1 تكون كبيرة قدر الإمكان. بالنسبة للمثال التالي، سنحاول
جعل احتمالية أن y =-1 مع إعطاء x2، وتكون w كبيرة
قدر الإمكان كمثال سلبي. وبالنسبة للمثال الثالثـ وهو أيضًا
مثال سلبي، لذا فنحن نسعى لجعل احتمالية أن
y = -1 مع إعطاء x لتكون nw. وبالنسبة للمثال الرابع، نحن نسعى
لإجراء احتمالية أن y، وهو مثال إيجابي، حيث y = +1
مع إعطاء x4 وw كبيرة بقدر الإمكان. لذلك وبعبارة أخرى، بالنسبة للمثال الممكن
لمحاولة إجراء الاحتمالية y = +1 كبيرة مثل قدر الإمكان
للأمثلة السلبية، نحن نحاول إجراء احتمالية y =-1 كبيرة
قدر الإمكان، وهو أمر طبيعي جدًا. ونحن نريد أن تفعل ذلك لكل مثال،
لكل واحد منها. والآن السؤال هو كيف نجمع، مثل لمقياس جودة واحد،
كيف نجمع بين هذه؟ ويمكنك أن تتخيل طرق متعددة
للجمع بين هذه المتوسطات، أنا لا أعرف،
كل أنواع الأفكار هنا. الطريقة التي تقوم بها بالجمع عادة
عندما تقوم بما يسمى بتكبير تقدير الاحتمال أو تعظيم الاحتمالات
هي بضرب هذه الأشياء معًا. لذا فستقوم بالضرب. وبعبارة أخرى، يمكنك أن تقول إنه ناتج y = +1، معطى، وهذا من السطر الأول. مع إعطاء x1 وw
ضرب احتمالية أن y =-1 من السطر الثاني هنا مع إعطاء x2 وw،
والسطر الثالث أيضًا سلبي. لذا فبالضرب في احتمالية أن y =-1 مع إعطاء x3، w وهكذا. إذًا أنت تقوم بضرب كل شيء معًا. إليكم ملاحظة جانبية صغيرة لأولئك
الذين لديهم معرفة بالاحتمالات. السبب وراء قيامك بالضرب هو أنك
تفترض أن كل صف من الصفوف يكون مستقلًا عن بعضها البعض. لذا، فهناك عامل الاستقلال
الذي يلعب دورًا، ولكن لا تقلق كثيرًا بشأن ذلك. فقط فكر في الأمر كعملية ضرب. حسنًا، دعونا نفعل ذلك بشكل أوضح قليلًا. الآن لدينا نقاط البيانات هذه من 1 إلى 4،
وبالنسبة لكل واحدة منها نحن نحاول زيادة
الاحتمالية المحددة لها إلى أقصى حد. لذا بالنسبة للأمثلة الإيجابية، نحن نحاول
زيادة احتمالية أن y = +1، وبالنسبة إلى للأمثلة السلبية
نحاول زيادة احتمالية y =-1. مع إعطاء المتغير w، سنقوم بإيجاد w الذي
يجعل تلك الاحتماليات كبيرة قدر الإمكان. لذا فإن دالة الاحتمال تعمل،
وهي الشيء الذي يكون فيه [غير مسموع] هو ناتج كل
واحدة من هذه الاحتماليات. أنا أحب هذه الحركة. إنها رائعة أليس كذلك؟. لذا، سنقوم باستخدام
ترميز مختصر هنا. لذا بالنسبة للمثال الأول،
لدينا أن y1 هنا، كانت +1. وبالتالي سنقوم بترميز ذلك باحتمالية
y1 مع إعطاء x1 وw. لذا فإن y1 سيتم الحصول عليها
من +1 هذا، وسوف تأتي x1 من
هذا التمثيل لـ x. وبالمثل للآخر، لذا فسيصبح
الترميز طويلًا وثقيلًا. ونحن نقول فقط احتمالية y1 بإعطاء x1 وستكون هذه هي احتمالية y2 بإعطاء x2 وw. واحتمالية y3 بإعطاء x3 وw،
وسنقوم فقط بضربها معًا. وأخيرًا، وحتى لا يصبح هذا السطر
طويلًا جدًا، لأنه إذا كان لدينا 1 أو 2 مليون مثال،
فسيكون لدينا 1 مليون من هذه الإدخالات. ونحن نستخدم ترميز الناتج. لذا فهذا هو الترميز هنا. وهو يقول، سأقوم فقط بكتابة
بعض الدوال هنا. (l(w سوف تكون مساوية للناتج الذي يتراوح بين نقطة
البيانات الأولى وn، وهو عدد نقاط البيانات
لاحتمالية أن أيًا كانت تسمية y، ستساوي +1، -1. مع إعطاء للإدخال xi، الذي هو
حالة هذا التقييم، والمتغير w. وهذه هي دالة الاحتمال
التي نحاول تحسينها. لذا فإن هدفنا هنا هو اختيار w لجعل هذا الشيء المجنون، أعني، هذه الدالة كبيرة بقدر الإمكان. وهذا هو هدفنا. [موسيقى]