[موسيقى] >> دعونا نتعمق أكثر الآن في مهمة التعلم
المتعلقة بشجرة القرارات. لذا، فقبل أن نبدأ في تقديم مجموعة
من بيانات التدريب ونستخرج بعض السمات من ذلك. ثم نأخذ بعد ذلك نموذج
شجرة القرارات (T(x، واستخدامه للتنبؤ بالقيمة Y^. لذا، لنستكشف (T(x بالمزيد
من التفصيل ونناقش ما قد تبدو عليه
عملية التعلم هنا. وعلى وجه الخصوص، فإن لدينا مجموعة من البيانات هنا،
وهي عبارة عن جدول حيث كل صف يتوافق مع أحد نقاط البيانات،
ولدينا بعض السمات هنا، (h1(x و(h2(x و(h3(x. والتي تمثل الائتمان والفترة والدخل، لذا، في هذا
المثال سيكون لدينا ثلاث سمات فقط، ثم نحاول التنبؤ بما ندعوه بحالة القرض. والتي تمثل المتغير y، والذي يشير إلى
ما إذا كان القرض خطير أو آمن. هدفنا هو التعرف إلى شجرة القرارات التي يمكن
أن تساعدنا في القيام بعملية التنبؤ، بالنسبة لواحدة أو أكثر من
سمات الإدخال هذه. وبشكل أعم، سيكون لدينا عملية المراقبة N
من البيانات لدينا للشكل xi وyi حيث أن yi تكون التسمية الحقيقية. ونحاول تحسين نوعًا من قياس الجودة
الذي يتناسب مع الشجرة التي تكون جيدة قدر الإمكان
فيما يتعلق بهذا المقياس. وفي حالة شجرة القرارات، فإن
المقياس الذي سنستخدمه هو بشكل مباشر عبارة عن خطأ بالتصنيف. وهناك مقاييس أخرى يمكن استخدامها
بالنسبة لشجرة القرارات، ولكن في هذه الوحدة سنركز بشكل مباشر
على الخطأ في التصنيف. ويقوم مقياس الخطأ في التصنيف بقياس
نسبة الأخطاء التي نقوم بها عندما نحاول القيام بعملية تنبؤ
بشأن بيانات التدريب. لذا، فهي عبارة عن عدد التنبؤات الخاطئة
مقسومًا على العدد الإجمالي للأمثلة، تمامًا كما رأينا في حالة الانحدار اللوجستي. وأفضل قيمة محتملة هنا هي 0،
وتعني أنه لا توجد أخطاء، وأسوأ قيمة محتملة هنا هي 1. وقد وضعت أكبر عدد ممكن من
الأخطاء في نقطة البيانات. لذا، لنأمل ألا تحصلوا خطأ بالقيمة 1، وان تحصلوا
على نسبة خطأ قيمة أقرب إلى 0. والآن بما أننا قد رأينا، مقياس
الخطأ في التصنيف، يمكننا تحديد أهداف التعلم لدينا
بشكل أكثر وضوحًا. وفقًا لمجموعة البيانات الموجودة، يمكننا العثور على الشجرة
التي تقوم بتقليل نسبة الخطأ في التصنيف. والسؤال هو، ما مدى صعوبة هذه المشكلة؟ ما مدى صعوبة مهمة التعلم هذه؟ وقد اتضح أن هذه مهمة تعلم
صعبة للغاية. وهناك تركيبات كثيرة لأشجار
القرارات هناك. حتى إذا نظرت فقط إلى فرع واحد
في شجرة القرارات. يمكن أن تكون عملية تحديد السمات التي ستأتي لاحقًا في
ترتيب ما، هي مشكلة صعبة للغاية والتي تؤدي إلى كم هائل
من التركيبات. وفي الواقع، بالنسبة لأولئك المطلعين على ذلك، فإن هذا مثال على
ما يسمى بمشكلة NP الصعبة للغاية. لذا، فهذه مشكلة صعبة للغاية، لا توجد أي
خوارزميات تقريبية لهذه المشكلة مع ضمانات، ولكن هناك بعض الأفكار
البسيطة حول الاستدلال والتي تميل إلى الأداء بشكل جيد للغاية
فيما يتعلق بالممارسة. وسنتحدث عن فكرة واحدة اليوم، والتي تدعى في الواقع
بخوارزمية greedy البسيطة. وسنقوم ببناء الشجرة تدريجيًا، حيث سنضع
طبقة واحدة في كل مرة، بهدف الحصول على أفضل قيمة ممكنة لنسبة
الخطأ في التصنيف بكل خطوة. >> [موسيقى]