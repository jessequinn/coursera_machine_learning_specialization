1
00:00:00,045 --> 00:00:04,491
[موسيقى]

2
00:00:04,491 --> 00:00:09,525
>> دعونا نتعمق أكثر الآن في مهمة التعلم
المتعلقة بشجرة القرارات.

3
00:00:09,525 --> 00:00:12,708
لذا، فقبل أن نبدأ في تقديم مجموعة
من بيانات التدريب

4
00:00:12,708 --> 00:00:14,830
ونستخرج بعض السمات من ذلك.

5
00:00:14,830 --> 00:00:18,950
ثم نأخذ بعد ذلك نموذج
شجرة القرارات (T(x،

6
00:00:18,950 --> 00:00:21,630
واستخدامه للتنبؤ بالقيمة Y^.

7
00:00:21,630 --> 00:00:24,300
لذا، لنستكشف (T(x بالمزيد
من التفصيل

8
00:00:24,300 --> 00:00:27,420
ونناقش ما قد تبدو عليه
عملية التعلم هنا.

9
00:00:27,420 --> 00:00:31,270
وعلى وجه الخصوص، فإن لدينا مجموعة من البيانات هنا،
وهي عبارة عن جدول حيث كل صف

10
00:00:31,270 --> 00:00:35,393
يتوافق مع أحد نقاط البيانات،
ولدينا بعض السمات هنا،

11
00:00:35,393 --> 00:00:40,810
(h1(x و(h2(x و(h3(x.

12
00:00:40,810 --> 00:00:43,980
والتي تمثل الائتمان والفترة والدخل، لذا، في هذا
المثال سيكون لدينا ثلاث سمات فقط،

13
00:00:43,980 --> 00:00:49,689
ثم نحاول التنبؤ بما ندعوه بحالة القرض.

14
00:00:50,770 --> 00:00:55,570
والتي تمثل المتغير y، والذي يشير إلى
ما إذا كان القرض خطير أو آمن.

15
00:00:55,570 --> 00:00:59,430
هدفنا هو التعرف إلى شجرة القرارات التي يمكن
أن تساعدنا في القيام بعملية التنبؤ،

16
00:00:59,430 --> 00:01:02,870
بالنسبة لواحدة أو أكثر من
سمات الإدخال هذه.

17
00:01:04,290 --> 00:01:09,830
وبشكل أعم، سيكون لدينا عملية المراقبة N
من البيانات لدينا للشكل xi

18
00:01:09,830 --> 00:01:12,150
وyi حيث أن yi تكون التسمية الحقيقية.

19
00:01:12,150 --> 00:01:16,390
ونحاول تحسين نوعًا من قياس الجودة
الذي يتناسب مع

20
00:01:16,390 --> 00:01:20,880
الشجرة التي تكون جيدة قدر الإمكان
فيما يتعلق بهذا المقياس.

21
00:01:20,880 --> 00:01:23,610
وفي حالة شجرة القرارات، فإن
المقياس الذي سنستخدمه

22
00:01:23,610 --> 00:01:26,220
هو بشكل مباشر عبارة عن خطأ بالتصنيف.

23
00:01:26,220 --> 00:01:29,110
وهناك مقاييس أخرى يمكن استخدامها
بالنسبة لشجرة القرارات، ولكن

24
00:01:29,110 --> 00:01:32,590
في هذه الوحدة سنركز بشكل مباشر
على الخطأ في التصنيف.

25
00:01:32,590 --> 00:01:35,960
ويقوم مقياس الخطأ في التصنيف بقياس
نسبة الأخطاء التي نقوم بها

26
00:01:35,960 --> 00:01:38,030
عندما نحاول القيام بعملية تنبؤ
بشأن بيانات التدريب.

27
00:01:38,030 --> 00:01:41,460
لذا، فهي عبارة عن عدد التنبؤات الخاطئة
مقسومًا على العدد الإجمالي

28
00:01:41,460 --> 00:01:43,150
للأمثلة، تمامًا كما رأينا

29
00:01:43,150 --> 00:01:45,490
في حالة الانحدار اللوجستي.

30
00:01:45,490 --> 00:01:47,940
وأفضل قيمة محتملة هنا هي 0،
وتعني أنه لا توجد أخطاء،

31
00:01:47,940 --> 00:01:49,450
وأسوأ قيمة محتملة هنا هي 1.

32
00:01:49,450 --> 00:01:53,200
وقد وضعت أكبر عدد ممكن من
الأخطاء في نقطة البيانات.

33
00:01:53,200 --> 00:01:56,850
لذا، لنأمل ألا تحصلوا خطأ بالقيمة 1، وان تحصلوا
على نسبة خطأ قيمة أقرب إلى 0.

34
00:01:56,850 --> 00:01:59,747
والآن بما أننا قد رأينا، مقياس
الخطأ في التصنيف،

35
00:01:59,747 --> 00:02:02,970
يمكننا تحديد أهداف التعلم لدينا
بشكل أكثر وضوحًا.

36
00:02:02,970 --> 00:02:07,140
وفقًا لمجموعة البيانات الموجودة، يمكننا العثور على الشجرة
التي تقوم بتقليل نسبة الخطأ في التصنيف.

37
00:02:07,140 --> 00:02:09,830
والسؤال هو، ما مدى صعوبة هذه المشكلة؟

38
00:02:09,830 --> 00:02:12,220
ما مدى صعوبة مهمة التعلم هذه؟

39
00:02:12,220 --> 00:02:14,842
وقد اتضح أن هذه مهمة تعلم
صعبة للغاية.

40
00:02:14,842 --> 00:02:18,520
وهناك تركيبات كثيرة لأشجار
القرارات هناك.

41
00:02:18,520 --> 00:02:21,500
حتى إذا نظرت فقط إلى فرع واحد
في شجرة القرارات.

42
00:02:21,500 --> 00:02:26,180
يمكن أن تكون عملية تحديد السمات التي ستأتي لاحقًا في
ترتيب ما، هي مشكلة صعبة للغاية

43
00:02:26,180 --> 00:02:28,500
والتي تؤدي إلى كم هائل
من التركيبات.

44
00:02:28,500 --> 00:02:29,020
وفي الواقع،

45
00:02:29,020 --> 00:02:33,440
بالنسبة لأولئك المطلعين على ذلك، فإن هذا مثال على
ما يسمى بمشكلة NP الصعبة للغاية.

46
00:02:33,440 --> 00:02:37,840
لذا، فهذه مشكلة صعبة للغاية، لا توجد أي
خوارزميات تقريبية لهذه المشكلة

47
00:02:37,840 --> 00:02:40,820
مع ضمانات، ولكن هناك بعض الأفكار
البسيطة حول الاستدلال

48
00:02:40,820 --> 00:02:42,808
والتي تميل إلى الأداء بشكل جيد للغاية
فيما يتعلق بالممارسة.

49
00:02:42,808 --> 00:02:45,705
وسنتحدث عن فكرة واحدة اليوم،

50
00:02:45,705 --> 00:02:49,380
والتي تدعى في الواقع
بخوارزمية greedy البسيطة.

51
00:02:49,380 --> 00:02:53,023
وسنقوم ببناء الشجرة تدريجيًا، حيث سنضع
طبقة واحدة في كل مرة،

52
00:02:53,023 --> 00:02:56,809
بهدف الحصول على أفضل قيمة ممكنة لنسبة
الخطأ في التصنيف بكل خطوة.

53
00:02:56,809 --> 00:02:57,309
>> [موسيقى]