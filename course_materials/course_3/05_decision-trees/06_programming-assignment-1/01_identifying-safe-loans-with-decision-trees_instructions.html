<meta charset="utf-8"/>
<co-content>
 <h1 level="1">
  Identifying safe loans with decision trees
 </h1>
 <p>
  The LendingClub is a peer-to-peer leading company that directly connects borrowers and potential lenders/investors. In this notebook, you will build a classification model to predict whether or not a loan provided by LendingClub is likely to default.
 </p>
 <p>
  In this notebook you will use data from the LendingClub to predict whether a loan will be paid off in full or the loan will be charged off and possibly go into default. In this assignment you will:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Use SFrames to do some feature engineering.
   </p>
  </li>
  <li>
   <p>
    Train a decision-tree on the LendingClub dataset.
   </p>
  </li>
  <li>
   <p>
    Visualize the tree.
   </p>
  </li>
  <li>
   <p>
    Predict whether a loan will default along with prediction probabilities (on a validation set).
   </p>
  </li>
  <li>
   <p>
    Train a complex tree model and compare it to simple tree model.
   </p>
  </li>
 </ul>
 <h2 level="2">
  If you are doing the assignment with IPython Notebook
 </h2>
 <p>
  An IPython Notebook has been provided below to you for this assignment. This notebook contains the instructions, quiz questions and partially-completed code for you to use as well as some cells to test your code.
 </p>
 <p>
  <strong>
   Make sure that you are using the latest version of GraphLab Create.
  </strong>
 </p>
 <h2 level="2">
  What you need to download
 </h2>
 <h3 level="3">
  If you are using GraphLab Create:
 </h3>
 <ul bullettype="bullets">
  <li>
   <p>
    Download the Lending club data in SFrame format:
   </p>
  </li>
 </ul>
 <asset assettype="generic" extension="zip" id="vTFakZb5EeaPaAqL2XDGfA" name="lending-club-data.gl">
 </asset>
 <ul bullettype="bullets">
  <li>
   <p>
    Download the companion IPython Notebook:
   </p>
  </li>
 </ul>
 <asset assettype="generic" extension="zip" id="vTEMJZb5EeaHjRLnexYMxg" name="module-5-decision-tree-assignment-1-blank.ipynb">
 </asset>
 <ul bullettype="bullets">
  <li>
   <p>
    Save both of these files in the same directory (where you are calling IPython notebook from) and unzip the data file.
   </p>
  </li>
  <li>
   <p>
    Follow the instructions contained in the IPython notebook.
   </p>
  </li>
 </ul>
 <h3 level="3">
  If you are not using GraphLab Create:
 </h3>
 <ul bullettype="bullets">
  <li>
   <p>
    If you are using SFrame, download the LendingClub dataset in SFrame format:
   </p>
  </li>
 </ul>
 <asset assettype="generic" extension="zip" id="vTFakZb5EeaPaAqL2XDGfA" name="lending-club-data.gl">
 </asset>
 <ul bullettype="bullets">
  <li>
   <p>
    If you are using a different package, download the LendingClub dataset in CSV format:
   </p>
  </li>
 </ul>
 <asset assettype="generic" extension="zip" id="RLfVh5cTEeaMvRLid-X_BA" name="lending-club-data.csv">
 </asset>
 <h2 level="2">
  If you are using GraphLab Create and the companion IPython Notebook
 </h2>
 <p>
  Open the companion IPython notebook and follow the instructions in the notebook.
 </p>
 <h2 level="2">
  If you are using other tools
 </h2>
 <p>
  <strong>
   This section is designed for people using tools other than GraphLab Create. Even though some instructions are specific to scikit-learn, most part of the assignment should be applicable to other tools as well. However, we highly suggest you use
   <a href="https://github.com/turi-code/SFrame">
    SFrame
   </a>
   since it is open source. In this part of the assignment, we describe general instructions, however we will tailor the instructions for SFrame and scikit-learn.
  </strong>
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    If you choose to use SFrame and scikit-learn, you should be able to follow the instructions here and complete the assessment.
    <strong>
     All code samples given here will be applicable to SFrame and scikit-learn
    </strong>
    .
   </p>
  </li>
  <li>
   <p>
    You are free to experiment with any tool of your choice, but
    <strong>
     some many not produce correct numbers for the quiz questions.
    </strong>
   </p>
  </li>
 </ul>
 <h3 level="3">
  Load the Lending Club dataset
 </h3>
 <p>
  We will be using a dataset from the
  <a href="https://www.lendingclub.com/">
   LendingClub
  </a>
  .
 </p>
 <ol bullettype="numbers">
  <li>
   <p>
    Load the dataset into a data frame named
    <strong>
     loans
    </strong>
    . Using SFrame, this would look like
   </p>
  </li>
 </ol>
 <pre language="python">import sframe
loans = sframe.SFrame('lending-club-data.gl/')</pre>
 <p>
  <strong>
   Note:
  </strong>
  To install SFrame (without installing GraphLab Create), run
 </p>
 <pre language="sh">pip install sframe</pre>
 <h3 level="3">
  Exploring some features
 </h3>
 <p>
  2. Let's quickly explore what the dataset looks like. First, print out the column names to see what features we have in this dataset. On SFrame, you can run this code:
 </p>
 <pre language="python">loans.column_names()</pre>
 <p>
  Here, we should see that we have some feature columns that have to do with grade of the loan, annual income, home ownership status, etc.
 </p>
 <h3 level="3">
  Exploring the target column
 </h3>
 <p>
  The target column (label column) of the dataset that we are interested in is called bad_loans. In this column
  <strong>
   1
  </strong>
  means a risky (bad) loan
  <strong>
   0
  </strong>
  means a safe loan.
 </p>
 <p>
  In order to make this more intuitive and consistent with the lectures, we reassign the target to be:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    <strong>
     +1
    </strong>
    as a safe loan
   </p>
  </li>
  <li>
   <p>
    <strong>
     -1
    </strong>
    as a risky (bad) loan
   </p>
  </li>
 </ul>
 <p>
  3. We put this in a new column called
  <strong>
   safe_loans
  </strong>
  .
 </p>
 <pre language="python"># safe_loans =  1 =&gt; safe
# safe_loans = -1 =&gt; risky
loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)
loans = loans.remove_column('bad_loans')</pre>
 <p>
  4. Now, let us explore the distribution of the column safe_loans. This gives us a sense of how many safe and risky loans are present in the dataset. Print out the percentage of safe loans and risky loans in the data frame.
 </p>
 <p>
  You should have:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Around 81% safe loans
   </p>
  </li>
  <li>
   <p>
    Around 19% risky loans
   </p>
  </li>
 </ul>
 <p>
  It looks like most of these loans are safe loans (thankfully). But this does make our problem of identifying risky loans challenging.
 </p>
 <h3 level="3">
  Features for the classification algorithm
 </h3>
 <p>
  5. In this assignment, we will be using a subset of features (categorical and numeric). The features we will be using are
  <strong>
   described in the code comments
  </strong>
  below. If you are a finance geek, the
  <a href="https://www.lendingclub.com/">
   LendingClub
  </a>
  website has a lot more details about these features. Extract these feature columns and target column from the dataset. We will only use these features.
 </p>
 <pre language="python">features = ['grade',                     # grade of the loan
            'sub_grade',                 # sub-grade of the loan
            'short_emp',                 # one year or less of employment
            'emp_length_num',            # number of years of employment
            'home_ownership',            # home_ownership status: own, mortgage or rent
            'dti',                       # debt to income ratio
            'purpose',                   # the purpose of the loan
            'term',                      # the term of the loan
            'last_delinq_none',          # has borrower had a delinquincy
            'last_major_derog_none',     # has borrower had 90 day or worse rating
            'revol_util',                # percent of available credit being used
            'total_rec_late_fee',        # total late fees received to day
           ]

target = 'safe_loans'                    # prediction target (y) (+1 means safe, -1 is risky)

# Extract the feature columns and target column
loans = loans[features + [target]]</pre>
 <p>
  What remains now is a
  <strong>
   subset of features
  </strong>
  and the
  <strong>
   target
  </strong>
  that we will use for the rest of this notebook.
 </p>
 <h3 level="3">
  Notes to people using other tools
 </h3>
 <p>
  <strong>
   If you are using SFrame, proceed to the section "Sample data to balance classes".
  </strong>
 </p>
 <p>
  <strong>
   If you are NOT using SFrame, download the list of indices for the training and validation sets
  </strong>
  :
 </p>
 <asset assettype="generic" extension="zip" id="egQncZcCEea9mwoGlQi6MA" name="module-5-assignment-1-train-idx.json">
 </asset>
 <asset assettype="generic" extension="zip" id="ef4MZJcCEeapsBLoXmtYXg" name="module-5-assignment-1-validation-idx.json">
 </asset>
 <p>
  Then follow the following steps:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Apply one-hot encoding to
    <strong>
     loans
    </strong>
    . Your tool may have a function for one-hot encoding. Alternatively, see #7 for implementation hints.
   </p>
  </li>
  <li>
   <p>
    Load the JSON files into the lists
    <strong>
     train_idx
    </strong>
    and
    <strong>
     validation_idx
    </strong>
    .
   </p>
  </li>
  <li>
   <p>
    Perform train/validation split using
    <strong>
     train_idx
    </strong>
    and
    <strong>
     validation_idx
    </strong>
    . In Pandas, for instance:
   </p>
  </li>
 </ul>
 <pre language="python">train_data = loans.iloc[train_idx]
validation_data = loans.iloc[validation_idx]</pre>
 <p>
  IMPORTANT: If you are using a programming language with 1-based indexing (e.g. R, Matlab), make sure to increment all indices by 1.
 </p>
 <p>
  Note. Some elements in loans are included neither in
  <strong>
   train_data
  </strong>
  nor
  <strong>
   validation_data
  </strong>
  . This is to perform sampling to achieve class balance.
 </p>
 <p>
  Now proceed to the section "Build a decision tree classifier", skipping three sections below.
 </p>
 <h3 level="3">
  Sample data to balance classes
 </h3>
 <p>
  6. As we explored above, our data is disproportionally full of safe loans. Let's create two datasets: one with just the safe loans (
  <strong>
   safe_loans_raw
  </strong>
  ) and one with just the risky loans (
  <strong>
   risky_loans_raw
  </strong>
  ).
 </p>
 <pre language="python">safe_loans_raw = loans[loans[target] == +1]
risky_loans_raw = loans[loans[target] == -1]
print "Number of safe loans  : %s" % len(safe_loans_raw)
print "Number of risky loans : %s" % len(risky_loans_raw)</pre>
 <p>
  One way to combat class imbalance is to undersample the larger class until the class distribution is approximately half and half. Here, we will undersample the larger class (safe loans) in order to balance out our dataset. This means we are throwing away many data points. We used seed=1 so everyone gets the same results.
 </p>
 <pre language="python"># Since there are fewer risky loans than safe loans, find the ratio of the sizes
# and use that percentage to undersample the safe loans.
percentage = len(risky_loans_raw)/float(len(safe_loans_raw))

risky_loans = risky_loans_raw
safe_loans = safe_loans_raw.sample(percentage, seed=1)

# Append the risky_loans with the downsampled version of safe_loans
loans_data = risky_loans.append(safe_loans)
</pre>
 <p>
  You can verify now that
  <strong>
   loans_data
  </strong>
  is comprised of approximately 50% safe loans and 50% risky loans.
 </p>
 <p>
  <strong>
   Note:
  </strong>
  There are many approaches for dealing with imbalanced data, including some where we modify the learning algorithm. These approaches are beyond the scope of this course, but some of them are reviewed in this
  <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=5128907&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel5%2F69%2F5173046%2F05128907.pdf%3Farnumber%3D5128907">
   paper
  </a>
  . For this assignment, we use the simplest possible approach, where we subsample the overly represented class to get a more balanced dataset. In general, and especially when the data is highly imbalanced, we recommend using more advanced methods.
 </p>
 <h3 level="3">
  One-hot encoding
 </h3>
 <p>
  7. For scikit-learn's decision tree implementation, it requires numerical values for it's data matrix. This means you will have to turn categorical variables into binary features via one-hot encoding.
  <strong>
   The next assignment has more details about this.
  </strong>
 </p>
 <p>
  If you are using SFrame, feel free to use this piece of code as is. Refer to the SFrame API documentation for a deeper understanding. If you are using different machine learning software, make sure you prepare the data to be passed to the learning software.
 </p>
 <pre language="python">loans_data = risky_loans.append(safe_loans)

categorical_variables = []
for feat_name, feat_type in zip(loans_data.column_names(), loans_data.column_types()):
    if feat_type == str:
        categorical_variables.append(feat_name)

for feature in categorical_variables:
    loans_data_one_hot_encoded = loans_data[feature].apply(lambda x: {x: 1})
    loans_data_unpacked = loans_data_one_hot_encoded.unpack(column_name_prefix=feature)

    # Change None's to 0's
    for column in loans_data_unpacked.column_names():
        loans_data_unpacked[column] = loans_data_unpacked[column].fillna(0)

    loans_data.remove_column(feature)
    loans_data.add_columns(loans_data_unpacked)</pre>
 <h3 level="3">
  Split data into training and validation
 </h3>
 <p>
  8. We split the data into training and validation sets using an 80/20 split and specifying seed=1 so everyone gets the same results. Call the training and validation sets
  <strong>
   train_data
  </strong>
  and
  <strong>
   validation_data
  </strong>
  , respectively.
 </p>
 <p>
  <strong>
   Note
  </strong>
  : In previous assignments, we have called this a
  <strong>
   train-test split
  </strong>
  . However, the portion of data that we don't train on will be used to help
  <strong>
   select model parameters
  </strong>
  (this is known as model selection). Thus, this portion of data should be called a
  <strong>
   validation set
  </strong>
  . Recall that examining performance of various potential models (i.e. models with different parameters) should be on validation set, while evaluation of the final selected model should always be on test data. Typically, we would also save a portion of the data (a real test set) to test our final model on or use cross-validation on the training set to select our final model. But for the learning purposes of this assignment, we won't do that.
 </p>
 <pre language="python">train_data, validation_data = loans_data.random_split(.8, seed=1)</pre>
 <h3 level="3">
  Build a decision tree classifier
 </h3>
 <p>
  9. Now, let's use the built-in scikit learn decision tree learner (
  <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">
   sklearn.tree.DecisionTreeClassifier
  </a>
  ) to create a loan prediction model on the training data. To do this, you will need to import
  <strong>
   sklearn
  </strong>
  ,
  <strong>
   sklearn.tree,
  </strong>
  and
  <strong>
   numpy
  </strong>
  .
 </p>
 <p>
  <strong>
   Note
  </strong>
  : You will have to first convert the SFrame into a numpy data matrix, and extract the target labels as a numpy array (Hint: you can use the
  <strong>
   .to_numpy()
  </strong>
  method call on SFrame to turn SFrames into numpy arrays). See
  <a href="https://turi.com/products/create/docs/generated/graphlab.SFrame.to_numpy.html">
   the API
  </a>
  for more information.
  <strong>
   Make sure to set max_depth=6
  </strong>
  .
 </p>
 <p>
  Call this model
  <strong>
   decision_tree_model
  </strong>
  .
 </p>
 <p>
  10. Also train a tree using with
  <strong>
   max_depth=2
  </strong>
  . Call this model
  <strong>
   small_model
  </strong>
  .
 </p>
 <h3 level="3">
  Visualizing a learned model (Optional)
 </h3>
 <p>
  10a. For this optional section, we would like to see what the small learned tree looks like. If you are using scikit-learn and have the package
  <a href="http://graphviz.readthedocs.org/en/latest/#">
   Graphviz
  </a>
  , then you will be able to perform this section. If you are using a different software, try your best to follow along.
 </p>
 <p>
  Visualize
  <strong>
   small_model
  </strong>
  in the software of your choice.
 </p>
 <h3 level="3">
  Making predictions
 </h3>
 <p>
  Let's consider two positive and two negative examples
  <strong>
   from the validation set
  </strong>
  and see what the model predicts. We will do the following:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    Predict whether or not a loan is safe.
   </p>
  </li>
  <li>
   <p>
    Predict the probability that a loan is safe.
   </p>
  </li>
 </ul>
 <p>
  11. First, let's grab 2 positive examples and 2 negative examples. In SFrame, that would be:
 </p>
 <pre language="python">validation_safe_loans = validation_data[validation_data[target] == 1]
validation_risky_loans = validation_data[validation_data[target] == -1]

sample_validation_data_risky = validation_risky_loans[0:2]
sample_validation_data_safe = validation_safe_loans[0:2]

sample_validation_data = sample_validation_data_safe.append(sample_validation_data_risky)
sample_validation_data
</pre>
 <p>
  12. Now, we will use our model to predict whether or not a loan is likely to default. For each row in the
  <strong>
   sample_validation_data
  </strong>
  , use the
  <strong>
   decision_tree_model
  </strong>
  to predict whether or not the loan is classified as a
  <strong>
   safe loan
  </strong>
  . (Hint: if you are using scikit-learn, you can use the
  <strong>
   .predict()
  </strong>
  method)
 </p>
 <p>
  <strong>
   Quiz Question:
  </strong>
  What percentage of the predictions on
  <strong>
   sample_validation_data
  </strong>
  did
  <strong>
   decision_tree_model
  </strong>
  get correct?
 </p>
 <h3 level="3">
  Explore probability predictions
 </h3>
 <p>
  13. For each row in the
  <strong>
   sample_validation_data
  </strong>
  , what is the probability (according
  <strong>
   decision_tree_model
  </strong>
  ) of a loan being classified as
  <strong>
   safe
  </strong>
  ? (Hint: if you are using scikit-learn, you can use the
  <strong>
   .predict_proba()
  </strong>
  method)
 </p>
 <p>
  <strong>
   Quiz Question:
  </strong>
  Which loan has the highest probability of being classified as a
  <strong>
   safe loan
  </strong>
  ?
 </p>
 <p>
  <strong>
   Checkpoint:
  </strong>
  Can you verify that for all the predictions with probability &gt;= 0.5, the model predicted the label
  <strong>
   +1
  </strong>
  ?
 </p>
 <h3 level="3">
  Tricky predictions!
 </h3>
 <p>
  14. Now, we will explore something pretty interesting. For each row in the
  <strong>
   sample_validation_data
  </strong>
  , what is the probability (according to
  <strong>
   small_model
  </strong>
  ) of a loan being classified as
  <strong>
   safe
  </strong>
  ?
 </p>
 <p>
  <strong>
   Quiz Question:
  </strong>
  Notice that the probability preditions are the
  <strong>
   exact same
  </strong>
  for the 2nd and 3rd loans. Why would this happen?
 </p>
 <h3 level="3">
  Visualize the prediction on a tree
 </h3>
 <p>
  14a. Note that you should be able to look at the small tree (of depth 2), traverse it yourself, and visualize the prediction being made. Consider the following point in the
  <strong>
   sample_validation_data:
  </strong>
 </p>
 <pre language="python">sample_validation_data[1]</pre>
 <p>
  If you have Graphviz, go ahead and re-visualize
  <strong>
   small_model
  </strong>
  here to do the traversing for this data point.
 </p>
 <p>
  <strong>
   Quiz Question:
  </strong>
  Based on the visualized tree, what prediction would you make for this data point (according to
  <strong>
   small_model
  </strong>
  )? (If you don't have Graphviz, you can answer this quiz question by executing the next part.)
 </p>
 <p>
  15. Now, verify your prediction by examining the prediction made using
  <strong>
   small_model.
  </strong>
 </p>
 <h3 level="3">
  Evaluating accuracy of the decision tree model
 </h3>
 <p>
  Recall that the accuracy is defined as follows:
 </p>
 <p hasmath="true">
  $$\mbox{accuracy} = \dfrac{\mbox{# correctly classified data points}}{\mbox{# total data points}}$$
 </p>
 <p>
  16. Evaluate the accuracy of
  <strong>
   small_model
  </strong>
  and
  <strong>
   decision_tree_model
  </strong>
  on the training data. (Hint: if you are using scikit-learn, you can use the
  <strong>
   .score()
  </strong>
  method)
 </p>
 <p>
  <strong>
   Checkpoint:
  </strong>
  You should see that the
  <strong>
   small_model
  </strong>
  performs worse than the
  <strong>
   decision_tree_model
  </strong>
  on the training data.
 </p>
 <p>
  17. Now, evaluate the accuracy of the
  <strong>
   small_model
  </strong>
  and
  <strong>
   decision_tree_model
  </strong>
  on the entire validation
  <strong>
   _data
  </strong>
  , not just the subsample considered above.
 </p>
 <p>
  <strong>
   Quiz Question:
  </strong>
  What is the accuracy of decision_tree_model on the validation set, rounded to the nearest .01?
 </p>
 <h3 level="3">
  Evaluating accuracy of a complex decision tree model
 </h3>
 <p>
  Here, we will train a large decision tree with
  <strong>
   max_depth
  </strong>
  =10. This will allow the learned tree to become very deep, and result in a very complex model. Recall that in lecture, we prefer simpler models with similar predictive power. This will be an example of a more complicated model which has similar predictive power, i.e. something we don't want.
 </p>
 <p>
  18. Using
  <a href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier">
   sklearn.tree.DecisionTreeClassifier
  </a>
  , train a decision tree with maximum depth = 10. Call this model
  <strong>
   big_model
  </strong>
  .
 </p>
 <p>
  19. Evaluate the accuracy of
  <strong>
   big_model
  </strong>
  on the training set and validation set.
 </p>
 <p>
  <strong>
   Checkpoint
  </strong>
  : We should see that
  <strong>
   big_model
  </strong>
  has even better performance on the training set than
  <strong>
   decision_tree_model
  </strong>
  did on the training set.
 </p>
 <p>
  <strong>
   Quiz Question:
  </strong>
  How does the performance of
  <strong>
   big_model
  </strong>
  on the validation set compare to
  <strong>
   decision_tree_model
  </strong>
  on the validation set? Is this a sign of overfitting?
 </p>
 <h3 level="3">
  Quantifying the cost of mistakes
 </h3>
 <p>
  Every mistake the model makes costs money. In this section, we will try and quantify the cost each mistake made by the model. Assume the following:
 </p>
 <ul bullettype="bullets">
  <li>
   <p>
    <strong>
     False negatives
    </strong>
    : Loans that were actually safe but were predicted to be risky. This results in an oppurtunity cost of loosing a loan that would have otherwise been accepted.
   </p>
  </li>
  <li>
   <p>
    <strong>
     False positives
    </strong>
    : Loans that were actually risky but were predicted to be safe. These are much more expensive because it results in a risky loan being given.
   </p>
  </li>
  <li>
   <p>
    <strong>
     Correct predictions
    </strong>
    : All correct predictions don't typically incur any cost.
   </p>
  </li>
 </ul>
 <p>
  Let's write code that can compute the cost of mistakes made by the model. Complete the following 4 steps:
 </p>
 <ol bullettype="numbers">
  <li>
   <p>
    First, let us compute the predictions made by the model.
   </p>
  </li>
  <li>
   <p>
    Second, compute the number of false positives.
   </p>
  </li>
  <li>
   <p>
    Third, compute the number of false negatives.
   </p>
  </li>
  <li>
   <p>
    Finally, compute the cost of mistakes made by the model by adding up the costs of true positives and false positves.
   </p>
  </li>
 </ol>
 <p>
  <strong>
   Quiz Question
  </strong>
  : Let's assume that each mistake costs us money: a false negative costs $10,000, while a false positive positive costs $20,000. What is the total cost of mistakes made by decision_tree_model on validation_data?
 </p>
</co-content>
<style>
 body {
    padding: 50px 85px 50px 85px;
}

table th, table td {
    border: 1px solid #e0e0e0;
    padding: 5px 20px;
    text-align: left;
}
input {
    margin: 10px;
}
}
th {
    font-weight: bold;
}
td, th {
    display: table-cell;
    vertical-align: inherit;
}
img {
    height: auto;
    max-width: 100%;
}
pre {
    display: block;
    margin: 20px;
    background: #424242;
    color: #fff;
    font-size: 13px;
    white-space: pre-wrap;
    padding: 9.5px;
    margin: 0 0 10px;
    border: 1px solid #ccc;
}
</style>
<script async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$$','$$'], ['$','$'] ],
      displayMath: [ ["\\[","\\]"] ],
      processEscapes: true
    }
  });
</script>
