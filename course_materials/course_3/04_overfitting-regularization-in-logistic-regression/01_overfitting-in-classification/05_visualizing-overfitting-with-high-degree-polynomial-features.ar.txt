[موسيقى] دعونا نرى ما سيحدث إذا استخدمنا
فرضية السمات من الدرجة 6 لمواءمة مصنف الانحدار اللوجستي على
نفس مجموعة البيانات. لذا، فإن كل السمات التي لدينا الآن تدرج بالترتيب
لتصل [2]X أس 6 و[1]X أس 6. حيث توجد العديد من السمات والعديد من المعاملات التي
يمكن التعرف عليها من خلال البيانات. والآن، إذا أخذت مجموعة البيانات هذه
وقمت بمواءمتها لتناسب مصنف الانحدار اللوجستي، فسأحصل
على حدود القرار التالية. وهي تناسب بيانات التدريب بشكل جيد للغاية. فإذا أمعنت النظر، فستلاحظ أن نسبة
الخطأ التدريبي صفر. والتي من المفترض أن تكون بمثابة علامة
تحذيرية بالمناسبة، كما ذكرنا مسبقًا. وإذا نظرت إلى حدود القرار
فستجد أنها معقدة للغاية معقدة. وقد يقول بعض الأشخاص إن هناك
مصطلحًا تقنيًّا يصف ذلك. وهو حدود القرار الجنونية. وعلى الرغم من أن نسبة الخطأ التدريبي صفر، إلا أن
هناك بعض التشكيلات الغريبة به. إذن، على سبيل المثال، أنا أحدد هنا
نطاق من المساحة الفارغة حيث على الرغم من أن تلك المساحة
محاطة بالتنبؤات الإيجابية، فإن في المنتصف هذه الدائرة يجب أن
يكون المجموع أقل من صفر لذا، فيما يتعلق بهذه المنطقة فسنقول
أن Y^ يجب أن تكون -1. وحتى إذا لم يكن ذلك يبدو منطقيًا بالنسبة لي،
لأن كل ما حولها، كل نقطة تساوي +1. فلما يجب أن أتوقع أن تكون النقاط
في المنتصف هنا تساوي -1؟ فإن البيانات لا تدعم ذلك مطلقًا. وفي الواقع، إذا نظرت إلى
حجم المعاملات، فستلاحظ أنها بدأت في الزيادة. فإن جميع القطع المكافئة الطبيعية لديها معاملات
تتراوح بين 1 و-0.5. والآن، فإن لدينا معاملات تبدأ
بالقيمة 42 أو أكثر، والتي هي أكبر بنسبة 10 إلى 40 مرة من
المعاملات التي كانت لدينا سابقًا. وهذا يعد علامة تحذيرية مبكرة لتجنب
الإفراط في المطابقة، كما ناقشنا في درس الانحدار. والآن، دعونا نخطو خطوة أخرى، ونحاول مواءمة نموذج الانحدار اللوجستي الذي يستخدم
سمات متعددة الحدود من الدرجة 20. وهذا يستمر في الزيادة إلى أن يصل
إلى [X[1 أس 20، و[X[2 أس 20، لذا، فإن لدينا قيم
حدود متعددة عالية للغاية. إذا نظرت إلى حدود القرار التي تعرفنا عليها،
وأعني أيعقل هذا. يمكنني القول إن هذه الحدود
جنونية حقًا. فهي معقدة إلى حدٍ كبير، وتحتوي بالفعل على البيانات،
ولكنها غير سلسلة بدرجة كبيرة. وإذا نظرت إلى ترجيح المعاملات
التي تم تعلمها، فإن المعاملات لديها قيم فيما بين
3000 و4000 و-2000، وهم أكبر بكثير من هذا القطع
المكافئ البسيط الذي تعلمناه. وتحتوي على كل بيانات التدريب بشكل صحيح، ولكن
بها إفراط شديد في المطابقة. ومن الواضح أن تخرج حدود
متعددة كبيرة للغاية. ومعاملات تقديرية كبيرة للغاية. ولذا، سنحرص بشدة على مراعاة
هذه المعاملات، ونحاول تجنب الإفراط في المطابقة. لذا، فإن مفهوم التطابق المفرط في التصنيف هو
مشابه جدًا لذلك المتعلق بالانحدار، ما عدا أن الخطأ الآن يتم قياسه
من حيث خطأ التصنيف. وربما يكون علينا التعرف على مجموعة
من المتغيرات وهي W^. والتي يبدو أنها تعمل بشكل جيد على بيانات التدريب،
فربما تكون كذلك بالنسبة لهذه الحدود الجنونية. ويوجد أيضًا متغير آخر يدعى W*، لذا
فإن لدينا معامل آخر وهو W*. وقد عمل ذلك بشكل أفضل بكثير
فيما يتعلق بالخطأ الحقيقي. والسؤال هو، كيف يمكننا القيام ودفع عملية التعلم لتصبح مثل W*
أكثر كونها مثل W^؟ وسنقوم بذلك عن طريق دفع المتغيرات
حتى لا تصبح ضخمة أو هائلة إلى هذا الحد، لذا فسأدفعها نحو الصفر،
كما فعلنا مع التنظيم. [موسيقى]