1
00:00:00,000 --> 00:00:04,608
[موسيقى]

2
00:00:04,608 --> 00:00:07,012
مع كل ذلك في الاعتبار، دعونا نتعمق

3
00:00:07,012 --> 00:00:11,140
ونراقب كيف يظهر الاحتواء في سياق تسلسل القرار.

4
00:00:11,140 --> 00:00:15,555
عند بدأ تعلم تسلسل القرار، نتعلم فرع القرار،

5
00:00:15,555 --> 00:00:17,725
وهو حد بسيط للغاية بين البيانات.

6
00:00:17,725 --> 00:00:20,525
دعنا نفترض أن المثال البسيط سيستخدم

7
00:00:20,525 --> 00:00:22,895
خط عمودي أو خط أفقي.

8
00:00:22,895 --> 00:00:27,625
في هذه الحالة، عندما تكون القرارات بالنسبة إلى x (1)

9
00:00:27,625 --> 00:00:32,559
سواء كانت أقل من -0.07 أو أكبر من 0.07.

10
00:00:32,559 --> 00:00:36,090
فإذا كانت أقل، سوف نتوقع -1

11
00:00:36,090 --> 00:00:40,560
وهذا يتوافق مع هذا الجانب من حدود القرار،

12
00:00:40,560 --> 00:00:45,540
إذا كان أكبر من -0.07 سوف يكون التنبؤ 1+

13
00:00:46,750 --> 00:00:51,220
سوف يكون في الجانب الأيمن من حدود القرار.

14
00:00:51,220 --> 00:00:54,920
تلك هي حدود قرار بسيطة للغاية، مع تسلسل قرار من الدرجة الأولى

15
00:00:54,920 --> 00:00:59,390
أو فرع قرار، لكن كلما زدنا في العمق،

16
00:00:59,390 --> 00:01:02,020
يصبح هذا الوضع أكثر تعقيدًا.

17
00:01:02,020 --> 00:01:04,100
كما تصبح حدود القرار أكثر تعقيدًا.

18
00:01:04,100 --> 00:01:05,144
لذلك يمكننا أن نرى،

19
00:01:05,144 --> 00:01:11,252
كلما زاد العمق، زاد
تعقيد حدود القرار.

20
00:01:15,003 --> 00:01:19,370
حتى نصل إلى هذا الشيء المعقد هنا، حيث يكون العمق 10.

21
00:01:19,370 --> 00:01:27,810
وهكذا، فإن عمق حد القرار العاشر ليس به خطأ في التدريب.

22
00:01:27,810 --> 00:01:32,781
لذا فإن خطأ التدريب عند هذه النقطة ينخفض من 0.22 وهو مرتفع نسبياً

23
00:01:32,781 --> 00:01:37,754
لفرع القرار من 0.13 إلى 0.10، وهو عمق من الدرجة الثانية

24
00:01:37,754 --> 00:01:41,219
وتسلسل القرار من الدرجة الثالثة، الذي لا بأس به

25
00:01:41,219 --> 00:01:46,070
حتى تسلسل القرار المعقد بعمق 10، الذي لا يحتوي على خطأ تدريبي.

26
00:01:46,070 --> 00:01:50,200
وهذا ينبغي أن يكون علامة تحذير كبيرة بالنسبة لك.

27
00:01:52,450 --> 00:01:54,040
لنمثل ذلك بوجه حزين.

28
00:01:55,845 --> 00:02:00,550
لقد رأينا أن مع تسلسل القرار، كلما زاد العمق، قل خطأ التدريب

29
00:02:00,550 --> 00:02:05,500
حتى نصل إلى نقطة حيث يمكن لخطأ التدريب أن يصل إلى الصفر،

30
00:02:05,500 --> 00:02:09,080
وكثيرا ما يحدث ذلك، ففي هذه الحالة
في تسلسل القرار ذي العمق 10.

31
00:02:09,080 --> 00:02:12,570
وقد تفكر، أن تسلسل القرار بعمق 10، هو شيء عظيم،

32
00:02:12,570 --> 00:02:15,980
فهو ليس به خطأ تدريبي، لذلك فهو تسلسل القرار المثالي.

33
00:02:15,980 --> 00:02:19,660
لكن في الواقع، هو ليس تسلسل قرار مثالي.

34
00:02:19,660 --> 00:02:23,110
وكما نعلم، على الرغم من أن خطأ التدريب هو صفر،

35
00:02:23,110 --> 00:02:26,080
الخطأ الحقيقي يمكن أن يتصاعد.

36
00:02:26,080 --> 00:02:32,583
ولذا قد يكون تسلسل القرار به الاحتواء المبالغ.

37
00:02:32,583 --> 00:02:37,260
لذا من الجيد أن نخطو خطوة إلى الوراء وأن نفهم حقاً بشكل أفضل

38
00:02:37,260 --> 00:02:42,540
لماذا يميل الخطأ التدريبي لتسلسل القرار إلى الانهيار بسرعة في وجود العمق.

39
00:02:42,540 --> 00:02:46,200
ﻟﻧﺄﺧذ ھذا اﻟﻣﺛﺎل اﻟﺑﺳﯾط ﺣﯾث ﻧﺗﻌﻠم فرع اﻟﻘرار.

40
00:02:46,200 --> 00:02:49,120
لدينا 40 نقطة بيانات، مثلما كنا نستخدم،

41
00:02:49,120 --> 00:02:53,070
22 منهم كانوا قروضًا آمنة، و 18 منها كانت محفوفة بالمخاطر.

42
00:02:53,070 --> 00:02:55,060
وقد اخترنا أولاً أن نقسم على الائتمان.

43
00:02:56,570 --> 00:03:01,510
والسؤال الآن هو لماذا اخترنا أن نقسم على الائتمان أولاً؟

44
00:03:01,510 --> 00:03:03,670
لماذا كانت هذه الميزة الأولى التي اخترناها؟

45
00:03:03,670 --> 00:03:06,730
والسبب الذي جعلنا نختار التقسيم على الائتمان أولاً هو

46
00:03:06,730 --> 00:03:09,500
أنه قام بتحسين الخطأ التدريبي أكثر.

47
00:03:09,500 --> 00:03:13,605
حيث قام بتحسين خطأ التدريب من 0.45 إلى 0.20.

48
00:03:13,605 --> 00:03:16,590
كان هذا أول انشقاق جيد.

49
00:03:16,590 --> 00:03:19,750
الآن، إذا عدنا وراجعنا خوارزمية

50
00:03:19,750 --> 00:03:24,970
لاختيار أفضل ميزة للانقسام

51
00:03:24,970 --> 00:03:28,100
ثم نحاول كل الميزات الممكنة

52
00:03:28,100 --> 00:03:32,600
ونختار ما تقلل الخطأ التدريبي أكثر من غيرها.

53
00:03:34,460 --> 00:03:36,870
وهكذا في كل خطوة على مدار تلك العملية،

54
00:03:36,870 --> 00:03:39,380
نقوم بإضافة الميزات التي تعمل على تقليل الخطأ في التدريب

55
00:03:39,380 --> 00:03:41,530
ثم نقوم بإضافة ميزات تقلل من خطأ التدريب.

56
00:03:41,530 --> 00:03:43,590
ثم نقوم بإضافة ميزات تقلل من خطأ التدريب.

57
00:03:43,590 --> 00:03:46,710
وفي النهاية سنقود خطأ التدريب إلى الصفر.

58
00:03:46,710 --> 00:03:49,460
ما لم نحصل بالطبع على بعض النقاط، حيث لا يمكننا أن نخفض خطأ التدريب

59
00:03:49,460 --> 00:03:51,870
لنفاد الميزات التي يتم عليها التقسيم

60
00:03:51,870 --> 00:03:55,990
لدينا نقاط إيجابية فوق نقاط سلبية، لكن هذه ملاحظة جانبية.

61
00:03:55,990 --> 00:03:58,670
الأهم من ذلك هو أن نتذكر أن الخطأ في التدريب يميل إلى الانخفاض،

62
00:03:58,670 --> 00:04:00,120
أكثر فأكثر.

63
00:04:00,120 --> 00:04:04,627
وهكذا فإن الانخفاض المرتبط بزيادة العمق هو ما يؤدي إلى

64
00:04:04,627 --> 00:04:07,839
انخفاض الخطأ في التدريب، والذي يؤدي غالبًا إلى هذه التسلسلات المعقدة جدًا،

65
00:04:07,839 --> 00:04:10,050
التي هي عرضة للاحتواء المبالغ بشكل كبير.

66
00:04:11,230 --> 00:04:14,460
وهنا مجموعة بيانات واقعية، من بيانات القروض.

67
00:04:14,460 --> 00:04:18,570
حيث لاحظنا في الواقع أن الاحتواء المبالغ هو مشكلة كبيرة سيئة.

68
00:04:18,570 --> 00:04:23,830
فإذا أخذنا عمق التسلسل،وحولناه إلى عمق 18،

69
00:04:23,830 --> 00:04:28,880
سنرى أن خطأ التدريب قد انخفض كثيرًا.

70
00:04:28,880 --> 00:04:33,680
والخط الأزرق، الذي قلل خطأ التدريب بنسبة 8 بالمائة،

71
00:04:33,680 --> 00:04:35,010
والذي يعتبر منخفضًا جدًا.

72
00:04:35,010 --> 00:04:40,640
ومع ذلك، إذا نظرت إلى خطأ مجموعة التحقق، فسترى أنه ليس جيدًا.

73
00:04:40,640 --> 00:04:48,340
ربما هذا حوالي 39 ٪، مما يعني أن هناك فجوة كبيرة بين الاثنين.

74
00:04:49,800 --> 00:04:54,190
التي سنقوم بتمييزه كنوع من أنواع الاحتواء المبالغ.

75
00:04:56,330 --> 00:05:02,240
إذا تمكنت بطريقة ما من اختيار أفضل عمق لتسلسل القرار،

76
00:05:02,240 --> 00:05:07,880
والذي في هذه الحالة كان عمق سبعة.

77
00:05:10,040 --> 00:05:14,715
ستلاحظ أنه في هذه الحالة،

78
00:05:17,141 --> 00:05:21,741
خطأ التحقق

79
00:05:21,741 --> 00:05:26,601
أقل من 35٪ بقدر قليل.

80
00:05:26,601 --> 00:05:31,341
بمعنى آخر، إذا كان يمكنني اختيار العمق المناسب،

81
00:05:31,341 --> 00:05:36,900
فسأحصل على خطأ في التدريب بنسبة 39%.

82
00:05:36,900 --> 00:05:41,110
ولكن، إذا تركته حتى خطأ تدريب منخفض للغاية،

83
00:05:41,110 --> 00:05:43,380
أحصل على خطأ في التحقق بنسبة 39٪.

84
00:05:43,380 --> 00:05:47,230
اتباع المسار لآخره هو فكرة سيئة.

85
00:05:47,230 --> 00:05:49,053
يجب التوقف مبكرًا.

86
00:05:49,053 --> 00:05:53,109
[موسيقى]