[موسيقى] من الأخبار التي باتت معروفة بالنسبة لكل شخص هي أن
مجموعات البيانات أصبحت تتزايد على مدار العقدين الأخيرين، ولكن الأمر المثير
للاهتمام هو تأثير ذلك على أبحاث التعلم الآلي وممارسات
التعلم الآلي. وإذا نظرت إلى الماضي قبل 20 عامًا، فقد كانت
مجموعات البيانات صغيرة للغاية، وقد انتهى بينا الأمر بالعمل على الكثير من
النماذج المعقدة حتى نصبح قادرين على الحصول على خلاصة معظم ما
تحتويه تلك البيانات. لأننا نحتاج إلى الدقة الكافية عند
التعامل مع البيانات القليلة. لذا، فقد عملنا على أشياء مثل 
وحدات kernel والنماذج الرسومية، وبالتالي كانت الأمور معقدة للغاية. ولكن بعد 10 أعوام من ذلك، قد بدأ حجم
البيانات في النمو على نحوٍ هائل. وقد بدأنا عصرًا جديدًا من البيانات، ما
يعرف بعصر البيانات الكبيرة. وقد اتضح أنه بسبب أن الأمر كان صعبًا للغاية لمواءمة خوارزميات التعلم الآلي مع مجموعات البيانات
الكبيرة، وكذلك بسبب أنه كان هناك الكثير من البيانات فقد عدنا مرة أخرى إلى خوارزميات
أبسط وأوقات أكثر بساطة. واستخدام أشياء مثل تحليل عوامل
مصفوفة الانحدار اللوجستي، لمعالجة مشكلة التعلم الآلي. وقد كان هناك الكثير من النقاشات
حول تأثير ذلك على مناهج التعلم الآلي. وكان هناك هذا الخطاب السابق
الذي تحدث حول التأثير غير المعقول لمجموعات
البيانات الكبيرة. وما قد أشار إليه في الأساس، هو أنه في حالة كان
لديك مجموعة ضخمة من البيانات، فيمكنك استخدام نهج بسيط للغاية،
مثل المصنف الخطي أو الانحدار اللوجستي، وتتغلب على نهج مميز،
مثل النموذج الرسومي، لأن النماذج الرسومية يمكنها التعامل مع
مجموعات أصغر من البيانات. لذا فعندما يأتي الأمر إلى مجموعات البيانات الكبيرة، فإن
المناهج البسيطة يمكنها القيام بذلك بشكل جيد للغاية. حسنًا، فقد تغيرت الكثير من
الأمور منذ ذلك الحين. أصبح حجم البيانات لدينا أكبر، وبالتالي
أصبحت تطلعاتنا أكبر. فنحن نريد أن نكون قادرين على التعامل مع
النماذج الدقيقة وهذه البيانات الكبيرة. لذا، فكان علينا ابتكار أنواع
جديدة من الخوارزميات التي يمكنها توسيع نطاق النماذج المعقدة لاحتواء مجموعات
البيانات الهائلة والحصول على الدقة الرائعة حقًا. وهذه كانت أمور مثل، العمليات الموازية،
واستخدام وحدات معالجة الرسومات واستخدام مجموعات الكمبيوتر الكبيرة،وذلك
الأسلوب المعين الذي سنتحدث حوله اليوم، والذي سيفيدنا للغاية عند
التعامل مع النماذج المعقدة. لذا، أشياء مثل أشجار القرار المعززة،
وعوامل التحليل الجذبية، والتعلم المعمق، حيث يتطلب
هذا النوع من التعلم كمية هائلة من وقت العمليات الحسابية
للوصول إلى هذه الدقة الرائعة. وبالعودة 20 عامًا إلى الوراء، فقد كان الناس يبنون نماذج
رسومية ضخمة للغاية. حيث إنه كانت لديهم أساليب جديدة
لمواءمتها بالتوازي وبإعدادات موزعة حتى يكونوا قادرين على الوصول إلى دقة
أكبر عند التعامل مع مجموعات البيانات الكبيرة. لذا، فملخص هذه القصة، هو أن فكرة التعلم الآلي
قد تطورت كثيرًا على مدار السنوات القليلة الماضية للعودة
أولًا إلى جذور أبسط، حتى تتمكن من التعامل مع مجموعات البيانات الكبيرة، ولكن اليوم
فقد أصبحت تهدف إلى ابتكار خوارزميات جديدة من شأنها مواءمة النماذج المعقدة مع
مجموعات البيانات الضخمة. وهذا ما نحن عليه اليوم. وبالعودة إلى نفس الإطار والذي
سنناقشه خلال باقي الدورة، حيث سنأخذ بعض بيانات التدريب،
ونستخرج بعض السمات، ثم نبني نموذجًا آليًا، ولكن فإن الخوارزمية
الآلية التي سنستخدمها هي عبارة عن تعديل صغير في التدرج
التصاعدي لدراسة هذا التغير. ولكنها ستسمح لنا بمواءمة
مجموعات بيانات هائلة، وإجراء ذلك بشكل جيد حقًا. وتدعى هذه التعديلات
بالتدرج العشوائي، ويقوم بأمر في غاية البساطة. فما يقوم به هو أخذ مجموعة البيانات
الهائلة والمتغير الحالي (W(t، وعندما تقوم بحساب التدرج، فبدلًا من
البحث في البيانات بأكملها، حيث إنك لا تحتاج إلى
البحث في كل شيء. فإنه يبحث في مجموعة فرعية
صغيرة من البيانات. لذا، فهو يتعامل مع قدر
قليل من البيانات، ثم يقوم بتحديث المعاملات
إلى (W(t+1. ثم يبحث قليلًا في المزيد من البيانات ثم يقوم بتحديث المعاملات
إلى (W(t+2. ثم يقوم بالبحث قليلًا في المزيد من البيانات
ويحدث المعاملات إلى (W(t+3. ثم يبحث قليلًا في المزيد من البيانات
ويحدث المعاملات إلى (W(t+4. لذا، فبدلًا من القيام بتخطٍّ هائل
عبر مجموعة البيانات، قبل إجراء تحديث المعامل،
فإننا نبحث في القليل من وحدات البيانات ونقوم بتحديث
المعاملات بشكل مترابط نوعًا ما. وهذا التعديل البسيط، سيقوم حقًا
بتغيير كل شيء بالنسبة لنا، ويسمح لنا بمواءمة مجموعات هائلة من
البيانات، تمامًا كما رأينا اليوم. [موسيقى]